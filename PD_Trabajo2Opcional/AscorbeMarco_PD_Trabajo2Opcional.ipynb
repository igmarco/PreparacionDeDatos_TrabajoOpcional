{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21f4faf-17db-4fff-b997-bbe979bd0691",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trabajo 2 Opcional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c27cde-bbac-4c5b-b9d1-19aa70b0957e",
   "metadata": {},
   "source": [
    " - Máster en Ciencia de Datos y Aprendizaje Automático.\n",
    " - Asignatura: Preparación de Datos.\n",
    " - Trabajo realizado por: Pablo Ascorbe e Ignacio Marco.\n",
    " - Fecha: --/01/2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb83e0-2a88-4a13-8a33-8b4bdcaae5dd",
   "metadata": {},
   "source": [
    "## 1. Lectura y análisis del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bdb0c-32b7-4dac-9ff7-a7ba0cc2ec55",
   "metadata": {},
   "source": [
    "En este primer apartado importaremos los datos y haremos un estudio inicial de estos.\n",
    "Los datos forman parte del [Best Books Ever Dataset](https://zenodo.org/record/4265096#.Y7vcdBXMLct), que contiene información sobre obras populares de literatura publicadas en la web [Good Reads](https://www.goodreads.com), para las que se registran los detalles de la obra y su edición, el autor o autora, los premios obtenidos y sus puntuaciones en distinas clasificaciones. Este dataset contiene un total de 52.407 registros y 25 variables que requieren un preprocesado relativamente exigente.\n",
    "\n",
    "Como contextualización, trasladamos la descripción de las variables del dataset:\n",
    "\n",
    "* *bookId*: Identificador de la obra dentro de la web Good Reads.\n",
    "* *title*: Título de la obra.\n",
    "* *series*: Título de la serie en la que se enmarca la obra.\n",
    "* *author*: Nombre del autor o la autora.\n",
    "* *rating*: Valoración global dentro de Good Reads por los usuarios.\n",
    "* *description*: Anotaciones en el registro.\n",
    "* *language*: Idioma en el que está escrita la obra\n",
    "* *isbn*: ISBN (identificador estándar) de la obra.\n",
    "* *genres*: Lista de géneros de la obra.\n",
    "* *characters*: Lista de personajes principales de la obra.\n",
    "* *bookFormat*: Formato de la obra (de tapa dura, de tapa blanda, digital, etc.)\n",
    "* *edition*: Edición de la obra.\n",
    "* *pages*: Número de páginas.\n",
    "* *publisher*: Editorial que publicó la edición de la obra.\n",
    "* *publishDate*: Fecha de publicación de la edición.\n",
    "* *firstPublishDate*: Fecha de publicación de la obra.\n",
    "* *awards*: Lista de premios recibidos por la obra reconocidos por Good Reads.\n",
    "* *numRatings*: Número de valoraciones por parte de los usuarios de Good Reads.\n",
    "* *ratingByStars*: Lista de los 5 números de valoraciones de los usuarios de Good Reads, correspondientes a las 5 posibles puntuaciones.\n",
    "* *likedPercent*: Porcentaje de los usuarios que han emitido una evaluación positiva en Good Reads.\n",
    "* *setting*: Colección de ubicaciones en las que transcurren los acontecimientos de la obra.\n",
    "* *coverImg*: Enlace a la imagen de portada subida a Good Reads.\n",
    "* *bbeScore*: Evaluación de la obra en la lista [Best Books Ever](https://www.goodreads.com/list/show/1.Best_Books_Ever).\n",
    "* *bbeVotes*: Número de evaluaciones en la lista [Best Books Ever](https://www.goodreads.com/list/show/1.Best_Books_Ever).\n",
    "* *price*: Precio de venta en la página."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db2641-5f32-491c-8aa0-5a171cdeaba6",
   "metadata": {},
   "source": [
    "### 1.1. Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f463db3-f6b0-43d4-a890-e874ec6ff9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52478, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('libros.csv', header=0, dtype=object)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ac814-a011-436c-8af7-e2c12a3ff305",
   "metadata": {},
   "source": [
    "Vemos que tenemos demasiadas instancias y que podría estar bien reducir un poco para simplificar, pero de momento vamos a seguir con todas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb57791d-2d3a-4e3d-b998-bb68df89d236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookId</th>\n",
       "      <th>title</th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>isbn</th>\n",
       "      <th>genres</th>\n",
       "      <th>characters</th>\n",
       "      <th>...</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>awards</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>setting</th>\n",
       "      <th>coverImg</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052-the-hunger-games</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>4.33</td>\n",
       "      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439023481</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n",
       "      <td>['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Locus Award Nominee for Best Young Adult Boo...</td>\n",
       "      <td>6376780</td>\n",
       "      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n",
       "      <td>96</td>\n",
       "      <td>['District 12, Panem', 'Capitol, Panem', 'Pane...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2993816</td>\n",
       "      <td>30516</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.Harry_Potter_and_the_Order_of_the_Phoenix</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n",
       "      <td>4.50</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439358071</td>\n",
       "      <td>['Fantasy', 'Young Adult', 'Fiction', 'Magic',...</td>\n",
       "      <td>['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...</td>\n",
       "      <td>...</td>\n",
       "      <td>06/21/03</td>\n",
       "      <td>['Bram Stoker Award for Works for Young Reader...</td>\n",
       "      <td>2507623</td>\n",
       "      <td>['1593642', '637516', '222366', '39573', '14526']</td>\n",
       "      <td>98</td>\n",
       "      <td>['Hogwarts School of Witchcraft and Wizardry (...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2632233</td>\n",
       "      <td>26923</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2657.To_Kill_a_Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4.28</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>English</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n",
       "      <td>['Scout Finch', 'Atticus Finch', 'Jem Finch', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>07/11/60</td>\n",
       "      <td>['Pulitzer Prize for Fiction (1961)', 'Audie A...</td>\n",
       "      <td>4501075</td>\n",
       "      <td>['2363896', '1333153', '573280', '149952', '80...</td>\n",
       "      <td>95</td>\n",
       "      <td>['Maycomb, Alabama (United States)']</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2269402</td>\n",
       "      <td>23328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1885.Pride_and_Prejudice</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jane Austen, Anna Quindlen (Introduction)</td>\n",
       "      <td>4.26</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>English</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>['Classics', 'Fiction', 'Romance', 'Historical...</td>\n",
       "      <td>['Mr. Bennet', 'Mrs. Bennet', 'Jane Bennet', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>01/28/13</td>\n",
       "      <td>[]</td>\n",
       "      <td>2998241</td>\n",
       "      <td>['1617567', '816659', '373311', '113934', '767...</td>\n",
       "      <td>94</td>\n",
       "      <td>['United Kingdom', 'Derbyshire, England (Unite...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>1983116</td>\n",
       "      <td>20452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41865.Twilight</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>The Twilight Saga #1</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3.60</td>\n",
       "      <td>About three things I was absolutely positive.\\...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780316015844</td>\n",
       "      <td>['Young Adult', 'Fantasy', 'Romance', 'Vampire...</td>\n",
       "      <td>['Edward Cullen', 'Jacob Black', 'Laurent', 'R...</td>\n",
       "      <td>...</td>\n",
       "      <td>10/05/05</td>\n",
       "      <td>['Georgia Peach Book Award (2007)', 'Buxtehude...</td>\n",
       "      <td>4964519</td>\n",
       "      <td>['1751460', '1113682', '1008686', '542017', '5...</td>\n",
       "      <td>78</td>\n",
       "      <td>['Forks, Washington (United States)', 'Phoenix...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>1459448</td>\n",
       "      <td>14874</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        bookId  \\\n",
       "0                     2767052-the-hunger-games   \n",
       "1  2.Harry_Potter_and_the_Order_of_the_Phoenix   \n",
       "2                   2657.To_Kill_a_Mockingbird   \n",
       "3                     1885.Pride_and_Prejudice   \n",
       "4                               41865.Twilight   \n",
       "\n",
       "                                       title                 series  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "3                        Pride and Prejudice                    NaN   \n",
       "4                                   Twilight   The Twilight Saga #1   \n",
       "\n",
       "                                      author rating  \\\n",
       "0                            Suzanne Collins   4.33   \n",
       "1  J.K. Rowling, Mary GrandPré (Illustrator)   4.50   \n",
       "2                                 Harper Lee   4.28   \n",
       "3  Jane Austen, Anna Quindlen (Introduction)   4.26   \n",
       "4                            Stephenie Meyer   3.60   \n",
       "\n",
       "                                         description language           isbn  \\\n",
       "0  WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...  English  9780439023481   \n",
       "1  There is a door at the end of a silent corrido...  English  9780439358071   \n",
       "2  The unforgettable novel of a childhood in a sl...  English  9999999999999   \n",
       "3  Alternate cover edition of ISBN 9780679783268S...  English  9999999999999   \n",
       "4  About three things I was absolutely positive.\\...  English  9780316015844   \n",
       "\n",
       "                                              genres  \\\n",
       "0  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...   \n",
       "1  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...   \n",
       "2  ['Classics', 'Fiction', 'Historical Fiction', ...   \n",
       "3  ['Classics', 'Fiction', 'Romance', 'Historical...   \n",
       "4  ['Young Adult', 'Fantasy', 'Romance', 'Vampire...   \n",
       "\n",
       "                                          characters  ... firstPublishDate  \\\n",
       "0  ['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...  ...              NaN   \n",
       "1  ['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...  ...         06/21/03   \n",
       "2  ['Scout Finch', 'Atticus Finch', 'Jem Finch', ...  ...         07/11/60   \n",
       "3  ['Mr. Bennet', 'Mrs. Bennet', 'Jane Bennet', '...  ...         01/28/13   \n",
       "4  ['Edward Cullen', 'Jacob Black', 'Laurent', 'R...  ...         10/05/05   \n",
       "\n",
       "                                              awards numRatings  \\\n",
       "0  ['Locus Award Nominee for Best Young Adult Boo...    6376780   \n",
       "1  ['Bram Stoker Award for Works for Young Reader...    2507623   \n",
       "2  ['Pulitzer Prize for Fiction (1961)', 'Audie A...    4501075   \n",
       "3                                                 []    2998241   \n",
       "4  ['Georgia Peach Book Award (2007)', 'Buxtehude...    4964519   \n",
       "\n",
       "                                      ratingsByStars likedPercent  \\\n",
       "0  ['3444695', '1921313', '745221', '171994', '93...           96   \n",
       "1  ['1593642', '637516', '222366', '39573', '14526']           98   \n",
       "2  ['2363896', '1333153', '573280', '149952', '80...           95   \n",
       "3  ['1617567', '816659', '373311', '113934', '767...           94   \n",
       "4  ['1751460', '1113682', '1008686', '542017', '5...           78   \n",
       "\n",
       "                                             setting  \\\n",
       "0  ['District 12, Panem', 'Capitol, Panem', 'Pane...   \n",
       "1  ['Hogwarts School of Witchcraft and Wizardry (...   \n",
       "2               ['Maycomb, Alabama (United States)']   \n",
       "3  ['United Kingdom', 'Derbyshire, England (Unite...   \n",
       "4  ['Forks, Washington (United States)', 'Phoenix...   \n",
       "\n",
       "                                            coverImg bbeScore bbeVotes price  \n",
       "0  https://i.gr-assets.com/images/S/compressed.ph...  2993816    30516  5.09  \n",
       "1  https://i.gr-assets.com/images/S/compressed.ph...  2632233    26923  7.38  \n",
       "2  https://i.gr-assets.com/images/S/compressed.ph...  2269402    23328   NaN  \n",
       "3  https://i.gr-assets.com/images/S/compressed.ph...  1983116    20452   NaN  \n",
       "4  https://i.gr-assets.com/images/S/compressed.ph...  1459448    14874   2.1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f065a7b4-0a46-4482-b8c4-a8ad97efd8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookId</th>\n",
       "      <th>title</th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>isbn</th>\n",
       "      <th>genres</th>\n",
       "      <th>characters</th>\n",
       "      <th>...</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>awards</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>setting</th>\n",
       "      <th>coverImg</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52473</th>\n",
       "      <td>11492014-fractured</td>\n",
       "      <td>Fractured</td>\n",
       "      <td>Fateful #2</td>\n",
       "      <td>Cheri Schmidt (Goodreads Author)</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The Fateful Trilogy continues with Fractured. ...</td>\n",
       "      <td>English</td>\n",
       "      <td>2940012616562</td>\n",
       "      <td>['Vampires', 'Paranormal', 'Young Adult', 'Rom...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>871</td>\n",
       "      <td>['311', '310', '197', '42', '11']</td>\n",
       "      <td>94</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52474</th>\n",
       "      <td>11836711-anasazi</td>\n",
       "      <td>Anasazi</td>\n",
       "      <td>Sense of Truth #2</td>\n",
       "      <td>Emma Michaels</td>\n",
       "      <td>4.19</td>\n",
       "      <td>'Anasazi', sequel to 'The Thirteenth Chime' by...</td>\n",
       "      <td>English</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>['Mystery', 'Young Adult']</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>August 3rd 2011</td>\n",
       "      <td>[]</td>\n",
       "      <td>37</td>\n",
       "      <td>['16', '14', '5', '2', '0']</td>\n",
       "      <td>95</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52475</th>\n",
       "      <td>10815662-marked</td>\n",
       "      <td>Marked</td>\n",
       "      <td>Soul Guardians #1</td>\n",
       "      <td>Kim Richardson (Goodreads Author)</td>\n",
       "      <td>3.70</td>\n",
       "      <td>--READERS FAVORITE AWARDS WINNER 2011--Sixteen...</td>\n",
       "      <td>English</td>\n",
       "      <td>9781461017097</td>\n",
       "      <td>['Fantasy', 'Young Adult', 'Paranormal', 'Ange...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>March 15th 2011</td>\n",
       "      <td>[\"Readers' Favorite Book Award (2011)\"]</td>\n",
       "      <td>6674</td>\n",
       "      <td>['2109', '1868', '1660', '647', '390']</td>\n",
       "      <td>84</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52476</th>\n",
       "      <td>11330278-wayward-son</td>\n",
       "      <td>Wayward Son</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tom Pollack (Goodreads Author), John Loftus (G...</td>\n",
       "      <td>3.85</td>\n",
       "      <td>A POWERFUL TREMOR UNEARTHS AN ANCIENT SECRETBu...</td>\n",
       "      <td>English</td>\n",
       "      <td>9781450755634</td>\n",
       "      <td>['Fiction', 'Mystery', 'Historical Fiction', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>April 5th 2011</td>\n",
       "      <td>[]</td>\n",
       "      <td>238</td>\n",
       "      <td>['77', '78', '59', '19', '5']</td>\n",
       "      <td>90</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52477</th>\n",
       "      <td>10991547-daughter-of-helaman</td>\n",
       "      <td>Daughter of Helaman</td>\n",
       "      <td>Stripling Warrior #1</td>\n",
       "      <td>Misty Moncur (Goodreads Author)</td>\n",
       "      <td>4.02</td>\n",
       "      <td>Fighting in Helaman's army is Keturah's deepes...</td>\n",
       "      <td>English</td>\n",
       "      <td>9781599554976</td>\n",
       "      <td>['Lds Fiction', 'Historical Fiction', 'Young A...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>246</td>\n",
       "      <td>['106', '73', '42', '17', '8']</td>\n",
       "      <td>90</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             bookId                title  \\\n",
       "52473            11492014-fractured            Fractured   \n",
       "52474              11836711-anasazi              Anasazi   \n",
       "52475               10815662-marked               Marked   \n",
       "52476          11330278-wayward-son          Wayward Son   \n",
       "52477  10991547-daughter-of-helaman  Daughter of Helaman   \n",
       "\n",
       "                     series  \\\n",
       "52473            Fateful #2   \n",
       "52474     Sense of Truth #2   \n",
       "52475     Soul Guardians #1   \n",
       "52476                   NaN   \n",
       "52477  Stripling Warrior #1   \n",
       "\n",
       "                                                  author rating  \\\n",
       "52473                   Cheri Schmidt (Goodreads Author)   4.00   \n",
       "52474                                      Emma Michaels   4.19   \n",
       "52475                  Kim Richardson (Goodreads Author)   3.70   \n",
       "52476  Tom Pollack (Goodreads Author), John Loftus (G...   3.85   \n",
       "52477                    Misty Moncur (Goodreads Author)   4.02   \n",
       "\n",
       "                                             description language  \\\n",
       "52473  The Fateful Trilogy continues with Fractured. ...  English   \n",
       "52474  'Anasazi', sequel to 'The Thirteenth Chime' by...  English   \n",
       "52475  --READERS FAVORITE AWARDS WINNER 2011--Sixteen...  English   \n",
       "52476  A POWERFUL TREMOR UNEARTHS AN ANCIENT SECRETBu...  English   \n",
       "52477  Fighting in Helaman's army is Keturah's deepes...  English   \n",
       "\n",
       "                isbn                                             genres  \\\n",
       "52473  2940012616562  ['Vampires', 'Paranormal', 'Young Adult', 'Rom...   \n",
       "52474  9999999999999                         ['Mystery', 'Young Adult']   \n",
       "52475  9781461017097  ['Fantasy', 'Young Adult', 'Paranormal', 'Ange...   \n",
       "52476  9781450755634  ['Fiction', 'Mystery', 'Historical Fiction', '...   \n",
       "52477  9781599554976  ['Lds Fiction', 'Historical Fiction', 'Young A...   \n",
       "\n",
       "      characters  ... firstPublishDate  \\\n",
       "52473         []  ...              NaN   \n",
       "52474         []  ...  August 3rd 2011   \n",
       "52475         []  ...  March 15th 2011   \n",
       "52476         []  ...   April 5th 2011   \n",
       "52477         []  ...              NaN   \n",
       "\n",
       "                                        awards numRatings  \\\n",
       "52473                                       []        871   \n",
       "52474                                       []         37   \n",
       "52475  [\"Readers' Favorite Book Award (2011)\"]       6674   \n",
       "52476                                       []        238   \n",
       "52477                                       []        246   \n",
       "\n",
       "                               ratingsByStars likedPercent setting  \\\n",
       "52473       ['311', '310', '197', '42', '11']           94      []   \n",
       "52474             ['16', '14', '5', '2', '0']           95      []   \n",
       "52475  ['2109', '1868', '1660', '647', '390']           84      []   \n",
       "52476           ['77', '78', '59', '19', '5']           90      []   \n",
       "52477          ['106', '73', '42', '17', '8']           90      []   \n",
       "\n",
       "                                                coverImg bbeScore bbeVotes  \\\n",
       "52473  https://i.gr-assets.com/images/S/compressed.ph...        0        1   \n",
       "52474  https://i.gr-assets.com/images/S/compressed.ph...        0        1   \n",
       "52475  https://i.gr-assets.com/images/S/compressed.ph...        0        1   \n",
       "52476  https://i.gr-assets.com/images/S/compressed.ph...        0        1   \n",
       "52477  https://i.gr-assets.com/images/S/compressed.ph...        0        1   \n",
       "\n",
       "      price  \n",
       "52473   NaN  \n",
       "52474   NaN  \n",
       "52475  7.37  \n",
       "52476  2.86  \n",
       "52477  5.20  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b9dbe5-baef-4a61-814d-7b7715feaa1f",
   "metadata": {},
   "source": [
    "Vemos que las últimas instancias del dataframe contienen un formato de fechas distintas a las primeras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4389a-4b40-4374-86b0-1fa6edbbed55",
   "metadata": {},
   "source": [
    "Ya con esta primera visualización de los datos vemos que tenemos nulos y que hay columnas que no nos van a interesar para nada, como la imagen de la portada o el ISBN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af2e74-0761-4077-9cde-d8626e030d8b",
   "metadata": {},
   "source": [
    "Otra duda es, ¿qué variable será la explicada?, ¿cuál usaremos como objetivo? Esto es totalmente libre y puede variar según nuestros intereses; como parece interesante determinar la puntuación de cada libro para poder predecir qué tan valorado será un libro concreto, nos quedaremos con 'rating'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e01881c-d46a-44ed-94d9-642571296caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52478, 24) (52478,)\n"
     ]
    }
   ],
   "source": [
    "# Separamos explicativas de explicada\n",
    "\n",
    "X, y = df.drop('rating', axis=1), df.rating\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f958bf74-db0a-47d5-a557-6376208ee2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookId</th>\n",
       "      <th>title</th>\n",
       "      <th>series</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "      <th>isbn</th>\n",
       "      <th>genres</th>\n",
       "      <th>characters</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>...</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>awards</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>setting</th>\n",
       "      <th>coverImg</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052-the-hunger-games</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games #1</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439023481</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n",
       "      <td>['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Locus Award Nominee for Best Young Adult Boo...</td>\n",
       "      <td>6376780</td>\n",
       "      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n",
       "      <td>96</td>\n",
       "      <td>['District 12, Panem', 'Capitol, Panem', 'Pane...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2993816</td>\n",
       "      <td>30516</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.Harry_Potter_and_the_Order_of_the_Phoenix</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Harry Potter #5</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780439358071</td>\n",
       "      <td>['Fantasy', 'Young Adult', 'Fiction', 'Magic',...</td>\n",
       "      <td>['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>...</td>\n",
       "      <td>06/21/03</td>\n",
       "      <td>['Bram Stoker Award for Works for Young Reader...</td>\n",
       "      <td>2507623</td>\n",
       "      <td>['1593642', '637516', '222366', '39573', '14526']</td>\n",
       "      <td>98</td>\n",
       "      <td>['Hogwarts School of Witchcraft and Wizardry (...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2632233</td>\n",
       "      <td>26923</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2657.To_Kill_a_Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>English</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n",
       "      <td>['Scout Finch', 'Atticus Finch', 'Jem Finch', ...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>...</td>\n",
       "      <td>07/11/60</td>\n",
       "      <td>['Pulitzer Prize for Fiction (1961)', 'Audie A...</td>\n",
       "      <td>4501075</td>\n",
       "      <td>['2363896', '1333153', '573280', '149952', '80...</td>\n",
       "      <td>95</td>\n",
       "      <td>['Maycomb, Alabama (United States)']</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2269402</td>\n",
       "      <td>23328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1885.Pride_and_Prejudice</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jane Austen, Anna Quindlen (Introduction)</td>\n",
       "      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n",
       "      <td>English</td>\n",
       "      <td>9999999999999</td>\n",
       "      <td>['Classics', 'Fiction', 'Romance', 'Historical...</td>\n",
       "      <td>['Mr. Bennet', 'Mrs. Bennet', 'Jane Bennet', '...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>...</td>\n",
       "      <td>01/28/13</td>\n",
       "      <td>[]</td>\n",
       "      <td>2998241</td>\n",
       "      <td>['1617567', '816659', '373311', '113934', '767...</td>\n",
       "      <td>94</td>\n",
       "      <td>['United Kingdom', 'Derbyshire, England (Unite...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>1983116</td>\n",
       "      <td>20452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41865.Twilight</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>The Twilight Saga #1</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>About three things I was absolutely positive.\\...</td>\n",
       "      <td>English</td>\n",
       "      <td>9780316015844</td>\n",
       "      <td>['Young Adult', 'Fantasy', 'Romance', 'Vampire...</td>\n",
       "      <td>['Edward Cullen', 'Jacob Black', 'Laurent', 'R...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>...</td>\n",
       "      <td>10/05/05</td>\n",
       "      <td>['Georgia Peach Book Award (2007)', 'Buxtehude...</td>\n",
       "      <td>4964519</td>\n",
       "      <td>['1751460', '1113682', '1008686', '542017', '5...</td>\n",
       "      <td>78</td>\n",
       "      <td>['Forks, Washington (United States)', 'Phoenix...</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>1459448</td>\n",
       "      <td>14874</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        bookId  \\\n",
       "0                     2767052-the-hunger-games   \n",
       "1  2.Harry_Potter_and_the_Order_of_the_Phoenix   \n",
       "2                   2657.To_Kill_a_Mockingbird   \n",
       "3                     1885.Pride_and_Prejudice   \n",
       "4                               41865.Twilight   \n",
       "\n",
       "                                       title                 series  \\\n",
       "0                           The Hunger Games    The Hunger Games #1   \n",
       "1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n",
       "2                      To Kill a Mockingbird  To Kill a Mockingbird   \n",
       "3                        Pride and Prejudice                    NaN   \n",
       "4                                   Twilight   The Twilight Saga #1   \n",
       "\n",
       "                                      author  \\\n",
       "0                            Suzanne Collins   \n",
       "1  J.K. Rowling, Mary GrandPré (Illustrator)   \n",
       "2                                 Harper Lee   \n",
       "3  Jane Austen, Anna Quindlen (Introduction)   \n",
       "4                            Stephenie Meyer   \n",
       "\n",
       "                                         description language           isbn  \\\n",
       "0  WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...  English  9780439023481   \n",
       "1  There is a door at the end of a silent corrido...  English  9780439358071   \n",
       "2  The unforgettable novel of a childhood in a sl...  English  9999999999999   \n",
       "3  Alternate cover edition of ISBN 9780679783268S...  English  9999999999999   \n",
       "4  About three things I was absolutely positive.\\...  English  9780316015844   \n",
       "\n",
       "                                              genres  \\\n",
       "0  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...   \n",
       "1  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...   \n",
       "2  ['Classics', 'Fiction', 'Historical Fiction', ...   \n",
       "3  ['Classics', 'Fiction', 'Romance', 'Historical...   \n",
       "4  ['Young Adult', 'Fantasy', 'Romance', 'Vampire...   \n",
       "\n",
       "                                          characters bookFormat  ...  \\\n",
       "0  ['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...  Hardcover  ...   \n",
       "1  ['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...  Paperback  ...   \n",
       "2  ['Scout Finch', 'Atticus Finch', 'Jem Finch', ...  Paperback  ...   \n",
       "3  ['Mr. Bennet', 'Mrs. Bennet', 'Jane Bennet', '...  Paperback  ...   \n",
       "4  ['Edward Cullen', 'Jacob Black', 'Laurent', 'R...  Paperback  ...   \n",
       "\n",
       "  firstPublishDate                                             awards  \\\n",
       "0              NaN  ['Locus Award Nominee for Best Young Adult Boo...   \n",
       "1         06/21/03  ['Bram Stoker Award for Works for Young Reader...   \n",
       "2         07/11/60  ['Pulitzer Prize for Fiction (1961)', 'Audie A...   \n",
       "3         01/28/13                                                 []   \n",
       "4         10/05/05  ['Georgia Peach Book Award (2007)', 'Buxtehude...   \n",
       "\n",
       "  numRatings                                     ratingsByStars likedPercent  \\\n",
       "0    6376780  ['3444695', '1921313', '745221', '171994', '93...           96   \n",
       "1    2507623  ['1593642', '637516', '222366', '39573', '14526']           98   \n",
       "2    4501075  ['2363896', '1333153', '573280', '149952', '80...           95   \n",
       "3    2998241  ['1617567', '816659', '373311', '113934', '767...           94   \n",
       "4    4964519  ['1751460', '1113682', '1008686', '542017', '5...           78   \n",
       "\n",
       "                                             setting  \\\n",
       "0  ['District 12, Panem', 'Capitol, Panem', 'Pane...   \n",
       "1  ['Hogwarts School of Witchcraft and Wizardry (...   \n",
       "2               ['Maycomb, Alabama (United States)']   \n",
       "3  ['United Kingdom', 'Derbyshire, England (Unite...   \n",
       "4  ['Forks, Washington (United States)', 'Phoenix...   \n",
       "\n",
       "                                            coverImg bbeScore bbeVotes price  \n",
       "0  https://i.gr-assets.com/images/S/compressed.ph...  2993816    30516  5.09  \n",
       "1  https://i.gr-assets.com/images/S/compressed.ph...  2632233    26923  7.38  \n",
       "2  https://i.gr-assets.com/images/S/compressed.ph...  2269402    23328   NaN  \n",
       "3  https://i.gr-assets.com/images/S/compressed.ph...  1983116    20452   NaN  \n",
       "4  https://i.gr-assets.com/images/S/compressed.ph...  1459448    14874   2.1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc84e86-270f-4a24-ba7d-1d5fba56851d",
   "metadata": {},
   "source": [
    "### 1.2. Estudio inicial del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d91530-7c2d-40f4-867a-a2b769575161",
   "metadata": {},
   "source": [
    "Como comentabamos, hay una serie de columnas que desde el comienzo no nos interesan; estas son: la URL de la portada, el ISBN, el identificador del libro, su título, la serie de la que viene y la descripción. De momento, eliminamos estas porque además de ser variables únicas, ya que casi todas son identificadores o textos extensos, no nos proporcionan información útil, a menos que podamos usar procesamiento de texto u otras técnicas que se escapan del objetivo del trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f9f6f-f16e-44b4-b17d-20c33f3647bc",
   "metadata": {},
   "source": [
    "#### 1.2.1. Eliminación de variables irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a2453-8c65-4918-a91d-02e882f93a41",
   "metadata": {},
   "source": [
    "Eliminemos las variables que consideramos poco relevante por ser índices o aportar poca información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93232411-05d1-41d9-8b80-8477d89938eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>genres</th>\n",
       "      <th>characters</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>pages</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>firstPublishDate</th>\n",
       "      <th>awards</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>setting</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n",
       "      <td>['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>374</td>\n",
       "      <td>09/14/08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Locus Award Nominee for Best Young Adult Boo...</td>\n",
       "      <td>6376780</td>\n",
       "      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n",
       "      <td>96</td>\n",
       "      <td>['District 12, Panem', 'Capitol, Panem', 'Pane...</td>\n",
       "      <td>2993816</td>\n",
       "      <td>30516</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>['Fantasy', 'Young Adult', 'Fiction', 'Magic',...</td>\n",
       "      <td>['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>870</td>\n",
       "      <td>09/28/04</td>\n",
       "      <td>06/21/03</td>\n",
       "      <td>['Bram Stoker Award for Works for Young Reader...</td>\n",
       "      <td>2507623</td>\n",
       "      <td>['1593642', '637516', '222366', '39573', '14526']</td>\n",
       "      <td>98</td>\n",
       "      <td>['Hogwarts School of Witchcraft and Wizardry (...</td>\n",
       "      <td>2632233</td>\n",
       "      <td>26923</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n",
       "      <td>['Scout Finch', 'Atticus Finch', 'Jem Finch', ...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>324</td>\n",
       "      <td>05/23/06</td>\n",
       "      <td>07/11/60</td>\n",
       "      <td>['Pulitzer Prize for Fiction (1961)', 'Audie A...</td>\n",
       "      <td>4501075</td>\n",
       "      <td>['2363896', '1333153', '573280', '149952', '80...</td>\n",
       "      <td>95</td>\n",
       "      <td>['Maycomb, Alabama (United States)']</td>\n",
       "      <td>2269402</td>\n",
       "      <td>23328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>['Classics', 'Fiction', 'Romance', 'Historical...</td>\n",
       "      <td>['Mr. Bennet', 'Mrs. Bennet', 'Jane Bennet', '...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>279</td>\n",
       "      <td>10/10/00</td>\n",
       "      <td>01/28/13</td>\n",
       "      <td>[]</td>\n",
       "      <td>2998241</td>\n",
       "      <td>['1617567', '816659', '373311', '113934', '767...</td>\n",
       "      <td>94</td>\n",
       "      <td>['United Kingdom', 'Derbyshire, England (Unite...</td>\n",
       "      <td>1983116</td>\n",
       "      <td>20452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>['Young Adult', 'Fantasy', 'Romance', 'Vampire...</td>\n",
       "      <td>['Edward Cullen', 'Jacob Black', 'Laurent', 'R...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>501</td>\n",
       "      <td>09/06/06</td>\n",
       "      <td>10/05/05</td>\n",
       "      <td>['Georgia Peach Book Award (2007)', 'Buxtehude...</td>\n",
       "      <td>4964519</td>\n",
       "      <td>['1751460', '1113682', '1008686', '542017', '5...</td>\n",
       "      <td>78</td>\n",
       "      <td>['Forks, Washington (United States)', 'Phoenix...</td>\n",
       "      <td>1459448</td>\n",
       "      <td>14874</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                             genres  \\\n",
       "0  English  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...   \n",
       "1  English  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...   \n",
       "2  English  ['Classics', 'Fiction', 'Historical Fiction', ...   \n",
       "3  English  ['Classics', 'Fiction', 'Romance', 'Historical...   \n",
       "4  English  ['Young Adult', 'Fantasy', 'Romance', 'Vampire...   \n",
       "\n",
       "                                          characters bookFormat pages  \\\n",
       "0  ['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...  Hardcover   374   \n",
       "1  ['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...  Paperback   870   \n",
       "2  ['Scout Finch', 'Atticus Finch', 'Jem Finch', ...  Paperback   324   \n",
       "3  ['Mr. Bennet', 'Mrs. Bennet', 'Jane Bennet', '...  Paperback   279   \n",
       "4  ['Edward Cullen', 'Jacob Black', 'Laurent', 'R...  Paperback   501   \n",
       "\n",
       "  publishDate firstPublishDate  \\\n",
       "0    09/14/08              NaN   \n",
       "1    09/28/04         06/21/03   \n",
       "2    05/23/06         07/11/60   \n",
       "3    10/10/00         01/28/13   \n",
       "4    09/06/06         10/05/05   \n",
       "\n",
       "                                              awards numRatings  \\\n",
       "0  ['Locus Award Nominee for Best Young Adult Boo...    6376780   \n",
       "1  ['Bram Stoker Award for Works for Young Reader...    2507623   \n",
       "2  ['Pulitzer Prize for Fiction (1961)', 'Audie A...    4501075   \n",
       "3                                                 []    2998241   \n",
       "4  ['Georgia Peach Book Award (2007)', 'Buxtehude...    4964519   \n",
       "\n",
       "                                      ratingsByStars likedPercent  \\\n",
       "0  ['3444695', '1921313', '745221', '171994', '93...           96   \n",
       "1  ['1593642', '637516', '222366', '39573', '14526']           98   \n",
       "2  ['2363896', '1333153', '573280', '149952', '80...           95   \n",
       "3  ['1617567', '816659', '373311', '113934', '767...           94   \n",
       "4  ['1751460', '1113682', '1008686', '542017', '5...           78   \n",
       "\n",
       "                                             setting bbeScore bbeVotes price  \n",
       "0  ['District 12, Panem', 'Capitol, Panem', 'Pane...  2993816    30516  5.09  \n",
       "1  ['Hogwarts School of Witchcraft and Wizardry (...  2632233    26923  7.38  \n",
       "2               ['Maycomb, Alabama (United States)']  2269402    23328   NaN  \n",
       "3  ['United Kingdom', 'Derbyshire, England (Unite...  1983116    20452   NaN  \n",
       "4  ['Forks, Washington (United States)', 'Phoenix...  1459448    14874   2.1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop(['bookId', 'title', 'series', 'isbn', 'description', 'coverImg', 'author', 'publisher', 'edition'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa26b38-cf17-4ad7-bfeb-fed965065fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   language          48672 non-null  object\n",
      " 1   genres            52478 non-null  object\n",
      " 2   characters        52478 non-null  object\n",
      " 3   bookFormat        51005 non-null  object\n",
      " 4   pages             50131 non-null  object\n",
      " 5   publishDate       51598 non-null  object\n",
      " 6   firstPublishDate  31152 non-null  object\n",
      " 7   awards            52478 non-null  object\n",
      " 8   numRatings        52478 non-null  object\n",
      " 9   ratingsByStars    52478 non-null  object\n",
      " 10  likedPercent      51856 non-null  object\n",
      " 11  setting           52478 non-null  object\n",
      " 12  bbeScore          52478 non-null  object\n",
      " 13  bbeVotes          52478 non-null  object\n",
      " 14  price             38113 non-null  object\n",
      "dtypes: object(15)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5429e-3485-414f-b3e7-3c40d47c67a3",
   "metadata": {},
   "source": [
    "#### 1.2.2. Tratamiento de variables numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6421e5-49ff-4fa1-b723-d2e9c8bb3200",
   "metadata": {},
   "source": [
    "Vemos que muchas de las columnas tienen nulos y que como hay muchas que son listas, fechas u otro tipo de datos se han importado todas como object, vamos a parsear aquellas que sabemos que representan un número. Además, vemos que una columna, concretamente \"edition\", tiene 5000 valores de 52.500 siendo tan absolutamente pequeño que merecería la pena eliminarlo directamente, pero como eso se valora en otro apartado vamos a ser pacientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d490d45f-604c-4f33-9862-b5752db27120",
   "metadata": {},
   "source": [
    "Vamos a hacer las transformaciones de los enteros primero, pero como no podemos transformar un 'NaN' a entero vamos a poner estos valores faltantes a -5, ya que en ningún caso de nuestras variables pueden darse valores negativos. Y luego, los devolveremos a 'NaN'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a7f23-5ec8-48bd-b340-33c1fdd1dc5c",
   "metadata": {},
   "source": [
    "Aunque primero mejor comprobarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7df5c47-80cf-482d-b61e-09baa53b8048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52478.000000</td>\n",
       "      <td>5.247800e+04</td>\n",
       "      <td>51856.000000</td>\n",
       "      <td>5.247800e+04</td>\n",
       "      <td>52478.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.021878</td>\n",
       "      <td>1.787865e+04</td>\n",
       "      <td>92.231545</td>\n",
       "      <td>1.984023e+03</td>\n",
       "      <td>22.529003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.367146</td>\n",
       "      <td>1.039448e+05</td>\n",
       "      <td>5.990689</td>\n",
       "      <td>3.515314e+04</td>\n",
       "      <td>369.158541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.820000</td>\n",
       "      <td>3.410000e+02</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.030000</td>\n",
       "      <td>2.307000e+03</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.230000</td>\n",
       "      <td>9.380500e+03</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.870000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.048471e+06</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.993816e+06</td>\n",
       "      <td>30516.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating    numRatings  likedPercent      bbeScore      bbeVotes\n",
       "count  52478.000000  5.247800e+04  51856.000000  5.247800e+04  52478.000000\n",
       "mean       4.021878  1.787865e+04     92.231545  1.984023e+03     22.529003\n",
       "std        0.367146  1.039448e+05      5.990689  3.515314e+04    369.158541\n",
       "min        0.000000  0.000000e+00      0.000000  0.000000e+00     -4.000000\n",
       "25%        3.820000  3.410000e+02     90.000000  8.400000e+01      1.000000\n",
       "50%        4.030000  2.307000e+03     94.000000  9.700000e+01      1.000000\n",
       "75%        4.230000  9.380500e+03     96.000000  1.870000e+02      2.000000\n",
       "max        5.000000  7.048471e+06    100.000000  2.993816e+06  30516.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('libros.csv', header=0)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f39427-1d14-4045-89e1-07dea7e0bed8",
   "metadata": {},
   "source": [
    "Vemos que algunos valores de bbeVotes tienen valores negativos, ante lo que podemos sospechar que nuestro dataset contiene datos erróneos. Como no tenemos forma de comprobarlo, vamos a dejarlos, asumiendo que son reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "677c6201-5196-40f9-8c79-5942bf0491ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[['pages', 'bbeVotes', 'bbeScore', 'numRatings']] = X[['pages', 'bbeVotes', 'bbeScore', 'numRatings']].fillna(-5).astype(np.int64)"
   ]
  },
  {
   "attachments": {
    "50681563-7382-4b21-9c3b-ca62d05d001b.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "38b9d8b5-7f9a-4f8f-94e6-81d2f9b37192",
   "metadata": {},
   "source": [
    "![image.png](attachment:50681563-7382-4b21-9c3b-ca62d05d001b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd134c-bcbb-44d3-b8bd-8dc46c931827",
   "metadata": {},
   "source": [
    "Hemos decidido dejar este error porque siendo obvio que las páginas son un entero, vemos que uno de los valores que intentamos parsear a enteros es '1 pages'; ¡¡bienvenidos al magnífico mundo de la ciencia del dato!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b78ef06-1e38-40c7-9682-cb3661c50d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.pages = X[['pages']].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f091ec-abc9-4a88-a6f1-460214a3f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['bbeScore', 'numRatings','bbeVotes']] = X[['bbeScore', 'numRatings','bbeVotes']].fillna(-5).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d3b9d84-a00b-4e64-a9db-5780a3935a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   language          48672 non-null  object \n",
      " 1   genres            52478 non-null  object \n",
      " 2   characters        52478 non-null  object \n",
      " 3   bookFormat        51005 non-null  object \n",
      " 4   pages             50108 non-null  float64\n",
      " 5   publishDate       51598 non-null  object \n",
      " 6   firstPublishDate  31152 non-null  object \n",
      " 7   awards            52478 non-null  object \n",
      " 8   numRatings        52478 non-null  int64  \n",
      " 9   ratingsByStars    52478 non-null  object \n",
      " 10  likedPercent      51856 non-null  object \n",
      " 11  setting           52478 non-null  object \n",
      " 12  bbeScore          52478 non-null  int64  \n",
      " 13  bbeVotes          52478 non-null  int64  \n",
      " 14  price             38113 non-null  object \n",
      "dtypes: float64(1), int64(3), object(11)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X.replace(-5,np.NaN).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c411acd5-4b7b-44a3-8549-165ebaf2d51f",
   "metadata": {},
   "source": [
    "Pages queda al final como float porque han tenido que ser eliminados ciertos datos de tipo cadena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89fcc9c-78bb-40c9-a0e2-b353a044859d",
   "metadata": {},
   "source": [
    "Para terminar con esta parte transformaremos los que son float64 y veremos los estadísticos más útiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af0d630-3bf7-45fc-adcb-2fa856491484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X[['likedPercent', 'price']] = X[['likedPercent', 'price']].astype(np.float64)"
   ]
  },
  {
   "attachments": {
    "21bd350e-bad2-48ab-a29b-ce19801c56e9.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "44e55b23-deee-44b0-ab78-b3227545ddad",
   "metadata": {},
   "source": [
    "![image.png](attachment:21bd350e-bad2-48ab-a29b-ce19801c56e9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616a630-591b-4f8b-8f08-2c68bc3877c9",
   "metadata": {},
   "source": [
    "Otro error de un cariz parecido al anterior, vemos que en los números de más de tres cifras con decimales se usó el punto en los dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87ec12b2-4830-46ba-abc2-aa75b29f7e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5.09\n",
       "1        7.38\n",
       "2         NaN\n",
       "3         NaN\n",
       "4         2.1\n",
       "         ... \n",
       "52473     NaN\n",
       "52474     NaN\n",
       "52475    7.37\n",
       "52476    2.86\n",
       "52477    5.20\n",
       "Name: price, Length: 52478, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for elem in X.price:\n",
    "    partes = str(elem).split('.')\n",
    "    if len(partes) > 2:\n",
    "        aux = [partes[0],partes[1],\".\",partes[2]]\n",
    "        res.append(''.join(aux))\n",
    "    elif len(partes) == 2:\n",
    "        aux = [partes[0],\".\",partes[1]]\n",
    "        res.append(''.join(aux))\n",
    "    else:\n",
    "        if partes[0] != 'nan':\n",
    "            res.append(partes[0])\n",
    "        else:\n",
    "            res.append(np.nan)\n",
    "            \n",
    "X = X.drop('price', axis = 1)\n",
    "\n",
    "X['price'] = res\n",
    "X.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4be5c6f-b9fd-473d-8222-11eaa39343a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['likedPercent', 'price']] = X[['likedPercent', 'price']].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bdb21c5-25af-4be1-96f8-411a085568d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   language          48672 non-null  object \n",
      " 1   genres            52478 non-null  object \n",
      " 2   characters        52478 non-null  object \n",
      " 3   bookFormat        51005 non-null  object \n",
      " 4   pages             50108 non-null  float64\n",
      " 5   publishDate       51598 non-null  object \n",
      " 6   firstPublishDate  31152 non-null  object \n",
      " 7   awards            52478 non-null  object \n",
      " 8   numRatings        52478 non-null  int64  \n",
      " 9   ratingsByStars    52478 non-null  object \n",
      " 10  likedPercent      51856 non-null  float64\n",
      " 11  setting           52478 non-null  object \n",
      " 12  bbeScore          52478 non-null  int64  \n",
      " 13  bbeVotes          52478 non-null  int64  \n",
      " 14  price             38113 non-null  float64\n",
      "dtypes: float64(3), int64(3), object(9)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d911fee5-631e-47bd-91ea-e80500c77fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50108.000000</td>\n",
       "      <td>5.247800e+04</td>\n",
       "      <td>51856.000000</td>\n",
       "      <td>5.247800e+04</td>\n",
       "      <td>52478.000000</td>\n",
       "      <td>38113.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>328.664864</td>\n",
       "      <td>1.787865e+04</td>\n",
       "      <td>92.231545</td>\n",
       "      <td>1.984023e+03</td>\n",
       "      <td>22.529003</td>\n",
       "      <td>10.414949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>252.178359</td>\n",
       "      <td>1.039448e+05</td>\n",
       "      <td>5.990689</td>\n",
       "      <td>3.515314e+04</td>\n",
       "      <td>369.158541</td>\n",
       "      <td>60.213706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>3.410000e+02</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>304.000000</td>\n",
       "      <td>2.307000e+03</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>9.380500e+03</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.870000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14777.000000</td>\n",
       "      <td>7.048471e+06</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.993816e+06</td>\n",
       "      <td>30516.000000</td>\n",
       "      <td>8715.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pages    numRatings  likedPercent      bbeScore      bbeVotes  \\\n",
       "count  50108.000000  5.247800e+04  51856.000000  5.247800e+04  52478.000000   \n",
       "mean     328.664864  1.787865e+04     92.231545  1.984023e+03     22.529003   \n",
       "std      252.178359  1.039448e+05      5.990689  3.515314e+04    369.158541   \n",
       "min        0.000000  0.000000e+00      0.000000  0.000000e+00     -4.000000   \n",
       "25%      210.000000  3.410000e+02     90.000000  8.400000e+01      1.000000   \n",
       "50%      304.000000  2.307000e+03     94.000000  9.700000e+01      1.000000   \n",
       "75%      392.000000  9.380500e+03     96.000000  1.870000e+02      2.000000   \n",
       "max    14777.000000  7.048471e+06    100.000000  2.993816e+06  30516.000000   \n",
       "\n",
       "              price  \n",
       "count  38113.000000  \n",
       "mean      10.414949  \n",
       "std       60.213706  \n",
       "min        0.840000  \n",
       "25%        3.240000  \n",
       "50%        5.210000  \n",
       "75%        8.860000  \n",
       "max     8715.510000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f0494-21f7-4cad-8253-cdef770c0bf5",
   "metadata": {},
   "source": [
    "Libros con 0 páginas o votos negativos nos dan pistas de que eso son valores espurios, pero será mejor resolverlo en posteriores apartados. Aunque marcaremos los libros sin páginas como valores faltantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96f16f32-08cf-4794-992f-1104c970298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X.pages < 1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2ebfd9a-4f15-4c4b-a58d-5bc072f1ef43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49944.000000</td>\n",
       "      <td>5.231400e+04</td>\n",
       "      <td>51698.000000</td>\n",
       "      <td>5.231400e+04</td>\n",
       "      <td>52314.000000</td>\n",
       "      <td>38042.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>329.744093</td>\n",
       "      <td>1.792728e+04</td>\n",
       "      <td>92.232156</td>\n",
       "      <td>1.989860e+03</td>\n",
       "      <td>22.594602</td>\n",
       "      <td>10.372188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>251.886630</td>\n",
       "      <td>1.041035e+05</td>\n",
       "      <td>5.988560</td>\n",
       "      <td>3.520805e+04</td>\n",
       "      <td>369.734813</td>\n",
       "      <td>60.114667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>212.000000</td>\n",
       "      <td>3.430000e+02</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>8.400000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>304.000000</td>\n",
       "      <td>2.323500e+03</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>9.700000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>9.408750e+03</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.870000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14777.000000</td>\n",
       "      <td>7.048471e+06</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.993816e+06</td>\n",
       "      <td>30516.000000</td>\n",
       "      <td>8715.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pages    numRatings  likedPercent      bbeScore      bbeVotes  \\\n",
       "count  49944.000000  5.231400e+04  51698.000000  5.231400e+04  52314.000000   \n",
       "mean     329.744093  1.792728e+04     92.232156  1.989860e+03     22.594602   \n",
       "std      251.886630  1.041035e+05      5.988560  3.520805e+04    369.734813   \n",
       "min        2.000000  0.000000e+00      0.000000  0.000000e+00     -4.000000   \n",
       "25%      212.000000  3.430000e+02     90.000000  8.400000e+01      1.000000   \n",
       "50%      304.000000  2.323500e+03     94.000000  9.700000e+01      1.000000   \n",
       "75%      392.000000  9.408750e+03     96.000000  1.870000e+02      2.000000   \n",
       "max    14777.000000  7.048471e+06    100.000000  2.993816e+06  30516.000000   \n",
       "\n",
       "              price  \n",
       "count  38042.000000  \n",
       "mean      10.372188  \n",
       "std       60.114667  \n",
       "min        0.840000  \n",
       "25%        3.240000  \n",
       "50%        5.200000  \n",
       "75%        8.850000  \n",
       "max     8715.510000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3806e3d3-9e8a-4b9e-a166-794057686c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Series name: rating\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "52478 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 410.1 KB\n"
     ]
    }
   ],
   "source": [
    "y = y.astype(np.float64)\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1326465c-2113-4e9d-abab-0fb432624e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    52478.000000\n",
       "mean         4.021878\n",
       "std          0.367146\n",
       "min          0.000000\n",
       "25%          3.820000\n",
       "50%          4.030000\n",
       "75%          4.230000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da87307-36ce-4af3-b038-3828c49c07c3",
   "metadata": {},
   "source": [
    "#### 1.2.3. Tratamiento de variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38de453-3db7-4879-9e6a-17905b9aedb1",
   "metadata": {},
   "source": [
    "En este apartado trataremos las dos variables categóricas \"language\" y \"bookFormat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb262338-08aa-4bb8-ad77-d0b4a6421c17",
   "metadata": {},
   "source": [
    "Primero nos definimos unas funciones auxiliares para facilitar el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8522ee70-f355-4b53-a2dd-1d956de44a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mas_populares(lista, n):\n",
    "    unique_values = pd.unique(lista)\n",
    "    value_counts = pd.value_counts(lista)\n",
    "    unique_values_sorted = value_counts.sort_values(ascending=False).index\n",
    "    return unique_values_sorted[0:n]\n",
    "\n",
    "def mas_populares_df(X, col_name, n):\n",
    "    return mas_populares(X[col_name], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "348a8bc0-013f-4ecb-968b-6fbae3b5483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['English', 'Arabic', 'Spanish', 'French', 'German', 'Indonesian',\n",
      "       'Portuguese', 'Italian', 'Dutch', 'Turkish', 'Persian', 'Polish',\n",
      "       'Greek, Modern (1453-)', 'Russian', 'Japanese', 'Swedish', 'Romanian',\n",
      "       'Bengali', 'Malay', 'Bulgarian'],\n",
      "      dtype='object')\n",
      "Index(['Paperback', 'Hardcover', 'Kindle Edition', 'Mass Market Paperback',\n",
      "       'ebook', 'Audio CD', 'Nook', 'Unknown Binding', 'Audiobook',\n",
      "       'Trade Paperback'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(mas_populares_df(X, 'language', 20))\n",
    "print(mas_populares_df(X, 'bookFormat', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d725e-05e2-4989-86bd-e3cf316851a3",
   "metadata": {},
   "source": [
    "Vemos que entre los idimos más populares está el griego moderno, pero para que no figure en ese fromato lo transformaremos más adelante.\n",
    "<br><br>\n",
    "Entre los formato de libros, vemos que muchos son muy parecidos de una misma categoría; por ello, los agruparemos para no tener muchas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d8a77a0-70fa-4da7-87b2-a643c1c124ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   language          48554 non-null  object \n",
      " 1   genres            52314 non-null  object \n",
      " 2   characters        52314 non-null  object \n",
      " 3   bookFormat        50841 non-null  object \n",
      " 4   pages             49944 non-null  float64\n",
      " 5   publishDate       51435 non-null  object \n",
      " 6   firstPublishDate  31037 non-null  object \n",
      " 7   awards            52314 non-null  object \n",
      " 8   numRatings        52314 non-null  float64\n",
      " 9   ratingsByStars    52314 non-null  object \n",
      " 10  likedPercent      51698 non-null  float64\n",
      " 11  setting           52314 non-null  object \n",
      " 12  bbeScore          52314 non-null  float64\n",
      " 13  bbeVotes          52314 non-null  float64\n",
      " 14  price             38042 non-null  float64\n",
      "dtypes: float64(6), object(9)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67cb3e38-8a24-48cd-a3de-4c5ef91ab870",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['language'] = X['language'].where(X['language'].isin(mas_populares_df(X, 'language', 20)), np.nan)\n",
    "X['bookFormat'] = X['bookFormat'].where(X['bookFormat'].isin(mas_populares_df(X, 'bookFormat', 5)), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b791859f-2796-4a93-96bd-8ce555878cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   language          47811 non-null  object \n",
      " 1   genres            52314 non-null  object \n",
      " 2   characters        52314 non-null  object \n",
      " 3   bookFormat        49896 non-null  object \n",
      " 4   pages             49944 non-null  float64\n",
      " 5   publishDate       51435 non-null  object \n",
      " 6   firstPublishDate  31037 non-null  object \n",
      " 7   awards            52314 non-null  object \n",
      " 8   numRatings        52314 non-null  float64\n",
      " 9   ratingsByStars    52314 non-null  object \n",
      " 10  likedPercent      51698 non-null  float64\n",
      " 11  setting           52314 non-null  object \n",
      " 12  bbeScore          52314 non-null  float64\n",
      " 13  bbeVotes          52314 non-null  float64\n",
      " 14  price             38042 non-null  float64\n",
      "dtypes: float64(6), object(9)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbd604ea-ae42-4fac-84e9-b926969bec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['language'] = X['language'].replace('Greek, Modern (1453-)', 'Greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bfc9bb6-5cdf-4c42-ab3f-f659b17ec8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X['bookFormat'] = X['bookFormat'].replace('Kindle Edition', 'Digital')\n",
    "X['bookFormat'] = X['bookFormat'].replace('ebook', 'Digital')\n",
    "X['bookFormat'] = X['bookFormat'].replace('Nook', 'Digital')\n",
    "\n",
    "X['bookFormat'] = X['bookFormat'].replace('Mass Market Paperback', 'Paperback')\n",
    "X['bookFormat'] = X['bookFormat'].replace('Trade Paperback', 'Paperback')\n",
    "\n",
    "X['bookFormat'] = X['bookFormat'].replace('Audio CD', 'Audio')\n",
    "X['bookFormat'] = X['bookFormat'].replace('Audiobook', 'Audio')\n",
    "\n",
    "X['bookFormat'] = X['bookFormat'].replace('Unknown Binding', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86630041-c3eb-4fbe-b67d-a34f07bd5d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hardcover', 'Paperback', 'Digital', nan], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.bookFormat.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc230e-c93a-49d8-a4d7-69410bfc6481",
   "metadata": {},
   "source": [
    "Vemos que ya hemos terminado con este apartado, pasemos a las fechas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e82dc-616d-43b0-97bc-eae25c442a7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.2.4. Tratamiento de fechas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2635d2bd-79e5-42fd-bfc6-939b17333968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   publishDate       51435 non-null  object\n",
      " 1   firstPublishDate  31037 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 820.1+ KB\n"
     ]
    }
   ],
   "source": [
    "X[['publishDate', 'firstPublishDate']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2220e689-2e1e-42a8-9f9c-2034469bf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['firstPublishDate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e38c132b-dfff-4101-bb0e-85c8e0d731a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  09/14/08\n",
       "1                  09/28/04\n",
       "2                  05/23/06\n",
       "3                  10/10/00\n",
       "4                  09/06/06\n",
       "                ...        \n",
       "52473                   NaN\n",
       "52474       August 5th 2011\n",
       "52475       March 18th 2011\n",
       "52476    September 1st 2011\n",
       "52477          May 8th 2011\n",
       "Name: publishDate, Length: 52478, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['publishDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9e348f9-ea30-420a-9153-30629d9e020b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2008-09-14\n",
       "1       2004-09-28\n",
       "2       2006-05-23\n",
       "3       2000-10-10\n",
       "4       2006-09-06\n",
       "           ...    \n",
       "52473          NaT\n",
       "52474   2011-08-05\n",
       "52475   2011-03-18\n",
       "52476   2011-09-01\n",
       "52477   2011-05-08\n",
       "Name: publishDate, Length: 52478, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['publishDate'] = pd.to_datetime(X['publishDate'], errors='coerce')\n",
    "X['publishDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25ce973e-45cf-4acf-85ec-32942b8dbef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>genres</th>\n",
       "      <th>characters</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>pages</th>\n",
       "      <th>awards</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>setting</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "      <th>publishYear</th>\n",
       "      <th>publishMonth</th>\n",
       "      <th>publishDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n",
       "      <td>['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>374.0</td>\n",
       "      <td>['Locus Award Nominee for Best Young Adult Boo...</td>\n",
       "      <td>6376780.0</td>\n",
       "      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>['District 12, Panem', 'Capitol, Panem', 'Pane...</td>\n",
       "      <td>2993816.0</td>\n",
       "      <td>30516.0</td>\n",
       "      <td>5.09</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                             genres  \\\n",
       "0  English  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...   \n",
       "\n",
       "                                          characters bookFormat  pages  \\\n",
       "0  ['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...  Hardcover  374.0   \n",
       "\n",
       "                                              awards  numRatings  \\\n",
       "0  ['Locus Award Nominee for Best Young Adult Boo...   6376780.0   \n",
       "\n",
       "                                      ratingsByStars  likedPercent  \\\n",
       "0  ['3444695', '1921313', '745221', '171994', '93...          96.0   \n",
       "\n",
       "                                             setting   bbeScore  bbeVotes  \\\n",
       "0  ['District 12, Panem', 'Capitol, Panem', 'Pane...  2993816.0   30516.0   \n",
       "\n",
       "   price  publishYear  publishMonth  publishDay  \n",
       "0   5.09       2008.0           9.0        14.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['publishYear'] = X['publishDate'].dt.year\n",
    "X['publishMonth'] = X['publishDate'].dt.month\n",
    "X['publishDay'] = X['publishDate'].dt.day\n",
    "\n",
    "X = X.drop(['publishDate'], axis=1)\n",
    "\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0594521-f675-46ba-83ec-cc5696bf4dcf",
   "metadata": {},
   "source": [
    "#### 1.2.5. Tratamiento de variables con formato lista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d28197-786b-4c14-ae95-c07817c2630d",
   "metadata": {},
   "source": [
    "Vamos a crear un método que transforme las variables con una cadena semejante a una lista en éstas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "527feeb3-203f-4f66-8e89-aa911321445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def trans_list(nom_col, X):\n",
    "    res = []\n",
    "    for elem in X[nom_col]:\n",
    "        if pd.isna(elem):\n",
    "                res.append(np.nan)\n",
    "        else:\n",
    "            res.append(ast.literal_eval(elem))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac3fad-d0f7-42e2-98c1-963a467f2e3a",
   "metadata": {},
   "source": [
    "Primero, vamos a decidir qué variables queremos preprocesar y cuales eliminar porque la información que nos pueden aportar no sea suficiente. Eliminemos estas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b270201-8e5e-40d7-a396-ae88cd0c139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>genres</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>pages</th>\n",
       "      <th>awards</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>ratingsByStars</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "      <th>publishYear</th>\n",
       "      <th>publishMonth</th>\n",
       "      <th>publishDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>374.0</td>\n",
       "      <td>['Locus Award Nominee for Best Young Adult Boo...</td>\n",
       "      <td>6376780.0</td>\n",
       "      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2993816.0</td>\n",
       "      <td>30516.0</td>\n",
       "      <td>5.09</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>['Fantasy', 'Young Adult', 'Fiction', 'Magic',...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>870.0</td>\n",
       "      <td>['Bram Stoker Award for Works for Young Reader...</td>\n",
       "      <td>2507623.0</td>\n",
       "      <td>['1593642', '637516', '222366', '39573', '14526']</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2632233.0</td>\n",
       "      <td>26923.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>324.0</td>\n",
       "      <td>['Pulitzer Prize for Fiction (1961)', 'Audie A...</td>\n",
       "      <td>4501075.0</td>\n",
       "      <td>['2363896', '1333153', '573280', '149952', '80...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2269402.0</td>\n",
       "      <td>23328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>['Classics', 'Fiction', 'Romance', 'Historical...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>279.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2998241.0</td>\n",
       "      <td>['1617567', '816659', '373311', '113934', '767...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1983116.0</td>\n",
       "      <td>20452.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>['Young Adult', 'Fantasy', 'Romance', 'Vampire...</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>501.0</td>\n",
       "      <td>['Georgia Peach Book Award (2007)', 'Buxtehude...</td>\n",
       "      <td>4964519.0</td>\n",
       "      <td>['1751460', '1113682', '1008686', '542017', '5...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1459448.0</td>\n",
       "      <td>14874.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                             genres bookFormat  \\\n",
       "0  English  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...  Hardcover   \n",
       "1  English  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...  Paperback   \n",
       "2  English  ['Classics', 'Fiction', 'Historical Fiction', ...  Paperback   \n",
       "3  English  ['Classics', 'Fiction', 'Romance', 'Historical...  Paperback   \n",
       "4  English  ['Young Adult', 'Fantasy', 'Romance', 'Vampire...  Paperback   \n",
       "\n",
       "   pages                                             awards  numRatings  \\\n",
       "0  374.0  ['Locus Award Nominee for Best Young Adult Boo...   6376780.0   \n",
       "1  870.0  ['Bram Stoker Award for Works for Young Reader...   2507623.0   \n",
       "2  324.0  ['Pulitzer Prize for Fiction (1961)', 'Audie A...   4501075.0   \n",
       "3  279.0                                                 []   2998241.0   \n",
       "4  501.0  ['Georgia Peach Book Award (2007)', 'Buxtehude...   4964519.0   \n",
       "\n",
       "                                      ratingsByStars  likedPercent   bbeScore  \\\n",
       "0  ['3444695', '1921313', '745221', '171994', '93...          96.0  2993816.0   \n",
       "1  ['1593642', '637516', '222366', '39573', '14526']          98.0  2632233.0   \n",
       "2  ['2363896', '1333153', '573280', '149952', '80...          95.0  2269402.0   \n",
       "3  ['1617567', '816659', '373311', '113934', '767...          94.0  1983116.0   \n",
       "4  ['1751460', '1113682', '1008686', '542017', '5...          78.0  1459448.0   \n",
       "\n",
       "   bbeVotes  price  publishYear  publishMonth  publishDay  \n",
       "0   30516.0   5.09       2008.0           9.0        14.0  \n",
       "1   26923.0   7.38       2004.0           9.0        28.0  \n",
       "2   23328.0    NaN       2006.0           5.0        23.0  \n",
       "3   20452.0    NaN       2000.0          10.0        10.0  \n",
       "4   14874.0   2.10       2006.0           9.0         6.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop(['characters', 'setting'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63158691-7395-4dc3-86be-283a5020b487",
   "metadata": {},
   "source": [
    "Y ahora transformemos las que sí que deseamos transformar a listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5d75ba0-5ef8-423a-a86c-7af7f272706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trans_list('genres', X)\n",
    "X = X.drop('genres', axis = 1)\n",
    "X['genres'] = res\n",
    "\n",
    "res = trans_list('ratingsByStars', X)\n",
    "X = X.drop('ratingsByStars', axis = 1)\n",
    "X['ratingsByStars'] = res\n",
    "\n",
    "res = trans_list('awards', X)\n",
    "X = X.drop('awards', axis = 1)\n",
    "X['awards'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efb0a047-a603-4e74-b7f4-6b9ab92c5ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Young Adult'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.genres[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89077cf8-3120-4e4b-a6b2-385739587623",
   "metadata": {},
   "source": [
    "Ahora, teniendo ya las listas en su formato correspondiente, vamos a tratar cada una de ellas:\n",
    "   - 'ratingsByStars': Tendría sentido separar cada uno de los cinco elementos en cinco columnas distintas; una para las cinco estrellas, otra para las cuatro y así hasta las valoraciones de una estrella.\n",
    "   - 'awards': vamos a contar el número de premios que tiene, si que estaríamos sesgando ligeramente el resultado porque no valen lo mismo unos premios que otros; pero no teniendo un conocimiento sobre éstos es la mejor solución.\n",
    "   - 'genre': con esta lista, lo mejor sería contar los 20 géneros más populares y dedicar en un oneHot encoding una columna a cada género, aquellos que no tengan género o sus generos no estén en esa lista tendrán todo ceros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a5f30-c21d-4ce1-ad76-85ff2051c495",
   "metadata": {},
   "source": [
    "ratingsByStars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9e6dd03-14c6-4d58-827c-1e76e6937ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"ratingsByStars\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48aff96-59e0-4c6d-9516-d952fc5f5e72",
   "metadata": {},
   "source": [
    "Transformamos los nulos a listas con 0s para que no nos den problemas, esto lo haremos con las tres listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d4e1d1a-1e03-4ef9-9652-d9e379c1bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"ratingsByStars\"] = X[\"ratingsByStars\"].apply(lambda x: [0, 0, 0, 0, 0] if pd.isna(np.array(x)).any() or not x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05e79564-47f4-4a27-a034-bc31d01cd6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"ratingsByStars\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45e75698-cbb0-4b9b-bf14-57a53655e72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>pages</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "      <th>publishYear</th>\n",
       "      <th>publishMonth</th>\n",
       "      <th>publishDay</th>\n",
       "      <th>genres</th>\n",
       "      <th>awards</th>\n",
       "      <th>5Stars</th>\n",
       "      <th>4Stars</th>\n",
       "      <th>3Stars</th>\n",
       "      <th>2Stars</th>\n",
       "      <th>1Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>374.0</td>\n",
       "      <td>6376780.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2993816.0</td>\n",
       "      <td>30516.0</td>\n",
       "      <td>5.09</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[Young Adult, Fiction, Dystopia, Fantasy, Scie...</td>\n",
       "      <td>[Locus Award Nominee for Best Young Adult Book...</td>\n",
       "      <td>3444695</td>\n",
       "      <td>1921313</td>\n",
       "      <td>745221</td>\n",
       "      <td>171994</td>\n",
       "      <td>93557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>870.0</td>\n",
       "      <td>2507623.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2632233.0</td>\n",
       "      <td>26923.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[Fantasy, Young Adult, Fiction, Magic, Childre...</td>\n",
       "      <td>[Bram Stoker Award for Works for Young Readers...</td>\n",
       "      <td>1593642</td>\n",
       "      <td>637516</td>\n",
       "      <td>222366</td>\n",
       "      <td>39573</td>\n",
       "      <td>14526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>324.0</td>\n",
       "      <td>4501075.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2269402.0</td>\n",
       "      <td>23328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>[Classics, Fiction, Historical Fiction, School...</td>\n",
       "      <td>[Pulitzer Prize for Fiction (1961), Audie Awar...</td>\n",
       "      <td>2363896</td>\n",
       "      <td>1333153</td>\n",
       "      <td>573280</td>\n",
       "      <td>149952</td>\n",
       "      <td>80794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2998241.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1983116.0</td>\n",
       "      <td>20452.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[Classics, Fiction, Romance, Historical Fictio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1617567</td>\n",
       "      <td>816659</td>\n",
       "      <td>373311</td>\n",
       "      <td>113934</td>\n",
       "      <td>76770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>501.0</td>\n",
       "      <td>4964519.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1459448.0</td>\n",
       "      <td>14874.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[Young Adult, Fantasy, Romance, Vampires, Fict...</td>\n",
       "      <td>[Georgia Peach Book Award (2007), Buxtehuder B...</td>\n",
       "      <td>1751460</td>\n",
       "      <td>1113682</td>\n",
       "      <td>1008686</td>\n",
       "      <td>542017</td>\n",
       "      <td>548674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language bookFormat  pages  numRatings  likedPercent   bbeScore  bbeVotes  \\\n",
       "0  English  Hardcover  374.0   6376780.0          96.0  2993816.0   30516.0   \n",
       "1  English  Paperback  870.0   2507623.0          98.0  2632233.0   26923.0   \n",
       "2  English  Paperback  324.0   4501075.0          95.0  2269402.0   23328.0   \n",
       "3  English  Paperback  279.0   2998241.0          94.0  1983116.0   20452.0   \n",
       "4  English  Paperback  501.0   4964519.0          78.0  1459448.0   14874.0   \n",
       "\n",
       "   price  publishYear  publishMonth  publishDay  \\\n",
       "0   5.09       2008.0           9.0        14.0   \n",
       "1   7.38       2004.0           9.0        28.0   \n",
       "2    NaN       2006.0           5.0        23.0   \n",
       "3    NaN       2000.0          10.0        10.0   \n",
       "4   2.10       2006.0           9.0         6.0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [Young Adult, Fiction, Dystopia, Fantasy, Scie...   \n",
       "1  [Fantasy, Young Adult, Fiction, Magic, Childre...   \n",
       "2  [Classics, Fiction, Historical Fiction, School...   \n",
       "3  [Classics, Fiction, Romance, Historical Fictio...   \n",
       "4  [Young Adult, Fantasy, Romance, Vampires, Fict...   \n",
       "\n",
       "                                              awards   5Stars   4Stars  \\\n",
       "0  [Locus Award Nominee for Best Young Adult Book...  3444695  1921313   \n",
       "1  [Bram Stoker Award for Works for Young Readers...  1593642   637516   \n",
       "2  [Pulitzer Prize for Fiction (1961), Audie Awar...  2363896  1333153   \n",
       "3                                                 []  1617567   816659   \n",
       "4  [Georgia Peach Book Award (2007), Buxtehuder B...  1751460  1113682   \n",
       "\n",
       "    3Stars  2Stars   1Star  \n",
       "0   745221  171994   93557  \n",
       "1   222366   39573   14526  \n",
       "2   573280  149952   80794  \n",
       "3   373311  113934   76770  \n",
       "4  1008686  542017  548674  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(X[\"ratingsByStars\"].to_list(), columns=['5Stars', '4Stars', '3Stars', '2Stars', '1Star'], index = X.index)\n",
    "X = X.drop('ratingsByStars', axis = 1)\n",
    "X = pd.concat([X, res], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edcde58a-9f25-4cb9-809f-1c06ce1b9815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   language      47811 non-null  object \n",
      " 1   bookFormat    49896 non-null  object \n",
      " 2   pages         49944 non-null  float64\n",
      " 3   numRatings    52314 non-null  float64\n",
      " 4   likedPercent  51698 non-null  float64\n",
      " 5   bbeScore      52314 non-null  float64\n",
      " 6   bbeVotes      52314 non-null  float64\n",
      " 7   price         38042 non-null  float64\n",
      " 8   publishYear   50532 non-null  float64\n",
      " 9   publishMonth  50532 non-null  float64\n",
      " 10  publishDay    50532 non-null  float64\n",
      " 11  genres        52314 non-null  object \n",
      " 12  awards        52314 non-null  object \n",
      " 13  5Stars        52478 non-null  object \n",
      " 14  4Stars        52478 non-null  object \n",
      " 15  3Stars        52478 non-null  object \n",
      " 16  2Stars        52478 non-null  object \n",
      " 17  1Star         52478 non-null  object \n",
      "dtypes: float64(9), object(9)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e9df5-34ad-405d-95d5-8da9d7e4217c",
   "metadata": {},
   "source": [
    "awards:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c2767-9a38-4996-a137-490851046ae9",
   "metadata": {},
   "source": [
    "Procedemos con la columna \"awards\", en este vamos a contar cuantos premios tiene y reemplazar ese valor por la lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18b749e7-a56c-4b74-bd24-dd46f87edb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"awards\"] = X[\"awards\"].apply(lambda x: [] if pd.isna(np.array(x)).any() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b0dd402-8d3f-4a36-9efd-265bbf29dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [len(x) for x in X.awards]\n",
    "X[\"awards\"] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8b4a32b-03d5-4f44-8659-bab9b3b2e856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        41\n",
       "1         9\n",
       "2         4\n",
       "3         0\n",
       "4        25\n",
       "         ..\n",
       "52473     0\n",
       "52474     0\n",
       "52475     1\n",
       "52476     0\n",
       "52477     0\n",
       "Name: awards, Length: 52478, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.awards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a88d8-f608-42ca-bda9-3474c50fed6b",
   "metadata": {},
   "source": [
    "genre:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42419e1e-ba88-4932-8f58-afa5c5994950",
   "metadata": {},
   "source": [
    "Para el género calculamos las 20 categorias más populares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bd7aa24-6681-4100-8ad0-54bcb8a3e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mas_populares_lista(X, col_name, n):\n",
    "    lista_global = [subelemento for elemento in X[\"genres\"].to_list() if not pd.isna(np.array(elemento)).any() for subelemento in elemento]\n",
    "    return mas_populares(lista_global, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6be02d40-f07c-49a6-bf7f-2abc369a74ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 602 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Fiction', 'Romance', 'Fantasy', 'Young Adult', 'Contemporary', 'Adult',\n",
       "       'Nonfiction', 'Novels', 'Mystery', 'Historical Fiction', 'Audiobook',\n",
       "       'Classics', 'Adventure', 'Historical', 'Paranormal', 'Literature',\n",
       "       'Science Fiction', 'Childrens', 'Thriller', 'Magic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mas_populares_lista(X, 'genres', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211d7ab-45ac-4f69-8d4c-44104256c3b5",
   "metadata": {},
   "source": [
    "Casi lo tenemos, pero como entre todas ellas hay una que es \"Audiobook\" vamos a buscar 21 y cambiarla por esa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2798f6ec-4ba5-41d0-a106-a182ff227a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pop = mas_populares_lista(X, 'genres', 21).delete(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be3deefb-b7d7-4152-b5c8-2c1b2e5c72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"genres\"] = X[\"genres\"].apply(lambda x: [] if pd.isna(np.array(x)).any() else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73e4f62b-6671-4fb7-83a8-801b50c65b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"genres\"] = X['genres'].apply(lambda x: [elem for elem in x if elem in gen_pop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4028f58-234d-4d82-a60f-2ba33ba665bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   language      47811 non-null  object \n",
      " 1   bookFormat    49896 non-null  object \n",
      " 2   pages         49944 non-null  float64\n",
      " 3   numRatings    52314 non-null  float64\n",
      " 4   likedPercent  51698 non-null  float64\n",
      " 5   bbeScore      52314 non-null  float64\n",
      " 6   bbeVotes      52314 non-null  float64\n",
      " 7   price         38042 non-null  float64\n",
      " 8   publishYear   50532 non-null  float64\n",
      " 9   publishMonth  50532 non-null  float64\n",
      " 10  publishDay    50532 non-null  float64\n",
      " 11  genres        52478 non-null  object \n",
      " 12  awards        52478 non-null  int64  \n",
      " 13  5Stars        52478 non-null  object \n",
      " 14  4Stars        52478 non-null  object \n",
      " 15  3Stars        52478 non-null  object \n",
      " 16  2Stars        52478 non-null  object \n",
      " 17  1Star         52478 non-null  object \n",
      "dtypes: float64(9), int64(1), object(8)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a92b664-6777-4468-9827-7222d0049cdb",
   "metadata": {},
   "source": [
    "Ya solo nos falta cambiar el formato de las columnas de las estrellas a \"int64\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06c84697-2bcb-4bfd-bcb6-bf755227ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['5Stars', '4Stars', '3Stars', '2Stars', '1Star']] = X[['5Stars', '4Stars', '3Stars', '2Stars', '1Star']].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c0092c8-ca27-4f60-9b4e-69a218110961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52478 entries, 0 to 52477\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   language      47811 non-null  object \n",
      " 1   bookFormat    49896 non-null  object \n",
      " 2   pages         49944 non-null  float64\n",
      " 3   numRatings    52314 non-null  float64\n",
      " 4   likedPercent  51698 non-null  float64\n",
      " 5   bbeScore      52314 non-null  float64\n",
      " 6   bbeVotes      52314 non-null  float64\n",
      " 7   price         38042 non-null  float64\n",
      " 8   publishYear   50532 non-null  float64\n",
      " 9   publishMonth  50532 non-null  float64\n",
      " 10  publishDay    50532 non-null  float64\n",
      " 11  genres        52478 non-null  object \n",
      " 12  awards        52478 non-null  int64  \n",
      " 13  5Stars        52478 non-null  int64  \n",
      " 14  4Stars        52478 non-null  int64  \n",
      " 15  3Stars        52478 non-null  int64  \n",
      " 16  2Stars        52478 non-null  int64  \n",
      " 17  1Star         52478 non-null  int64  \n",
      "dtypes: float64(9), int64(6), object(3)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1653b819-3be9-447d-a0fa-dcaf1c3075de",
   "metadata": {},
   "source": [
    "Y con esto habríamos acabado todo el apartado de preprocesado, que vemos que no es poco. Pero antes, para poder realizar los apartados posteriores, vamos a hacer un OneHot encoding sobre los géneros, para tener 20 columnas para cada género y no una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4812d14d-a15c-49c3-abda-90f5844583ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adult</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Childrens</th>\n",
       "      <th>Classics</th>\n",
       "      <th>Contemporary</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>Historical</th>\n",
       "      <th>Historical Fiction</th>\n",
       "      <th>Humor</th>\n",
       "      <th>Literature</th>\n",
       "      <th>Magic</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Nonfiction</th>\n",
       "      <th>Novels</th>\n",
       "      <th>Paranormal</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Young Adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adult  Adventure  Childrens  Classics  Contemporary  Fantasy  Fiction  \\\n",
       "0      0          1          0         0             0        1        1   \n",
       "1      0          1          1         1             0        1        1   \n",
       "2      0          0          0         1             0        0        1   \n",
       "3      1          0          0         1             0        0        1   \n",
       "4      0          0          0         0             0        1        1   \n",
       "\n",
       "   Historical  Historical Fiction  Humor  Literature  Magic  Mystery  \\\n",
       "0           0                   0      0           0      0        0   \n",
       "1           0                   0      0           0      1        0   \n",
       "2           1                   1      0           1      0        0   \n",
       "3           1                   1      0           1      0        0   \n",
       "4           0                   0      0           0      0        0   \n",
       "\n",
       "   Nonfiction  Novels  Paranormal  Romance  Science Fiction  Thriller  \\\n",
       "0           0       0           0        1                1         0   \n",
       "1           0       0           0        0                0         0   \n",
       "2           0       1           0        0                0         0   \n",
       "3           0       1           0        1                0         0   \n",
       "4           0       0           1        1                0         0   \n",
       "\n",
       "   Young Adult  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            0  \n",
       "4            1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "res = pd.DataFrame(mlb.fit_transform(X.genres),\n",
    "                   columns=mlb.classes_,\n",
    "                   index=X.index)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5271f1b-c971-4893-a19c-650b6968241d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>pages</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "      <th>publishYear</th>\n",
       "      <th>publishMonth</th>\n",
       "      <th>...</th>\n",
       "      <th>Literature</th>\n",
       "      <th>Magic</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Nonfiction</th>\n",
       "      <th>Novels</th>\n",
       "      <th>Paranormal</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Young Adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>374.0</td>\n",
       "      <td>6376780.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2993816.0</td>\n",
       "      <td>30516.0</td>\n",
       "      <td>5.09</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>870.0</td>\n",
       "      <td>2507623.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2632233.0</td>\n",
       "      <td>26923.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>324.0</td>\n",
       "      <td>4501075.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2269402.0</td>\n",
       "      <td>23328.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2998241.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1983116.0</td>\n",
       "      <td>20452.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>501.0</td>\n",
       "      <td>4964519.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1459448.0</td>\n",
       "      <td>14874.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  language bookFormat  pages  numRatings  likedPercent   bbeScore  bbeVotes  \\\n",
       "0  English  Hardcover  374.0   6376780.0          96.0  2993816.0   30516.0   \n",
       "1  English  Paperback  870.0   2507623.0          98.0  2632233.0   26923.0   \n",
       "2  English  Paperback  324.0   4501075.0          95.0  2269402.0   23328.0   \n",
       "3  English  Paperback  279.0   2998241.0          94.0  1983116.0   20452.0   \n",
       "4  English  Paperback  501.0   4964519.0          78.0  1459448.0   14874.0   \n",
       "\n",
       "   price  publishYear  publishMonth  ...  Literature  Magic  Mystery  \\\n",
       "0   5.09       2008.0           9.0  ...           0      0        0   \n",
       "1   7.38       2004.0           9.0  ...           0      1        0   \n",
       "2    NaN       2006.0           5.0  ...           1      0        0   \n",
       "3    NaN       2000.0          10.0  ...           1      0        0   \n",
       "4   2.10       2006.0           9.0  ...           0      0        0   \n",
       "\n",
       "   Nonfiction  Novels  Paranormal  Romance  Science Fiction  Thriller  \\\n",
       "0           0       0           0        1                1         0   \n",
       "1           0       0           0        0                0         0   \n",
       "2           0       1           0        0                0         0   \n",
       "3           0       1           0        1                0         0   \n",
       "4           0       0           1        1                0         0   \n",
       "\n",
       "   Young Adult  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            0  \n",
       "4            1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop('genres', axis = 1)\n",
    "X = pd.concat([X, res], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41159cd2-330b-48a3-b6b3-5ae6e09bc687",
   "metadata": {},
   "source": [
    "#### 1.2.6. Eliminación de registros inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7421857e-4966-450e-b82a-405d8f2b1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4068ba7-728a-4ad3-8077-189c075d4e5a",
   "metadata": {},
   "source": [
    "Antes hemos notado que ciertos valores podrían ser espurios. Concretamente, aquellos de la columna `'bbeVotes'` que tienen valores menores que 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "935d7219-f39d-4e32-8e7a-d64bd53190e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().loc['min','bbeVotes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26164cb-0d1d-4e57-8466-0f3973b4d8ca",
   "metadata": {},
   "source": [
    "Además, también nos podemos fijar en que no todos los valores de la variable `'rating'` están entre 1 y 5 (posibles evaluaciones al tratar medias de puntuaciones en el intervalo [1,5])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95b635d4-cdc5-4b79-aa16-09154c36dd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mínimo: 0.0\n",
      "Máximo: 5.0\n"
     ]
    }
   ],
   "source": [
    "print('Mínimo:', df['rating'].min())\n",
    "print('Máximo:', df['rating'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192f30a-baa0-421d-985a-7cd2c83482e9",
   "metadata": {},
   "source": [
    "Hay valores que bajan hasta 0.0. Esto se debe a que la página registra con este valor aquellos registros que no tienen votaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8fb9691-1d2f-4966-a84b-2e40bc98e90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'bookFormat', 'pages', 'numRatings', 'likedPercent',\n",
       "       'bbeScore', 'bbeVotes', 'price', 'publishYear', 'publishMonth',\n",
       "       'publishDay', 'awards', '5Stars', '4Stars', '3Stars', '2Stars', '1Star',\n",
       "       'Adult', 'Adventure', 'Childrens', 'Classics', 'Contemporary',\n",
       "       'Fantasy', 'Fiction', 'Historical', 'Historical Fiction', 'Humor',\n",
       "       'Literature', 'Magic', 'Mystery', 'Nonfiction', 'Novels', 'Paranormal',\n",
       "       'Romance', 'Science Fiction', 'Thriller', 'Young Adult', 'rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27178297-23c3-4170-b12e-1695a99e0dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17907</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18618</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       numRatings  likedPercent\n",
       "8321          0.0           NaN\n",
       "17834         0.0           NaN\n",
       "17907         0.0           NaN\n",
       "18197         0.0           NaN\n",
       "18618         0.0           NaN"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rating'] == 0][['numRatings', 'likedPercent']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27790d-f50c-4e69-9f97-5fcbf9874952",
   "metadata": {},
   "source": [
    "Eliminamos estos registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c66f824-c1c7-4427-81f8-a94e68fc8e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52478, 38)\n",
      "(52191, 38)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df[(df['rating'] != 0) & (df['bbeVotes'] >= 0)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2ef1cb5-a75f-4c85-893d-5ecd2996ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52191, 37) (52191,)\n"
     ]
    }
   ],
   "source": [
    "# Separamos explicativas de explicada\n",
    "\n",
    "X, y = df.drop('rating', axis=1), df.rating\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5495ad-7cb2-4818-8381-a315b3349288",
   "metadata": {},
   "source": [
    "Finalmente, vamos a exportar el dataset, para poder trabajar a partir de aquí de una mejor manera. Por cuestiones de claridad vamos a cambiar el nombre de la variable objetivo por `'target'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73745fff-03c7-458c-90a0-7c68f7a76b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['target'] = y.values\n",
    "X.to_csv('libros_preprocesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3db71e65-8d70-4ced-a01a-d24fd5453356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52191, 37) (52191,)\n"
     ]
    }
   ],
   "source": [
    "X, y = X.drop('target', axis=1), X.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36160f42-d6f4-4f50-995d-286f14751d88",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feefe967-52b1-4822-b3c0-16b5c01ea5eb",
   "metadata": {},
   "source": [
    "Primero, vamos a cargar los datos limpios, para no tener que ejecutar todo lo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73e0f870-aff2-47e2-9781-dcbd85f33e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52191, 38)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('libros_preprocesado.csv', header=0, index_col=0)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99249e2a-1dde-431e-b61a-4c845d42367a",
   "metadata": {},
   "source": [
    "Para limpiar los datos, vamos a eliminar las columnas que contengan un único valor y a estudiar aquellas que tengan un bajo número de valores diferentes o una baja varianza. También vamos a eliminar las filas repetidas.También analizaremos tanto los valores nulos, realizando el borrado o las imputaciones correspondientes, como los outliers, aplicando las técnicas estudiadas en clase.\n",
    "<br><br>\n",
    "Después, se aplicarán técnicas en esos datos que implicarán codificar, escalar y transformar su distribución, para terminar aplicando \"features engineering\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec9bf3-e453-4127-8435-13c4754f491c",
   "metadata": {},
   "source": [
    "### 2.1. Limpieza básica de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596be0c-5694-4e1d-8fd7-672e3cdd8563",
   "metadata": {},
   "source": [
    "#### 2.1.1. Valores únicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e0e0d-2a6a-45e2-8e6b-7e30ee1625b1",
   "metadata": {},
   "source": [
    "Primero, para identificar los valores únicos, vamos a comprobar para cada columna cuantos tiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1345830-6200-43f5-aa00-94547b00ab3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language                 20\n",
       "bookFormat                3\n",
       "pages                  1362\n",
       "numRatings            19326\n",
       "likedPercent             66\n",
       "bbeScore               3540\n",
       "bbeVotes                645\n",
       "price                  3645\n",
       "publishYear             126\n",
       "publishMonth             12\n",
       "publishDay               31\n",
       "awards                   27\n",
       "5Stars                12883\n",
       "4Stars                12470\n",
       "3Stars                 9680\n",
       "2Stars                 5001\n",
       "1Star                  3226\n",
       "Adult                     2\n",
       "Adventure                 2\n",
       "Childrens                 2\n",
       "Classics                  2\n",
       "Contemporary              2\n",
       "Fantasy                   2\n",
       "Fiction                   2\n",
       "Historical                2\n",
       "Historical Fiction        2\n",
       "Humor                     2\n",
       "Literature                2\n",
       "Magic                     2\n",
       "Mystery                   2\n",
       "Nonfiction                2\n",
       "Novels                    2\n",
       "Paranormal                2\n",
       "Romance                   2\n",
       "Science Fiction           2\n",
       "Thriller                  2\n",
       "Young Adult               2\n",
       "target                  260\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f546fda-17d2-44bb-89fd-d1f871f7fc84",
   "metadata": {},
   "source": [
    "Tenemos las columnas a las que les hemos aplicado el OneHot encoding que tienen únicamente 2 valores, pero eso es normal; a parte de estas variables, ninguna numérica tienen pocos valores como para ser eliminada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d85f9-03eb-4833-8e1c-847cbb7bac62",
   "metadata": {},
   "source": [
    "#### 2.1.2. Baja variedad de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e18ba-57fe-4929-928d-1f76f384ebea",
   "metadata": {},
   "source": [
    "Para llevar a cabo la identificación de las variables que tienen una baja variedad de valores, mostremos para cada una el número de valores únicos que toma y el porcentaje que supone respecto al total de registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cfdca244-4925-4949-9e93-568fcca5deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 21 \t 0.0% \t language\n",
      "1 \t 4 \t 0.0% \t bookFormat\n",
      "2 \t 1363 \t 2.6% \t pages\n",
      "3 \t 19326 \t 37.0% \t numRatings\n",
      "4 \t 67 \t 0.1% \t likedPercent\n",
      "5 \t 3540 \t 6.8% \t bbeScore\n",
      "6 \t 645 \t 1.2% \t bbeVotes\n",
      "7 \t 3646 \t 7.0% \t price\n",
      "8 \t 127 \t 0.2% \t publishYear\n",
      "9 \t 13 \t 0.0% \t publishMonth\n",
      "10 \t 32 \t 0.1% \t publishDay\n",
      "11 \t 27 \t 0.1% \t awards\n",
      "12 \t 12883 \t 24.7% \t 5Stars\n",
      "13 \t 12470 \t 23.9% \t 4Stars\n",
      "14 \t 9680 \t 18.5% \t 3Stars\n",
      "15 \t 5001 \t 9.6% \t 2Stars\n",
      "16 \t 3226 \t 6.2% \t 1Star\n",
      "17 \t 2 \t 0.0% \t Adult\n",
      "18 \t 2 \t 0.0% \t Adventure\n",
      "19 \t 2 \t 0.0% \t Childrens\n",
      "20 \t 2 \t 0.0% \t Classics\n",
      "21 \t 2 \t 0.0% \t Contemporary\n",
      "22 \t 2 \t 0.0% \t Fantasy\n",
      "23 \t 2 \t 0.0% \t Fiction\n",
      "24 \t 2 \t 0.0% \t Historical\n",
      "25 \t 2 \t 0.0% \t Historical Fiction\n",
      "26 \t 2 \t 0.0% \t Humor\n",
      "27 \t 2 \t 0.0% \t Literature\n",
      "28 \t 2 \t 0.0% \t Magic\n",
      "29 \t 2 \t 0.0% \t Mystery\n",
      "30 \t 2 \t 0.0% \t Nonfiction\n",
      "31 \t 2 \t 0.0% \t Novels\n",
      "32 \t 2 \t 0.0% \t Paranormal\n",
      "33 \t 2 \t 0.0% \t Romance\n",
      "34 \t 2 \t 0.0% \t Science Fiction\n",
      "35 \t 2 \t 0.0% \t Thriller\n",
      "36 \t 2 \t 0.0% \t Young Adult\n",
      "37 \t 260 \t 0.5% \t target\n"
     ]
    }
   ],
   "source": [
    "for i in range(df.shape[1]):\n",
    "    name = ''\n",
    "    num = len(df.iloc[:, i].unique())\n",
    "    name = df.columns[i]\n",
    "    percentage = num / df.shape[0] * 100\n",
    "    print('%d \\t %d \\t %.1f%% \\t %s' % (i, num, percentage, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4db2d-3172-45d0-bcf3-522ce858c5df",
   "metadata": {},
   "source": [
    "Vemos que en hay variables que tienen pocos valores distintos, pero esto es porque son varaibles categóricas limitadas a un rango concreto. No parece necesario eliminar estas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac252cc-e82f-40d7-9999-243a39cb1b3e",
   "metadata": {},
   "source": [
    "#### 2.1.3. Valores de baja varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c43c8-68a8-4335-a102-dbac425185aa",
   "metadata": {},
   "source": [
    "Ahora vamos a comprobar qué variables tienen una varianza muy muy pequeña, lo cual implicaría que estuvieran muy cerca de tener un solo valor, y de ser necesario eliminarlas también.\n",
    "\n",
    "Primero, separamos las variables explicativas de la explicada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "646e7de1-768b-4364-b28d-2f567864d646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52191 entries, 0 to 52477\n",
      "Data columns (total 38 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   language            47716 non-null  object \n",
      " 1   bookFormat          49783 non-null  object \n",
      " 2   pages               49848 non-null  float64\n",
      " 3   numRatings          52191 non-null  float64\n",
      " 4   likedPercent        51646 non-null  float64\n",
      " 5   bbeScore            52191 non-null  float64\n",
      " 6   bbeVotes            52191 non-null  float64\n",
      " 7   price               37977 non-null  float64\n",
      " 8   publishYear         50424 non-null  float64\n",
      " 9   publishMonth        50424 non-null  float64\n",
      " 10  publishDay          50424 non-null  float64\n",
      " 11  awards              52191 non-null  int64  \n",
      " 12  5Stars              52191 non-null  int64  \n",
      " 13  4Stars              52191 non-null  int64  \n",
      " 14  3Stars              52191 non-null  int64  \n",
      " 15  2Stars              52191 non-null  int64  \n",
      " 16  1Star               52191 non-null  int64  \n",
      " 17  Adult               52191 non-null  int64  \n",
      " 18  Adventure           52191 non-null  int64  \n",
      " 19  Childrens           52191 non-null  int64  \n",
      " 20  Classics            52191 non-null  int64  \n",
      " 21  Contemporary        52191 non-null  int64  \n",
      " 22  Fantasy             52191 non-null  int64  \n",
      " 23  Fiction             52191 non-null  int64  \n",
      " 24  Historical          52191 non-null  int64  \n",
      " 25  Historical Fiction  52191 non-null  int64  \n",
      " 26  Humor               52191 non-null  int64  \n",
      " 27  Literature          52191 non-null  int64  \n",
      " 28  Magic               52191 non-null  int64  \n",
      " 29  Mystery             52191 non-null  int64  \n",
      " 30  Nonfiction          52191 non-null  int64  \n",
      " 31  Novels              52191 non-null  int64  \n",
      " 32  Paranormal          52191 non-null  int64  \n",
      " 33  Romance             52191 non-null  int64  \n",
      " 34  Science Fiction     52191 non-null  int64  \n",
      " 35  Thriller            52191 non-null  int64  \n",
      " 36  Young Adult         52191 non-null  int64  \n",
      " 37  target              52191 non-null  float64\n",
      "dtypes: float64(10), int64(26), object(2)\n",
      "memory usage: 15.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1276794-958b-4ef5-809b-56e229e4cc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Threshold=0.00, Features=35\n",
      ">Threshold=0.01, Features=35\n",
      ">Threshold=0.02, Features=35\n",
      ">Threshold=0.03, Features=35\n",
      ">Threshold=0.04, Features=35\n",
      ">Threshold=0.05, Features=35\n",
      ">Threshold=0.06, Features=35\n",
      ">Threshold=0.07, Features=35\n",
      ">Threshold=0.08, Features=32\n",
      ">Threshold=0.09, Features=31\n",
      ">Threshold=0.10, Features=29\n",
      ">Threshold=0.11, Features=26\n",
      ">Threshold=0.12, Features=25\n",
      ">Threshold=0.13, Features=22\n",
      ">Threshold=0.14, Features=20\n",
      ">Threshold=0.15, Features=20\n",
      ">Threshold=0.16, Features=20\n",
      ">Threshold=0.17, Features=19\n",
      ">Threshold=0.18, Features=18\n",
      ">Threshold=0.19, Features=18\n",
      ">Threshold=0.20, Features=18\n",
      ">Threshold=0.21, Features=16\n",
      ">Threshold=0.22, Features=16\n",
      ">Threshold=0.23, Features=16\n",
      ">Threshold=0.24, Features=15\n",
      ">Threshold=0.25, Features=15\n",
      ">Threshold=0.26, Features=15\n",
      ">Threshold=0.27, Features=15\n",
      ">Threshold=0.28, Features=15\n",
      ">Threshold=0.29, Features=15\n",
      ">Threshold=0.30, Features=15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#También necesitamos, para este método quedarnos solo con las variables numéricas\n",
    "col_num = df.iloc[:,2:-1]\n",
    "\n",
    "thresholds = np.arange(0.0, 0.31, 0.01)\n",
    "\n",
    "results = list()\n",
    "for t in thresholds:\n",
    "    \n",
    "    transform = VarianceThreshold(threshold=t)\n",
    "    \n",
    "    col_num_trans = transform.fit_transform(col_num)\n",
    "    \n",
    "    n_features = col_num_trans.shape[1]\n",
    "    print('>Threshold=%.2f, Features=%d' % (t, n_features))\n",
    "    \n",
    "    results.append(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cceb9ae0-619d-4e62-8b0a-05b91574c6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(thresholds, results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f2013-37a6-4654-9069-db216285c3cc",
   "metadata": {},
   "source": [
    "Vemos que puede ser interesante eliminar las variables hasta el 0.15, por ello vamos generar dos datasets: uno con todas las variables y otro con las eliminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92b9fb76-140f-49b1-8981-18b8c227ad32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52191, 20)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "transform = VarianceThreshold(threshold=0.15)\n",
    "\n",
    "df_noLowVar = transform.fit_transform(col_num)\n",
    "df_noLowVar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f95572e2-e3f1-411a-885a-2001e8dfb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noLowVar = pd.concat([pd.DataFrame(df_noLowVar, index=df.index),  df.iloc[:,:2], df.target], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2cd74a-446d-4c7e-8453-10f39fa72cc8",
   "metadata": {},
   "source": [
    "Vamos almacenando nuestros datasets en la siguiente lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e150d2d8-0996-456d-9f4a-9da6fe32900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"Original\": df, \"Sin baja varianza\": df_noLowVar}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab4ed5-0eb9-4f9d-aada-f248ff0b116e",
   "metadata": {},
   "source": [
    "#### 2.1.4. Valores duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c9dfc-44d1-4ccd-8412-b78bbeb44528",
   "metadata": {},
   "source": [
    "Veamos el número de registros duplicados (contando la variable target) que existen en nuestros datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "32aeff5b-d173-443a-8ecf-b8718fb57142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "52\n",
      "True\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "# Normal\n",
    "dups = datasets[\"Original\"].duplicated()\n",
    "print(dups.any())\n",
    "print(datasets[\"Original\"][dups].shape[0])\n",
    "# Sin variables con baja varianza\n",
    "dups = datasets[\"Sin baja varianza\"].duplicated()\n",
    "print(dups.any())\n",
    "print(datasets[\"Sin baja varianza\"][dups].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f3995-2eac-412e-94b5-7a3a30df1966",
   "metadata": {},
   "source": [
    "Vemos que tenemos 52 filas duplicadas, procedemos a eliminarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9be17a1-c597-405b-b4dc-0e272649280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con duplicados:  (52191, 38)\n",
      "Sin duplicados:  (52139, 38)\n"
     ]
    }
   ],
   "source": [
    "print(\"Con duplicados: \", datasets[\"Original\"].shape)\n",
    "datasets[\"Original\"].drop_duplicates(inplace=True)\n",
    "print(\"Sin duplicados: \", datasets[\"Original\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ff2a1-e65f-4c71-9203-6578d23eb8e9",
   "metadata": {},
   "source": [
    "Lo hacemos para el otro dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0395dd18-16e1-4f66-b130-e42657074df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con duplicados:  (52191, 23)\n",
      "Sin duplicados:  (52139, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Con duplicados: \", datasets[\"Sin baja varianza\"].shape)\n",
    "datasets[\"Sin baja varianza\"].drop_duplicates(inplace=True)\n",
    "print(\"Sin duplicados: \", datasets[\"Sin baja varianza\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f30fa-cb4a-4544-bae6-603056fcd249",
   "metadata": {},
   "source": [
    "Ya tenemos nuestros datos limpios de duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e364a6-4555-4f3e-8318-f50969d6ae9a",
   "metadata": {},
   "source": [
    "### 2.2. Valores perdidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2d0a1-49ed-464c-8bf3-8d9e043c40c6",
   "metadata": {},
   "source": [
    "En este apartado vamos a encargarnos de los valores espurios, lo hacemos aquí y no después porque tener valores perdidos a la hora de realizar posteriores apartados nos generará problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b4747e-0a3a-42d1-9559-0e1326d32dc7",
   "metadata": {},
   "source": [
    "#### 2.2.1. Identificación de valores perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "221c9bd2-9314-4e81-b4e8-ecd89f25b2da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language               4468\n",
      "bookFormat             2405\n",
      "pages                  2337\n",
      "numRatings                0\n",
      "likedPercent            544\n",
      "bbeScore                  0\n",
      "bbeVotes                  0\n",
      "price                 14191\n",
      "publishYear            1764\n",
      "publishMonth           1764\n",
      "publishDay             1764\n",
      "awards                    0\n",
      "5Stars                    0\n",
      "4Stars                    0\n",
      "3Stars                    0\n",
      "2Stars                    0\n",
      "1Star                     0\n",
      "Adult                     0\n",
      "Adventure                 0\n",
      "Childrens                 0\n",
      "Classics                  0\n",
      "Contemporary              0\n",
      "Fantasy                   0\n",
      "Fiction                   0\n",
      "Historical                0\n",
      "Historical Fiction        0\n",
      "Humor                     0\n",
      "Literature                0\n",
      "Magic                     0\n",
      "Mystery                   0\n",
      "Nonfiction                0\n",
      "Novels                    0\n",
      "Paranormal                0\n",
      "Romance                   0\n",
      "Science Fiction           0\n",
      "Thriller                  0\n",
      "Young Adult               0\n",
      "target                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_nulls = (df.isnull()).sum()\n",
    "\n",
    "print(num_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17b4e4af-71bf-4ed5-8fbf-20899ff9200f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Missing(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>price</td>\n",
       "      <td>14191</td>\n",
       "      <td>27.217630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>language</td>\n",
       "      <td>4468</td>\n",
       "      <td>8.569401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bookFormat</td>\n",
       "      <td>2405</td>\n",
       "      <td>4.612670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pages</td>\n",
       "      <td>2337</td>\n",
       "      <td>4.482249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>publishYear</td>\n",
       "      <td>1764</td>\n",
       "      <td>3.383264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>publishMonth</td>\n",
       "      <td>1764</td>\n",
       "      <td>3.383264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>publishDay</td>\n",
       "      <td>1764</td>\n",
       "      <td>3.383264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>likedPercent</td>\n",
       "      <td>544</td>\n",
       "      <td>1.043365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column  Missing  Missing(%)\n",
       "7          price    14191   27.217630\n",
       "0       language     4468    8.569401\n",
       "1     bookFormat     2405    4.612670\n",
       "2          pages     2337    4.482249\n",
       "8    publishYear     1764    3.383264\n",
       "9   publishMonth     1764    3.383264\n",
       "10    publishDay     1764    3.383264\n",
       "4   likedPercent      544    1.043365"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulos = pd.DataFrame(columns=['Column', 'Missing', 'Missing(%)'])\n",
    "\n",
    "for i in range(df.shape[1]):\n",
    "    n_miss = df.iloc[:,i].isnull().sum()\n",
    "    perc = n_miss / df.shape[0] * 100\n",
    "    nulos.loc[i] = [df.columns[i], n_miss, perc]\n",
    "\n",
    "nulos[nulos['Missing(%)'] > 0.].sort_values('Missing', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e098a-59ae-470f-85a5-ce7063b8877f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Vemos que tenemos en muchas columnas un grave problema de valores nulos, así que como viene así estructurado en la asignatura en este apartado simplemente vamos a eliminarlos. Más adelante los imputaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7156b273-ecf1-46e9-97ba-773a9b04c1fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.2. Borrado de filas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c4e8b73-61ee-4bf7-a493-6bf80c94fcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "(52139, 38)\n",
      "(34401, 38)\n",
      "Sin baja varianza\n",
      "(52139, 23)\n",
      "(34401, 23)\n"
     ]
    }
   ],
   "source": [
    "ds_aux = datasets.copy()\n",
    "for key, value in ds_aux.items():\n",
    "    print(key)\n",
    "    aux = value.copy()\n",
    "    aux.dropna(inplace=True)\n",
    "    #Antes\n",
    "    print(value.shape)\n",
    "    #Después\n",
    "    print(aux.shape)\n",
    "    datasets[f\"{key}_NoNulls\"] = aux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad902a39-0278-485d-8714-b31fd15fd777",
   "metadata": {},
   "source": [
    "Vemos que pasamos a tener unas 34.000 instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7c0b3e76-f384-4ab4-8b88-ee17596fa1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>bookFormat</th>\n",
       "      <th>pages</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "      <th>publishYear</th>\n",
       "      <th>publishMonth</th>\n",
       "      <th>...</th>\n",
       "      <th>Magic</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Nonfiction</th>\n",
       "      <th>Novels</th>\n",
       "      <th>Paranormal</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Young Adult</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>374.0</td>\n",
       "      <td>6376780.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2993816.0</td>\n",
       "      <td>30516.0</td>\n",
       "      <td>5.09</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>870.0</td>\n",
       "      <td>2507623.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2632233.0</td>\n",
       "      <td>26923.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>501.0</td>\n",
       "      <td>4964519.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1459448.0</td>\n",
       "      <td>14874.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>English</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>552.0</td>\n",
       "      <td>1834276.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1372809.0</td>\n",
       "      <td>14168.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2740713.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1276599.0</td>\n",
       "      <td>13264.0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52470</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>416.0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.55</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52472</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.18</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52475</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>280.0</td>\n",
       "      <td>6674.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.37</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52476</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>507.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52477</th>\n",
       "      <td>English</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>201.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34401 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      language bookFormat  pages  numRatings  likedPercent   bbeScore  \\\n",
       "0      English  Hardcover  374.0   6376780.0          96.0  2993816.0   \n",
       "1      English  Paperback  870.0   2507623.0          98.0  2632233.0   \n",
       "4      English  Paperback  501.0   4964519.0          78.0  1459448.0   \n",
       "5      English  Hardcover  552.0   1834276.0          96.0  1372809.0   \n",
       "6      English  Paperback  141.0   2740713.0          91.0  1276599.0   \n",
       "...        ...        ...    ...         ...           ...        ...   \n",
       "52470  English  Paperback  416.0      2143.0          95.0        0.0   \n",
       "52472  English  Paperback  360.0      1028.0          94.0        0.0   \n",
       "52475  English  Paperback  280.0      6674.0          84.0        0.0   \n",
       "52476  English  Paperback  507.0       238.0          90.0        0.0   \n",
       "52477  English  Paperback  201.0       246.0          90.0        0.0   \n",
       "\n",
       "       bbeVotes  price  publishYear  publishMonth  ...  Magic  Mystery  \\\n",
       "0       30516.0   5.09       2008.0           9.0  ...      0        0   \n",
       "1       26923.0   7.38       2004.0           9.0  ...      1        0   \n",
       "4       14874.0   2.10       2006.0           9.0  ...      0        0   \n",
       "5       14168.0   3.80       2006.0           3.0  ...      0        0   \n",
       "6       13264.0   4.42       1996.0           4.0  ...      0        0   \n",
       "...         ...    ...          ...           ...  ...    ...      ...   \n",
       "52470       1.0   5.55       2011.0          10.0  ...      0        1   \n",
       "52472       1.0  19.18       2013.0           4.0  ...      0        1   \n",
       "52475       1.0   7.37       2011.0           3.0  ...      0        0   \n",
       "52476       1.0   2.86       2011.0           9.0  ...      0        1   \n",
       "52477       1.0   5.20       2011.0           5.0  ...      0        0   \n",
       "\n",
       "       Nonfiction  Novels  Paranormal  Romance  Science Fiction  Thriller  \\\n",
       "0               0       0           0        1                1         0   \n",
       "1               0       0           0        0                0         0   \n",
       "4               0       0           1        1                0         0   \n",
       "5               0       0           0        0                0         0   \n",
       "6               0       1           0        0                1         0   \n",
       "...           ...     ...         ...      ...              ...       ...   \n",
       "52470           0       0           0        1                0         0   \n",
       "52472           0       0           0        1                0         0   \n",
       "52475           0       0           1        1                0         0   \n",
       "52476           0       0           0        0                0         0   \n",
       "52477           0       0           0        1                0         0   \n",
       "\n",
       "       Young Adult  target  \n",
       "0                1    4.33  \n",
       "1                1    4.50  \n",
       "4                1    3.60  \n",
       "5                1    4.37  \n",
       "6                0    3.95  \n",
       "...            ...     ...  \n",
       "52470            0    4.14  \n",
       "52472            1    4.16  \n",
       "52475            1    3.70  \n",
       "52476            0    3.85  \n",
       "52477            1    4.02  \n",
       "\n",
       "[34401 rows x 38 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " datasets[\"Original_NoNulls\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ddc47-20bd-4684-9c3b-89b592fcde4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.3. Imputación de valores perdidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1bd3d6-222b-4429-bb1f-9d54188c0729",
   "metadata": {},
   "source": [
    "##### 2.2.3.1. Imputación estadística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d8c2d093-76e1-4682-bf77-c384382d8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipelines = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aba7c068-5a32-4a5f-8dfa-6196e005e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la pipeline para imputar las variables categóricas\n",
    "cat_cols = ['language', 'bookFormat']\n",
    "cat = SimpleImputer(strategy='most_frequent')\n",
    "# Y la que imputará las variables numéricas:\n",
    "num_cols = df[df.columns.difference(cat_cols+['target'])].columns.to_list()\n",
    "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
    "for s in strategies:\n",
    "    pipelines[f'SimpleImputer_{s}'] = ColumnTransformer(\n",
    "                                                        [\n",
    "                                                         ('cat_imputer', cat, cat_cols),\n",
    "                                                         ('num_imputer', SimpleImputer(strategy=s), num_cols)\n",
    "                                                         ]\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7945f49c-5cb7-42cb-a5da-e16af43f900c",
   "metadata": {},
   "source": [
    "Vemos que tenemos en varias pipelines las estrategias de imputado, haremos esto con las posteriores estratégias y en un apartado de resultados las validaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106aa3ac-a2c9-468c-a84d-8c90feaf4a0b",
   "metadata": {},
   "source": [
    "##### 2.2.3.2. Imputación por KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c82bf8-d383-4ba4-aae6-c3ca3b245db8",
   "metadata": {},
   "source": [
    "Hacemos lo mismo con al estrategia de imputación por KNN. Pero en este apartado, perimero haremos un Label Encoder de las variables categóricas para poder realizarlo sobre todo el dataset y luego su correspondiente inverse_transform. Es decir, codificamos con un label encoder, luego aplicamos KNN_imputer, y por último decodificamos. Para ello, hemos creado dos clases que se puedan meter en una pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e52b233c-53b5-40f6-bd05-cbdadaab4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b80f220a-2920-4247-837d-3b064a48aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnLabelEncoder:\n",
    "    def __init__(self, le = None, column = None):\n",
    "        self.le = le\n",
    "        self.column = column # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self# not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        output[self.column] = self.le.fit_transform(output[self.column])\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        return self.le.inverse_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e5c3b53-b830-4372-ae17-b82c3664e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnLabelDesencoder:\n",
    "    def __init__(self,le = None, column = None):\n",
    "        self.le = le # array of column names to encode\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        output = np.array(X.copy(), dtype=object)\n",
    "        output[:,self.column] = self.le.inverse_transform(X[:,self.column].astype(int))\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71f4f319-a107-4319-85b0-5cd30d27da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "strategies = [i for i in range(5,16,2)]\n",
    "le_lan = ColumnLabelEncoder(LabelEncoder(), 'language')\n",
    "le_bf = ColumnLabelEncoder(LabelEncoder(), 'bookFormat')\n",
    "for s in strategies:\n",
    "    pipelines[f'Numerical_KNN{s}'] = Pipeline(steps=[('le_lan', le_lan), ('le_bf', le_bf),\n",
    "                                                     ('i',KNNImputer(n_neighbors=s)), ('ld_lan', ColumnLabelDesencoder(le_lan, 0)),\n",
    "                                                    ('ld_bf', ColumnLabelDesencoder(le_bf, 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4bd82-182b-4081-82b1-8c485cda884b",
   "metadata": {},
   "source": [
    "##### 2.2.3.3. Imputación iterativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "82ee6afd-c45b-4454-8e77-04e98e6ec0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e691fd56-90fa-4d08-a2fe-273dc90cd79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import linear_model\n",
    "\n",
    "strategies = ['ascending', 'descending', 'roman', 'arabic', 'random']\n",
    "le_lan = ColumnLabelEncoder(LabelEncoder(), 'language')\n",
    "le_bf = ColumnLabelEncoder(LabelEncoder(), 'bookFormat')\n",
    "for s in strategies:\n",
    "    pipelines[f'Numerical_Lasso_{s}'] = Pipeline(steps=[('le_lan', le_lan), ('le_bf', le_bf),\n",
    "                                                        ('i', IterativeImputer(estimator=linear_model.Lasso(alpha=0.1), n_nearest_features=None,imputation_order=s)),\n",
    "                                                       ('ld_lan', ColumnLabelDesencoder(le_lan, 0)),\n",
    "                                                        ('ld_bf', ColumnLabelDesencoder(le_bf, 1))])\n",
    "    pipelines[f'Numerical_LassoLars_{s}'] = Pipeline(steps=[('le_lan', le_lan), ('le_bf', le_bf),\n",
    "                                                        ('i', IterativeImputer(estimator=linear_model.LassoLars(), n_nearest_features=None,imputation_order=s)),\n",
    "                                                       ('ld_lan', ColumnLabelDesencoder(le_lan, 0)),\n",
    "                                                        ('ld_bf', ColumnLabelDesencoder(le_bf, 1))])\n",
    "    pipelines[f'Numerical_BayesianRidge_{s}'] = Pipeline(steps=[('le_lan', le_lan), ('le_bf', le_bf),\n",
    "                                                        ('i', IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None,imputation_order=s)),\n",
    "                                                       ('ld_lan', ColumnLabelDesencoder(le_lan, 0)),\n",
    "                                                        ('ld_bf', ColumnLabelDesencoder(le_bf, 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "674dcdfc-7c85-47f2-8c39-8680bc798eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SimpleImputer_mean', 'SimpleImputer_median', 'SimpleImputer_most_frequent', 'SimpleImputer_constant', 'Numerical_KNN5', 'Numerical_KNN7', 'Numerical_KNN9', 'Numerical_KNN11', 'Numerical_KNN13', 'Numerical_KNN15', 'Numerical_Lasso_ascending', 'Numerical_LassoLars_ascending', 'Numerical_BayesianRidge_ascending', 'Numerical_Lasso_descending', 'Numerical_LassoLars_descending', 'Numerical_BayesianRidge_descending', 'Numerical_Lasso_roman', 'Numerical_LassoLars_roman', 'Numerical_BayesianRidge_roman', 'Numerical_Lasso_arabic', 'Numerical_LassoLars_arabic', 'Numerical_BayesianRidge_arabic', 'Numerical_Lasso_random', 'Numerical_LassoLars_random', 'Numerical_BayesianRidge_random'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93e75d-da9c-4c86-8f7f-065813da89b1",
   "metadata": {},
   "source": [
    "#### 2.2.4. Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978123f5-4ca1-4399-aeae-af55c7e66a81",
   "metadata": {},
   "source": [
    "Ahora tenemos todas las pipelines, pero no podemos probarlas porque sería necesario codificar los datos para ello, así que vamos a hacerlo ahora. Por ello, no tenemos como tal un apartado para la codificación de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444783b5-cd8d-4a6e-b827-338027f907ba",
   "metadata": {},
   "source": [
    "Primero vamos a tener en una lista los tres modelos que vamos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0f949d7f-238f-43a6-8e0f-e46a25eeae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "modelos = {\"RF\": RandomForestRegressor(random_state=1), \"RL\": LinearRegression(), \"SVR\": SVR()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f3411-7e21-4f68-912d-956a3e2c6df2",
   "metadata": {},
   "source": [
    "Y ahora vemos el score de cada uno de los datasets con las distintas técnicas de imputado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ea5fd6e7-c3c0-44ee-9de9-6d9026a13fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Original, Modelo: RF, Estrategia de imputación SimpleImputer_mean RMSE: 0.085302\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación SimpleImputer_median RMSE: 0.085469\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación SimpleImputer_most_frequent RMSE: 0.084701\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación SimpleImputer_constant RMSE: 0.083928\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_KNN5 RMSE: 0.085838\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_KNN7 RMSE: 0.086024\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_KNN9 RMSE: 0.085340\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_KNN11 RMSE: 0.086196\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_KNN13 RMSE: 0.085459\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_KNN15 RMSE: 0.085569\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_Lasso_ascending RMSE: 0.085034\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_LassoLars_ascending RMSE: 0.085508\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_BayesianRidge_ascending RMSE: 0.084470\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_Lasso_descending RMSE: 0.085147\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_LassoLars_descending RMSE: 0.085508\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_BayesianRidge_descending RMSE: 0.084470\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_Lasso_roman RMSE: 0.085147\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_LassoLars_roman RMSE: 0.085508\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_BayesianRidge_roman RMSE: 0.084470\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_Lasso_arabic RMSE: 0.085090\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_LassoLars_arabic RMSE: 0.085508\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_BayesianRidge_arabic RMSE: 0.084470\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_Lasso_random RMSE: 0.085147\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_LassoLars_random RMSE: 0.085508\n",
      "Dataset: Original, Modelo: RF, Estrategia de imputación Numerical_BayesianRidge_random RMSE: 0.084470\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación SimpleImputer_mean RMSE: 0.106338\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación SimpleImputer_median RMSE: 0.105852\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación SimpleImputer_most_frequent RMSE: 0.105659\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación SimpleImputer_constant RMSE: 0.105303\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_KNN5 RMSE: 0.105911\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_KNN7 RMSE: 0.105422\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_KNN9 RMSE: 0.105462\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_KNN11 RMSE: 0.105694\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_KNN13 RMSE: 0.105561\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_KNN15 RMSE: 0.105693\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_Lasso_ascending RMSE: 0.109919\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_LassoLars_ascending RMSE: 0.106338\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_BayesianRidge_ascending RMSE: 0.107579\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_Lasso_descending RMSE: 0.109928\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_LassoLars_descending RMSE: 0.106338\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_BayesianRidge_descending RMSE: 0.107579\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_Lasso_roman RMSE: 0.109926\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_LassoLars_roman RMSE: 0.106338\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_BayesianRidge_roman RMSE: 0.107579\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_Lasso_arabic RMSE: 0.109920\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_LassoLars_arabic RMSE: 0.106338\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_BayesianRidge_arabic RMSE: 0.107579\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_Lasso_random RMSE: 0.109926\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_LassoLars_random RMSE: 0.106338\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputación Numerical_BayesianRidge_random RMSE: 0.107579\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación SimpleImputer_mean RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación SimpleImputer_median RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación SimpleImputer_most_frequent RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación SimpleImputer_constant RMSE: 0.142939\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_KNN5 RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_KNN7 RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_KNN9 RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_KNN11 RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_KNN13 RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_KNN15 RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_Lasso_ascending RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_LassoLars_ascending RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_BayesianRidge_ascending RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_Lasso_descending RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_LassoLars_descending RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_BayesianRidge_descending RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_Lasso_roman RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_LassoLars_roman RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_BayesianRidge_roman RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_Lasso_arabic RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_LassoLars_arabic RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_BayesianRidge_arabic RMSE: 0.142954\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_Lasso_random RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_LassoLars_random RMSE: 0.142944\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputación Numerical_BayesianRidge_random RMSE: 0.142954\n",
      "CPU times: total: 1min 27s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for model_name, model in modelos.items():\n",
    "    for pip_name, pip in pipelines.items():\n",
    "            \n",
    "        df = datasets[\"Original\"]\n",
    "        \n",
    "        X = df.loc[:500, df.columns != 'target']\n",
    "        y = df.loc[:500, df.columns == 'target']\n",
    "    \n",
    "        # X = df_def.loc[:,df_def.columns != 'target']\n",
    "        # y = df_def.loc[:,df_def.columns == 'target']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "        cat_cols = ['language', 'bookFormat']\n",
    "            \n",
    "        col_trans = ColumnTransformer([('num', pip.fit(X_train), X.columns),\n",
    "                                                ('ohe_encoder', OneHotEncoder(), cat_cols)])\n",
    "            \n",
    "        X_train = col_trans.fit_transform(X_train)\n",
    "        X_test = col_trans.transform(X_test)\n",
    "\n",
    "        X_train = np.delete(X_train, [0,1], 1)\n",
    "        X_test = np.delete(X_test, [0,1], 1)\n",
    "\n",
    "        model.fit(X_train, y_train.values.ravel())\n",
    "        y_hat = model.predict(X_test)\n",
    "\n",
    "        score = mean_squared_error(y_test.values.ravel(), y_hat)\n",
    "\n",
    "        print(f\"Dataset: Original, Modelo: {model_name}, Estrategia de imputación {pip_name}\",'RMSE: %.6f' % np.sqrt(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b4be5-ac9f-4a5d-8d42-8b0bf38a5186",
   "metadata": {},
   "source": [
    "Entre todos los que hemos obtenido vemos que uno de los mejores es, utilizando el dataset original, KNNImputer con 9 vecinos. En el siguiente apartado, generaremos un dataset con esos datos imputados y continuaremos aplicando las técnicas de procesamiento de datos sobre este."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eb890e-6754-43e1-89ab-6b1c102b8dc0",
   "metadata": {},
   "source": [
    "### 2.3. Codificación de las variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05faf154-c641-436e-a824-ec1f6b5c2d6b",
   "metadata": {},
   "source": [
    "A continuación vamos a tratar las variables categóricas. Para ello, estudiamos los datos de las columnas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d5058a8f-871b-49dc-8c20-e954654b0216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['language', 'bookFormat'], dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['Original'].select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c50b4-4e39-4361-ad9a-c837efb9844f",
   "metadata": {},
   "source": [
    "Ambas columnas contienen datos categóricos independientes y no ordenados, por lo que vamos a tener que utilizar un `OneHotEncoder` para codificar estas variables. Como comentábamos en el anterior apartado, vamos a proceder a aplicar las mejores técnicas identificadas (aquellas que nos han dado los mejores resultados) juntas al dataframe original, para posteriormente ejecutar esta codificación de variables categóricas. De este modo, obtendremos un dataset final con el procesamiento que hemos realizado hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7ca9f3ea-89f5-4f74-ad8f-d38f00788344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 18s\n",
      "Wall time: 1min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['English', 'Hardcover', 374.0, ..., 1.0, 0.0, 0.0],\n",
       "       ['English', 'Paperback', 870.0, ..., 0.0, 1.0, 0.0],\n",
       "       ['English', 'Paperback', 324.0, ..., 0.0, 1.0, 0.0],\n",
       "       ...,\n",
       "       ['English', 'Paperback', 280.0, ..., 0.0, 1.0, 0.0],\n",
       "       ['English', 'Paperback', 507.0, ..., 0.0, 1.0, 0.0],\n",
       "       ['English', 'Paperback', 201.0, ..., 0.0, 1.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = datasets[\"Original\"]\n",
    "\n",
    "cat_cols = ['language', 'bookFormat']\n",
    "\n",
    "le_lan = ColumnLabelEncoder(LabelEncoder(), 'language')\n",
    "le_bf = ColumnLabelEncoder(LabelEncoder(), 'bookFormat')\n",
    "\n",
    "pip = Pipeline(steps=[('le_lan', le_lan), \n",
    "                      ('le_bf', le_bf),\n",
    "                    ('i',KNNImputer(n_neighbors=9)), \n",
    "                      ('ld_lan', ColumnLabelDesencoder(le_lan, 0)),\n",
    "                    ('ld_bf', ColumnLabelDesencoder(le_bf, 1))])\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "            \n",
    "col_trans = ColumnTransformer([('num', pip.fit(df), df.columns),\n",
    "                                ('ohe_encoder', ohe.fit(df[cat_cols]), cat_cols)])\n",
    "            \n",
    "df_def = col_trans.fit_transform(df)\n",
    "\n",
    "df_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ac730bd-af83-40fe-82a0-ead1af8cae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ohe.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f27cc2db-dd6c-4672-ae19-c2b08a79207c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52139, 63)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_def.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad57cde5-5780-482d-85ef-daddda218619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52139 entries, 0 to 52477\n",
      "Data columns (total 61 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   pages               52139 non-null  object\n",
      " 1   numRatings          52139 non-null  object\n",
      " 2   likedPercent        52139 non-null  object\n",
      " 3   bbeScore            52139 non-null  object\n",
      " 4   bbeVotes            52139 non-null  object\n",
      " 5   price               52139 non-null  object\n",
      " 6   publishYear         52139 non-null  object\n",
      " 7   publishMonth        52139 non-null  object\n",
      " 8   publishDay          52139 non-null  object\n",
      " 9   awards              52139 non-null  object\n",
      " 10  5Stars              52139 non-null  object\n",
      " 11  4Stars              52139 non-null  object\n",
      " 12  3Stars              52139 non-null  object\n",
      " 13  2Stars              52139 non-null  object\n",
      " 14  1Star               52139 non-null  object\n",
      " 15  Adult               52139 non-null  object\n",
      " 16  Adventure           52139 non-null  object\n",
      " 17  Childrens           52139 non-null  object\n",
      " 18  Classics            52139 non-null  object\n",
      " 19  Contemporary        52139 non-null  object\n",
      " 20  Fantasy             52139 non-null  object\n",
      " 21  Fiction             52139 non-null  object\n",
      " 22  Historical          52139 non-null  object\n",
      " 23  Historical Fiction  52139 non-null  object\n",
      " 24  Humor               52139 non-null  object\n",
      " 25  Literature          52139 non-null  object\n",
      " 26  Magic               52139 non-null  object\n",
      " 27  Mystery             52139 non-null  object\n",
      " 28  Nonfiction          52139 non-null  object\n",
      " 29  Novels              52139 non-null  object\n",
      " 30  Paranormal          52139 non-null  object\n",
      " 31  Romance             52139 non-null  object\n",
      " 32  Science Fiction     52139 non-null  object\n",
      " 33  Thriller            52139 non-null  object\n",
      " 34  Young Adult         52139 non-null  object\n",
      " 35  target              52139 non-null  object\n",
      " 36  x0_Arabic           52139 non-null  object\n",
      " 37  x0_Bengali          52139 non-null  object\n",
      " 38  x0_Bulgarian        52139 non-null  object\n",
      " 39  x0_Dutch            52139 non-null  object\n",
      " 40  x0_English          52139 non-null  object\n",
      " 41  x0_French           52139 non-null  object\n",
      " 42  x0_German           52139 non-null  object\n",
      " 43  x0_Greek            52139 non-null  object\n",
      " 44  x0_Indonesian       52139 non-null  object\n",
      " 45  x0_Italian          52139 non-null  object\n",
      " 46  x0_Japanese         52139 non-null  object\n",
      " 47  x0_Malay            52139 non-null  object\n",
      " 48  x0_Persian          52139 non-null  object\n",
      " 49  x0_Polish           52139 non-null  object\n",
      " 50  x0_Portuguese       52139 non-null  object\n",
      " 51  x0_Romanian         52139 non-null  object\n",
      " 52  x0_Russian          52139 non-null  object\n",
      " 53  x0_Spanish          52139 non-null  object\n",
      " 54  x0_Swedish          52139 non-null  object\n",
      " 55  x0_Turkish          52139 non-null  object\n",
      " 56  x0_nan              52139 non-null  object\n",
      " 57  x1_Digital          52139 non-null  object\n",
      " 58  x1_Hardcover        52139 non-null  object\n",
      " 59  x1_Paperback        52139 non-null  object\n",
      " 60  x1_nan              52139 non-null  object\n",
      "dtypes: object(61)\n",
      "memory usage: 26.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_def = pd.DataFrame(df_def, columns = np.concatenate((df.columns, ohe.get_feature_names())), index=datasets[\"Original\"].index)\n",
    "df_def = df_def.drop(['language', 'bookFormat'], axis=1)\n",
    "\n",
    "df_def.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a70132c-f5cb-4d41-9838-559115be2a42",
   "metadata": {},
   "source": [
    "También necesitamos mover la variable 35 al final porque es la target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79aa2cb1-9a0b-4bf8-9aa4-6ef1d6efd0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_move = df_def.pop('target')\n",
    "df_def.insert(len(df_def.columns), 'target', column_to_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ad9a2e-b693-4a7b-8f5b-316e35668ec6",
   "metadata": {},
   "source": [
    "### 2.4. Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e43c54-bb60-4944-89ec-c7adb9cb174c",
   "metadata": {},
   "source": [
    "Comencemos primero con los valores espurios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf579f-1ac1-4b1a-a223-b84e93338441",
   "metadata": {},
   "source": [
    "#### 2.4.1. Borrado de outliers mediante el Standard Deviation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac796c-c4c1-429a-a0ab-00bd9e668a27",
   "metadata": {},
   "source": [
    "Primero vamos a comprobar qué distribución siguen nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c3db49d7-8acf-4491-8ab5-fce755616abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 36 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = df.hist(figsize=[20,15], xlabelsize=4, ylabelsize=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a17d1-e2d0-4786-957a-d4e477913723",
   "metadata": {},
   "source": [
    "Viendo estas distribuciones podemos aseverar que tenemos espurios, pero no podemos considerar ninguna variable normal (salvo la target), por lo que no podemos utilizar el método SDM para eliminar outliers. Probemos a utilizar el Interquartile Range Method (IQR) y el borrado automático de outliers mediante el Local Outlier Factor (LOF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c961f252-583f-49cd-bd5d-543b61454547",
   "metadata": {},
   "source": [
    "#### 2.4.2. Identificación de outliers mediante el Interquartile Range Method (IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f93aedee-b1f2-4f0e-ae20-db45fa037662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages\n",
      "Percentiles: 25th=196.000, 75th=386.000, IQR=190.000\n",
      "Identified outliers: 4534\n",
      "numRatings\n",
      "Percentiles: 25th=409.000, 75th=10023.000, IQR=9614.000\n",
      "Identified outliers: 5967\n",
      "likedPercent\n",
      "Percentiles: 25th=89.000, 75th=96.000, IQR=7.000\n",
      "Identified outliers: 1813\n",
      "bbeScore\n",
      "Percentiles: 25th=81.000, 75th=135.000, IQR=54.000\n",
      "Identified outliers: 5189\n",
      "bbeVotes\n",
      "Percentiles: 25th=1.000, 75th=1.000, IQR=0.000\n",
      "Identified outliers: 6164\n",
      "price\n",
      "Percentiles: 25th=-9223372036854775808.000, 75th=6.000, IQR=9223372036854775808.000\n",
      "Identified outliers: 0\n"
     ]
    }
   ],
   "source": [
    "df_IQR = df.copy()\n",
    "\n",
    "for i in df_IQR.iloc[:, 2:8]:\n",
    "    print(i)\n",
    "    datos = df_IQR[[i]].values.astype('int64')\n",
    "    \n",
    "    q25, q75 = np.percentile(datos, 25), np.percentile(datos, 75)\n",
    "    iqr = q75 - q25\n",
    "    print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "    \n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    \n",
    "    outliers = [x for x in datos if x < lower or x > upper]\n",
    "    print('Identified outliers: %d' % len(outliers))\n",
    "    df_IQR = df_IQR[(df_IQR[i] >= lower) & (df_IQR[i] <= upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e008b669-30ac-49ff-85e3-fdb09f659383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 36 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = df_IQR.hist(figsize=[20,15], xlabelsize=4, ylabelsize=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c343081-4853-4ca7-9af1-7828638984a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"IQR\"] = df_IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1827a0-f1f3-4e40-9f72-a394182db22e",
   "metadata": {},
   "source": [
    "Como los nulos los hemos gestionado antes, vamos a eliminar de aquí los nulos también:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1de8ce-95a7-4729-b455-e8181219c2cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.4.3. Borrado automático de outliers mediante el Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd01d316-c638-473d-afc6-a42da0bf2e38",
   "metadata": {},
   "source": [
    "Para esta técnica vamos a usar el dataset sin nulos generado en el apartado 2.2.df_def ya que este método funciona si no hay nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b88d000e-81d7-453f-94c4-03bee4bf8b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Original, Modelo: RF, Estrategia de imputado Numerical_BayesianRidge_random RMSE: 0.241801\n",
      "Dataset: Original, Modelo: RL, Estrategia de imputado Numerical_BayesianRidge_random RMSE: 0.427603\n",
      "Dataset: Original, Modelo: SVR, Estrategia de imputado Numerical_BayesianRidge_random RMSE: 0.432803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "for model_name, model in modelos.items():\n",
    "            \n",
    "    X = df_def.loc[:500, df_def.columns != 'target']\n",
    "    y = df_def.loc[:500, df_def.columns == 'target']\n",
    "    \n",
    "    # X = df_def.loc[:,df_def.columns != 'target']\n",
    "    # y = df_def.loc[:,df_def.columns == 'target']\n",
    "    \n",
    "    lof = LocalOutlierFactor()\n",
    "    yhat = lof.fit_predict(X)\n",
    "    X = X[yhat == -1]\n",
    "    y = y[yhat == -1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    \n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    y_hat = model.predict(X_test)\n",
    "\n",
    "    score = mean_squared_error(y_test.values.ravel(), y_hat)\n",
    "\n",
    "    print(f\"Dataset: Original, Modelo: {model_name}, Estrategia de imputado {pip_name}\",'RMSE: %.6f' % np.sqrt(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd7c108-123b-4a6b-ac29-ed2c9c25d36e",
   "metadata": {},
   "source": [
    "Eliminando los outliers vemos que empeoran los resultados, por lo que a partir de aquí utilizaremos el dataset completo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d6f81-521a-40e3-8b76-94db1d675901",
   "metadata": {},
   "source": [
    "### 2.5. Escalado y transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfab63b-b4e2-407c-b17e-be95c908d515",
   "metadata": {},
   "source": [
    "En esta sección partiremos del dataset obtenido mediante la imputación de nulos con un KNNImputer para la configuración óptima y la codificación de las variables categóricas mediante un OneHotEncoder. Nuestro DataFrame contendrá todavía, por tanto, outliers y valores imputados, variables categóricas dummy y columnas numéricas con distribuciones y escalas no homogéneas.\n",
    "\n",
    "Nuestro objetivo será, por tanto, obtener una serie de resultados para distintos tratamientos y escalados de las variables numéricas del dataset de partida, pasando por distintos tipos de estandarización, normalización y otras transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "807a76af-44c0-4e1a-b4a6-e3fdbb5a4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_def.loc[:1500,df_def.columns != 'target']\n",
    "y = df_def.loc[:1500,df_def.columns == 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dadcc593-9c36-4c4f-8dac-8c5216f16e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['pages', 'numRatings', 'likedPercent', 'bbeScore', 'bbeVotes', 'price',\n",
    "                   'publishYear', 'publishMonth', 'publishDay', 'awards', '5Stars',\n",
    "                   '4Stars', '3Stars', '2Stars', '1Star']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa82fa-32f5-4853-b1e9-b48f02097827",
   "metadata": {},
   "source": [
    "Para evaluar los modelos, utilizaremos un Cross Validation K-Fold con 5 splits, e iremos guardando las métricas en un DataFrame de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e7fd176-eea9-4ae2-a0b6-e35a4ad442e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(columns=['Modelo', \n",
    "                               'Estrategia de escalado',\n",
    "                               'RMSE (mean)',\n",
    "                               'RMSE (std)',\n",
    "                               'Escalador'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70470e87-5274-4487-a3cb-ea548ecd7eaf",
   "metadata": {},
   "source": [
    "Para cada tipo de escalado seguiremos la misma estructura fija:\n",
    "\n",
    "* Importación del paquete.\n",
    "* Iteración para recorrer los tres modelos y cada parámtro del algoritmo de escalado.\n",
    "* Definición del método de escalado aplicado a las variables numéricas o el Pipeline contenedor de dicho método.\n",
    "* Ejecución del Cross Validation mediante un K-Fold de 5 splits.\n",
    "* Muestra de los resultados y almacenamiento en el DataFrame de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e65725f7-7d01-43b2-80b0-0ee2cbe5ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3fbfc6-5ee7-44b1-b6cf-bf0c10d9d90d",
   "metadata": {},
   "source": [
    "#### 2.5.1. Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c72f49-96a9-4f1f-84b4-c94e20635761",
   "metadata": {},
   "source": [
    "Probamos a aplicar un `MinMaxScaler` a nuestros datos y obtenemos los resultados para los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4ded5a20-ef1b-4a4b-9288-8f740e75631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.09 (0.00)\n",
      "RL: 0.55 (0.91)\n",
      "SVR: 0.12 (0.03)\n",
      "CPU times: total: 7.09 s\n",
      "Wall time: 4.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for model_name, model in modelos.items():\n",
    "    \n",
    "    scal = ColumnTransformer([('numeric',  MinMaxScaler(), numeric_columns)], remainder='passthrough')\n",
    "    \n",
    "    pip = Pipeline(steps=[('scaler', scal),\n",
    "                          ('model',  model)])\n",
    "\n",
    "    # preparar el procedimiento de cross-validation \n",
    "    cv = KFold(n_splits=5)\n",
    "    # evaluar el modelo\n",
    "    cv_results = cross_validate(pip, X, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "    \n",
    "    print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                         - mean(cv_results['test_score']), \n",
    "                                         std(cv_results['test_score'])))\n",
    "    \n",
    "    scores.loc[len(scores)] = [model_name,\n",
    "                               'Normalization',\n",
    "                               - mean(cv_results['test_score']),\n",
    "                               std(cv_results['test_score']),\n",
    "                               scal]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b87806-ab3d-4b1a-8890-3b83838e61a3",
   "metadata": {},
   "source": [
    "Finalmente, mostramos los resultados para el método de escalado concreto; en nuestro caso, el de normalización. Finalmente, comparamos los resultados y vemos cuál es el modelo que más éxito tiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4296299b-2b08-42f0-a069-30ef99e54c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de escalado</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Escalador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>0.085087</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVR</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>0.121318</td>\n",
       "      <td>0.030099</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL</td>\n",
       "      <td>Normalization</td>\n",
       "      <td>0.545928</td>\n",
       "      <td>0.912135</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelo Estrategia de escalado  RMSE (mean)  RMSE (std)  \\\n",
       "0     RF          Normalization     0.085087    0.002827   \n",
       "2    SVR          Normalization     0.121318    0.030099   \n",
       "1     RL          Normalization     0.545928    0.912135   \n",
       "\n",
       "                                           Escalador  \n",
       "0  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "2  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "1  ColumnTransformer(remainder='passthrough',\\n  ...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['Estrategia de escalado'] == 'Normalization'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d6fd95-033d-4ab5-a5ad-e29fe2a78033",
   "metadata": {},
   "source": [
    "#### 2.5.2. Estandarización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8b44e-efb5-4e1c-b74e-4e9cdf708d6e",
   "metadata": {},
   "source": [
    "Pasamos a utilizar un `StandardScaler` en nuestros datos. Los resultados obtenidos son similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b5e3549-9b46-4f6b-8191-380b53beadf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.09 (0.00)\n",
      "RL: 0.55 (0.91)\n",
      "SVR: 0.12 (0.05)\n",
      "CPU times: total: 6.3 s\n",
      "Wall time: 4.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for model_name, model in modelos.items():\n",
    "    \n",
    "    scal = ColumnTransformer([('numeric',  StandardScaler(), numeric_columns)], remainder='passthrough')\n",
    "    \n",
    "    pip = Pipeline(steps=[('scaler', scal),\n",
    "                          ('model',  model)])\n",
    "\n",
    "    # preparar el procedimiento de cross-validation \n",
    "    cv = KFold(n_splits=5)\n",
    "    # evaluar el modelo\n",
    "    cv_results = cross_validate(pip, X, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "    \n",
    "    print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                         - mean(cv_results['test_score']), \n",
    "                                         std(cv_results['test_score'])))\n",
    "    \n",
    "    scores.loc[len(scores)] = [model_name,\n",
    "                               'Standarization',\n",
    "                               - mean(cv_results['test_score']),\n",
    "                               std(cv_results['test_score']),\n",
    "                               scal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ee9de4ac-1b85-499a-860d-6ce1eef63a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de escalado</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Escalador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>Standarization</td>\n",
       "      <td>0.085137</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>Standarization</td>\n",
       "      <td>0.115393</td>\n",
       "      <td>0.046830</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RL</td>\n",
       "      <td>Standarization</td>\n",
       "      <td>0.546029</td>\n",
       "      <td>0.912088</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Modelo Estrategia de escalado  RMSE (mean)  RMSE (std)  \\\n",
       "3     RF         Standarization     0.085137    0.002793   \n",
       "5    SVR         Standarization     0.115393    0.046830   \n",
       "4     RL         Standarization     0.546029    0.912088   \n",
       "\n",
       "                                           Escalador  \n",
       "3  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "5  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "4  ColumnTransformer(remainder='passthrough',\\n  ...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['Estrategia de escalado'] == 'Standarization'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f68fdf-7aa0-4bd2-bd0c-0ab48764c6b7",
   "metadata": {},
   "source": [
    "#### 2.5.3. Estandarización mediante Robust Scaling (RS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a4c5e-b306-461e-8204-1b2137ba14f2",
   "metadata": {},
   "source": [
    "Para la estandarización mediante un `RobustScaler`, debemos elegir el valor de `quantile_range` para determinar el rango de cuartiles que ha de tener en cuenta. Tomamos este valor de una lista concreta y añadimos los resultados al grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3339e89d-3a59-4277-9dbe-a0025194cb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile Range:  1\n",
      "RF: 0.09 (0.00)\n",
      "Quantile Range:  1\n",
      "RL: 0.55 (0.91)\n",
      "Quantile Range:  1\n",
      "SVR: 0.12 (0.04)\n",
      "Quantile Range:  5\n",
      "RF: 0.09 (0.00)\n",
      "Quantile Range:  5\n",
      "RL: 0.55 (0.91)\n",
      "Quantile Range:  5\n",
      "SVR: 0.11 (0.04)\n",
      "Quantile Range:  10\n",
      "RF: 0.09 (0.00)\n",
      "Quantile Range:  10\n",
      "RL: 0.55 (0.91)\n",
      "Quantile Range:  10\n",
      "SVR: 0.11 (0.04)\n",
      "Quantile Range:  15\n",
      "RF: 0.09 (0.00)\n",
      "Quantile Range:  15\n",
      "RL: 0.55 (0.91)\n",
      "Quantile Range:  15\n",
      "SVR: 0.11 (0.05)\n",
      "Quantile Range:  20\n",
      "RF: 0.09 (0.00)\n",
      "Quantile Range:  20\n",
      "RL: 0.55 (0.91)\n",
      "Quantile Range:  20\n",
      "SVR: 0.10 (0.05)\n",
      "Quantile Range:  25\n",
      "RF: 0.09 (0.00)\n",
      "Quantile Range:  25\n",
      "RL: 0.55 (0.91)\n",
      "Quantile Range:  25\n",
      "SVR: 0.10 (0.05)\n",
      "Quantile Range:  30\n",
      "RF: 0.09 (0.00)\n",
      "Quantile Range:  30\n",
      "RL: 0.55 (0.91)\n",
      "Quantile Range:  30\n",
      "SVR: 0.11 (0.05)\n",
      "CPU times: total: 45.4 s\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "for value in [1, 5, 10, 15, 20, 25, 30]:\n",
    "    for model_name, model in modelos.items():\n",
    "\n",
    "        scal = ColumnTransformer([('numeric', RobustScaler(quantile_range=(value, 100-value)), numeric_columns)], remainder='passthrough')\n",
    "\n",
    "        pip = Pipeline(steps=[('scaler', scal),\n",
    "                              ('model',  model)])\n",
    "\n",
    "        # preparar el procedimiento de cross-validation \n",
    "        cv = KFold(n_splits=5)\n",
    "        # evaluar el modelo\n",
    "        cv_results = cross_validate(pip, X, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "        \n",
    "        print('Quantile Range: ', value)\n",
    "        print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                             - mean(cv_results['test_score']), \n",
    "                                             std(cv_results['test_score'])))\n",
    "\n",
    "        scores.loc[len(scores)] = [model_name,\n",
    "                                   'RobustScaling - ' + str(value),\n",
    "                                   - mean(cv_results['test_score']),\n",
    "                                   std(cv_results['test_score']),\n",
    "                                   scal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55726da3-1ed4-4ad5-b5be-dbc44103121f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de escalado</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Escalador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF</td>\n",
       "      <td>RobustScaling - 10</td>\n",
       "      <td>0.085048</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF</td>\n",
       "      <td>RobustScaling - 1</td>\n",
       "      <td>0.085066</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF</td>\n",
       "      <td>RobustScaling - 15</td>\n",
       "      <td>0.085069</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF</td>\n",
       "      <td>RobustScaling - 5</td>\n",
       "      <td>0.085070</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RF</td>\n",
       "      <td>RobustScaling - 25</td>\n",
       "      <td>0.085098</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RF</td>\n",
       "      <td>RobustScaling - 30</td>\n",
       "      <td>0.085104</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RF</td>\n",
       "      <td>RobustScaling - 20</td>\n",
       "      <td>0.085115</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RobustScaling - 25</td>\n",
       "      <td>0.103662</td>\n",
       "      <td>0.049730</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RobustScaling - 20</td>\n",
       "      <td>0.104435</td>\n",
       "      <td>0.049050</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RobustScaling - 15</td>\n",
       "      <td>0.105676</td>\n",
       "      <td>0.046963</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RobustScaling - 30</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>0.049326</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RobustScaling - 10</td>\n",
       "      <td>0.108456</td>\n",
       "      <td>0.044584</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RobustScaling - 5</td>\n",
       "      <td>0.113285</td>\n",
       "      <td>0.041231</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RobustScaling - 1</td>\n",
       "      <td>0.118877</td>\n",
       "      <td>0.037948</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RL</td>\n",
       "      <td>RobustScaling - 20</td>\n",
       "      <td>0.545784</td>\n",
       "      <td>0.911876</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RL</td>\n",
       "      <td>RobustScaling - 30</td>\n",
       "      <td>0.545913</td>\n",
       "      <td>0.912142</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RL</td>\n",
       "      <td>RobustScaling - 15</td>\n",
       "      <td>0.545914</td>\n",
       "      <td>0.912142</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RL</td>\n",
       "      <td>RobustScaling - 5</td>\n",
       "      <td>0.545917</td>\n",
       "      <td>0.912141</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RL</td>\n",
       "      <td>RobustScaling - 25</td>\n",
       "      <td>0.545917</td>\n",
       "      <td>0.912141</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RL</td>\n",
       "      <td>RobustScaling - 1</td>\n",
       "      <td>0.546490</td>\n",
       "      <td>0.911856</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RL</td>\n",
       "      <td>RobustScaling - 10</td>\n",
       "      <td>0.546809</td>\n",
       "      <td>0.911696</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Modelo Estrategia de escalado  RMSE (mean)  RMSE (std)  \\\n",
       "12     RF     RobustScaling - 10     0.085048    0.002791   \n",
       "6      RF      RobustScaling - 1     0.085066    0.002783   \n",
       "15     RF     RobustScaling - 15     0.085069    0.002852   \n",
       "9      RF      RobustScaling - 5     0.085070    0.002753   \n",
       "21     RF     RobustScaling - 25     0.085098    0.002736   \n",
       "24     RF     RobustScaling - 30     0.085104    0.002828   \n",
       "18     RF     RobustScaling - 20     0.085115    0.002825   \n",
       "23    SVR     RobustScaling - 25     0.103662    0.049730   \n",
       "20    SVR     RobustScaling - 20     0.104435    0.049050   \n",
       "17    SVR     RobustScaling - 15     0.105676    0.046963   \n",
       "26    SVR     RobustScaling - 30     0.105894    0.049326   \n",
       "14    SVR     RobustScaling - 10     0.108456    0.044584   \n",
       "11    SVR      RobustScaling - 5     0.113285    0.041231   \n",
       "8     SVR      RobustScaling - 1     0.118877    0.037948   \n",
       "19     RL     RobustScaling - 20     0.545784    0.911876   \n",
       "25     RL     RobustScaling - 30     0.545913    0.912142   \n",
       "16     RL     RobustScaling - 15     0.545914    0.912142   \n",
       "10     RL      RobustScaling - 5     0.545917    0.912141   \n",
       "22     RL     RobustScaling - 25     0.545917    0.912141   \n",
       "7      RL      RobustScaling - 1     0.546490    0.911856   \n",
       "13     RL     RobustScaling - 10     0.546809    0.911696   \n",
       "\n",
       "                                            Escalador  \n",
       "12  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "6   ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "15  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "9   ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "21  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "24  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "18  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "23  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "20  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "17  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "26  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "14  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "11  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "8   ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "19  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "25  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "16  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "10  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "22  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "7   ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "13  ColumnTransformer(remainder='passthrough',\\n  ...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['Estrategia de escalado'].str[0:13] == 'RobustScaling'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac1785a-e502-4d2e-9181-3fe9adcc4341",
   "metadata": {},
   "source": [
    "#### 2.5.4. Transformación de los datos mediante Power Transform (PT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ebcf9-66bd-457b-96bb-381f20cf0c9e",
   "metadata": {},
   "source": [
    "Para el método de transformación de la distribución de los datos Power Transform, utilizamos los métodos de Yeo-Johnson y Box-Cox. Para este segundo, debemos asegurarnos de que los datos son positivos, por lo que tendremos que aplicar una estandarización previa de los valores de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7fd3b207-f9f0-42a8-833b-adb3e5786ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerTransformation - yeo-johnson - St.: False\n",
      "RF: 0.09 (0.00)\n",
      "PowerTransformation - yeo-johnson - St.: False\n",
      "RL: 0.11 (0.01)\n",
      "PowerTransformation - yeo-johnson - St.: False\n",
      "SVR: 0.14 (0.05)\n",
      "PowerTransformation - yeo-johnson - St.: True\n",
      "RF: 0.09 (0.00)\n",
      "PowerTransformation - yeo-johnson - St.: True\n",
      "RL: 0.05 (0.02)\n",
      "PowerTransformation - yeo-johnson - St.: True\n",
      "SVR: 0.09 (0.02)\n",
      "CPU times: total: 15.8 s\n",
      "Wall time: 9.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "for method in ['yeo-johnson'\n",
    "               # , 'box-cox' # Debemos escalar los valores para hacerlos positivos estrictamente\n",
    "              ]:\n",
    "    for standardize in [False, True]:\n",
    "        for model_name, model in modelos.items():\n",
    "\n",
    "            scal = ColumnTransformer([('numeric',  PowerTransformer(method=method, standardize=standardize), numeric_columns)], remainder='passthrough')\n",
    "\n",
    "            pip = Pipeline(steps=[('scaler', scal),\n",
    "                                  ('model',  model)])\n",
    "\n",
    "            # preparar el procedimiento de cross-validation \n",
    "            cv = KFold(n_splits=5)\n",
    "            # evaluar el modelo\n",
    "            cv_results = cross_validate(pip, X, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "            print('PowerTransformation - ' + str(method) + ' - St.: ' + str(standardize))\n",
    "            print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                                 - mean(cv_results['test_score']), \n",
    "                                                 std(cv_results['test_score'])))\n",
    "\n",
    "            scores.loc[len(scores)] = [model_name,\n",
    "                                       'PowerTransformation - ' + str(method) + ' - St.: ' + str(standardize),\n",
    "                                       - mean(cv_results['test_score']),\n",
    "                                       std(cv_results['test_score']),\n",
    "                                       scal]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1595904-607d-4db9-b193-514324ffde62",
   "metadata": {},
   "source": [
    "Para evitar posibles problemas futuros, escalamos entre 1 y 2, con el fin de que no exista ningún futuro valor atípico en el conjunto de predicción que se haga negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bad18100-e281-4710-9adc-b488bc87c4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerTransformation - yeo-johnson - PreNormalized - St.: False\n",
      "RF: 0.10 (0.01)\n",
      "PowerTransformation - yeo-johnson - PreNormalized - St.: False\n",
      "RL: 0.28 (0.22)\n",
      "PowerTransformation - yeo-johnson - PreNormalized - St.: False\n",
      "SVR: 0.11 (0.01)\n",
      "PowerTransformation - yeo-johnson - PreNormalized - St.: True\n",
      "RF: 0.09 (0.00)\n",
      "PowerTransformation - yeo-johnson - PreNormalized - St.: True\n",
      "RL: 0.07 (0.01)\n",
      "PowerTransformation - yeo-johnson - PreNormalized - St.: True\n",
      "SVR: 0.09 (0.01)\n",
      "PowerTransformation - box-cox - PreNormalized - St.: False\n",
      "RF: 0.08 (0.00)\n",
      "PowerTransformation - box-cox - PreNormalized - St.: False\n",
      "RL: 0.06 (0.01)\n",
      "PowerTransformation - box-cox - PreNormalized - St.: False\n",
      "SVR: 0.10 (0.01)\n",
      "PowerTransformation - box-cox - PreNormalized - St.: True\n",
      "RF: 0.09 (0.00)\n",
      "PowerTransformation - box-cox - PreNormalized - St.: True\n",
      "RL: 0.06 (0.01)\n",
      "PowerTransformation - box-cox - PreNormalized - St.: True\n",
      "SVR: 0.08 (0.01)\n",
      "CPU times: total: 29.7 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "for method in ['yeo-johnson', 'box-cox']:\n",
    "    for standardize in [False, True]:\n",
    "        for model_name, model in modelos.items():\n",
    "\n",
    "            nor_pt = Pipeline(steps=[('normalize', MinMaxScaler(feature_range=(1, 2))),\n",
    "                                  ('powertransformation',  PowerTransformer(method=method, standardize=standardize))])\n",
    "            \n",
    "            scal = ColumnTransformer([('numeric',  nor_pt, numeric_columns)], remainder='passthrough')\n",
    "\n",
    "            pip = Pipeline(steps=[('scaler', scal),\n",
    "                                  ('model',  model)])\n",
    "\n",
    "            # preparar el procedimiento de cross-validation \n",
    "            cv = KFold(n_splits=5)\n",
    "            # evaluar el modelo\n",
    "            cv_results = cross_validate(pip, X, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "            print('PowerTransformation - ' + str(method) + ' - PreNormalized - St.: ' + str(standardize))\n",
    "            print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                                 - mean(cv_results['test_score']), \n",
    "                                                 std(cv_results['test_score'])))\n",
    "\n",
    "            scores.loc[len(scores)] = [model_name,\n",
    "                                       'PowerTransformation - ' + str(method) + ' - PreNormalized - St.: ' + str(standardize),\n",
    "                                       - mean(cv_results['test_score']),\n",
    "                                       std(cv_results['test_score']),\n",
    "                                       scal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d85acf0f-a952-4d25-a9fb-7ff1bc2fcc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de escalado</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Escalador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RL</td>\n",
       "      <td>PowerTransformation - yeo-johnson - St.: True</td>\n",
       "      <td>0.054572</td>\n",
       "      <td>0.016838</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RL</td>\n",
       "      <td>PowerTransformation - box-cox - PreNormalized ...</td>\n",
       "      <td>0.061422</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RL</td>\n",
       "      <td>PowerTransformation - box-cox - PreNormalized ...</td>\n",
       "      <td>0.061422</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RL</td>\n",
       "      <td>PowerTransformation - yeo-johnson - PreNormali...</td>\n",
       "      <td>0.070943</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SVR</td>\n",
       "      <td>PowerTransformation - box-cox - PreNormalized ...</td>\n",
       "      <td>0.084248</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RF</td>\n",
       "      <td>PowerTransformation - box-cox - PreNormalized ...</td>\n",
       "      <td>0.084969</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RF</td>\n",
       "      <td>PowerTransformation - box-cox - PreNormalized ...</td>\n",
       "      <td>0.085039</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RF</td>\n",
       "      <td>PowerTransformation - yeo-johnson - St.: False</td>\n",
       "      <td>0.086051</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RF</td>\n",
       "      <td>PowerTransformation - yeo-johnson - St.: True</td>\n",
       "      <td>0.086051</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVR</td>\n",
       "      <td>PowerTransformation - yeo-johnson - St.: True</td>\n",
       "      <td>0.087525</td>\n",
       "      <td>0.019676</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RF</td>\n",
       "      <td>PowerTransformation - yeo-johnson - PreNormali...</td>\n",
       "      <td>0.091690</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVR</td>\n",
       "      <td>PowerTransformation - yeo-johnson - PreNormali...</td>\n",
       "      <td>0.092820</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVR</td>\n",
       "      <td>PowerTransformation - box-cox - PreNormalized ...</td>\n",
       "      <td>0.099845</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RF</td>\n",
       "      <td>PowerTransformation - yeo-johnson - PreNormali...</td>\n",
       "      <td>0.103142</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVR</td>\n",
       "      <td>PowerTransformation - yeo-johnson - PreNormali...</td>\n",
       "      <td>0.107612</td>\n",
       "      <td>0.007465</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RL</td>\n",
       "      <td>PowerTransformation - yeo-johnson - St.: False</td>\n",
       "      <td>0.108535</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVR</td>\n",
       "      <td>PowerTransformation - yeo-johnson - St.: False</td>\n",
       "      <td>0.136409</td>\n",
       "      <td>0.049405</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RL</td>\n",
       "      <td>PowerTransformation - yeo-johnson - PreNormali...</td>\n",
       "      <td>0.284365</td>\n",
       "      <td>0.220360</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Modelo                             Estrategia de escalado  RMSE (mean)  \\\n",
       "31     RL      PowerTransformation - yeo-johnson - St.: True     0.054572   \n",
       "40     RL  PowerTransformation - box-cox - PreNormalized ...     0.061422   \n",
       "43     RL  PowerTransformation - box-cox - PreNormalized ...     0.061422   \n",
       "37     RL  PowerTransformation - yeo-johnson - PreNormali...     0.070943   \n",
       "44    SVR  PowerTransformation - box-cox - PreNormalized ...     0.084248   \n",
       "39     RF  PowerTransformation - box-cox - PreNormalized ...     0.084969   \n",
       "42     RF  PowerTransformation - box-cox - PreNormalized ...     0.085039   \n",
       "27     RF     PowerTransformation - yeo-johnson - St.: False     0.086051   \n",
       "30     RF      PowerTransformation - yeo-johnson - St.: True     0.086051   \n",
       "32    SVR      PowerTransformation - yeo-johnson - St.: True     0.087525   \n",
       "36     RF  PowerTransformation - yeo-johnson - PreNormali...     0.091690   \n",
       "38    SVR  PowerTransformation - yeo-johnson - PreNormali...     0.092820   \n",
       "41    SVR  PowerTransformation - box-cox - PreNormalized ...     0.099845   \n",
       "33     RF  PowerTransformation - yeo-johnson - PreNormali...     0.103142   \n",
       "35    SVR  PowerTransformation - yeo-johnson - PreNormali...     0.107612   \n",
       "28     RL     PowerTransformation - yeo-johnson - St.: False     0.108535   \n",
       "29    SVR     PowerTransformation - yeo-johnson - St.: False     0.136409   \n",
       "34     RL  PowerTransformation - yeo-johnson - PreNormali...     0.284365   \n",
       "\n",
       "    RMSE (std)                                          Escalador  \n",
       "31    0.016838  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "40    0.010055  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "43    0.010055  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "37    0.010841  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "44    0.011922  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "39    0.002938  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "42    0.002854  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "27    0.002395  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "30    0.002395  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "32    0.019676  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "36    0.004988  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "38    0.007246  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "41    0.005400  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "33    0.007811  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "35    0.007465  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "28    0.006835  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "29    0.049405  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "34    0.220360  ColumnTransformer(remainder='passthrough',\\n  ...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['Estrategia de escalado'].str[0:19] == 'PowerTransformation'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796fe8d-9ce0-4907-a758-93648cf0902e",
   "metadata": {},
   "source": [
    "#### 2.5.5. Transformación de los datos mediante Quantile Transform (QT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e027afb-e8bf-452c-aadc-51adab994e12",
   "metadata": {},
   "source": [
    "Aplicamos un `QuantileTransformer` a los datos para distintos números de cuantiles para los rangos del método y para dos diferentes distribuciones (uniforme y normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a9af4154-8473-4c64-9481-87672f01b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantileTransformation - normal - n_quantiles=10\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=10\n",
      "RL: 0.08 (0.06)\n",
      "QuantileTransformation - normal - n_quantiles=10\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=10\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=10\n",
      "RL: 0.08 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=10\n",
      "SVR: 0.09 (0.01)\n",
      "QuantileTransformation - normal - n_quantiles=25\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=25\n",
      "RL: 0.07 (0.04)\n",
      "QuantileTransformation - normal - n_quantiles=25\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=25\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=25\n",
      "RL: 0.07 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=25\n",
      "SVR: 0.09 (0.01)\n",
      "QuantileTransformation - normal - n_quantiles=50\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=50\n",
      "RL: 0.07 (0.04)\n",
      "QuantileTransformation - normal - n_quantiles=50\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=50\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=50\n",
      "RL: 0.07 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=50\n",
      "SVR: 0.09 (0.01)\n",
      "QuantileTransformation - normal - n_quantiles=75\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=75\n",
      "RL: 0.07 (0.03)\n",
      "QuantileTransformation - normal - n_quantiles=75\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=75\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=75\n",
      "RL: 0.07 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=75\n",
      "SVR: 0.09 (0.01)\n",
      "QuantileTransformation - normal - n_quantiles=100\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=100\n",
      "RL: 0.07 (0.03)\n",
      "QuantileTransformation - normal - n_quantiles=100\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=100\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=100\n",
      "RL: 0.07 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=100\n",
      "SVR: 0.09 (0.01)\n",
      "QuantileTransformation - normal - n_quantiles=200\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=200\n",
      "RL: 0.07 (0.03)\n",
      "QuantileTransformation - normal - n_quantiles=200\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=200\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=200\n",
      "RL: 0.07 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=200\n",
      "SVR: 0.09 (0.01)\n",
      "QuantileTransformation - normal - n_quantiles=500\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=500\n",
      "RL: 0.07 (0.03)\n",
      "QuantileTransformation - normal - n_quantiles=500\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=500\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=500\n",
      "RL: 0.07 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=500\n",
      "SVR: 0.09 (0.01)\n",
      "QuantileTransformation - normal - n_quantiles=1000\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=1000\n",
      "RL: 0.07 (0.03)\n",
      "QuantileTransformation - normal - n_quantiles=1000\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=1000\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=1000\n",
      "RL: 0.07 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=1000\n",
      "SVR: 0.09 (0.01)\n",
      "QuantileTransformation - normal - n_quantiles=1500\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=1500\n",
      "RL: 0.07 (0.03)\n",
      "QuantileTransformation - normal - n_quantiles=1500\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=1500\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=1500\n",
      "RL: 0.07 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=1500\n",
      "SVR: 0.09 (0.01)\n",
      "QuantileTransformation - normal - n_quantiles=2000\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - normal - n_quantiles=2000\n",
      "RL: 0.07 (0.03)\n",
      "QuantileTransformation - normal - n_quantiles=2000\n",
      "SVR: 0.11 (0.04)\n",
      "QuantileTransformation - uniform - n_quantiles=2000\n",
      "RF: 0.09 (0.00)\n",
      "QuantileTransformation - uniform - n_quantiles=2000\n",
      "RL: 0.07 (0.01)\n",
      "QuantileTransformation - uniform - n_quantiles=2000\n",
      "SVR: 0.09 (0.01)\n",
      "CPU times: total: 2min 18s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "for n_quantiles in [10,25,50,75,100,200,500,1000,1500,2000]:\n",
    "    for output_distribution in ['normal', 'uniform']:\n",
    "        for model_name, model in modelos.items():\n",
    "\n",
    "            scal = ColumnTransformer([('numeric',  QuantileTransformer(n_quantiles=n_quantiles, output_distribution=output_distribution), numeric_columns)], remainder='passthrough')\n",
    "\n",
    "            pip = Pipeline(steps=[('scaler', scal),\n",
    "                                  ('model',  model)])\n",
    "\n",
    "            # preparar el procedimiento de cross-validation \n",
    "            cv = KFold(n_splits=5)\n",
    "            # evaluar el modelo\n",
    "            cv_results = cross_validate(pip, X, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "            print('QuantileTransformation - ' + str(output_distribution) + ' - n_quantiles=' + str(n_quantiles))\n",
    "            print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                                 - mean(cv_results['test_score']), \n",
    "                                                 std(cv_results['test_score'])))\n",
    "\n",
    "            scores.loc[len(scores)] = [model_name,\n",
    "                                       'QuantileTransformation - ' + str(output_distribution) + ' - n_quantiles=' + str(n_quantiles),\n",
    "                                       - mean(cv_results['test_score']),\n",
    "                                       std(cv_results['test_score']),\n",
    "                                       scal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0dff1d0e-5d54-46ef-a769-cf89bd93356e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de escalado</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Escalador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=100</td>\n",
       "      <td>0.067026</td>\n",
       "      <td>0.032578</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=200</td>\n",
       "      <td>0.067247</td>\n",
       "      <td>0.030934</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=75</td>\n",
       "      <td>0.068010</td>\n",
       "      <td>0.034812</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.068743</td>\n",
       "      <td>0.032597</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.068743</td>\n",
       "      <td>0.032597</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.069205</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=500</td>\n",
       "      <td>0.069454</td>\n",
       "      <td>0.033428</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=50</td>\n",
       "      <td>0.070828</td>\n",
       "      <td>0.038646</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=25</td>\n",
       "      <td>0.072243</td>\n",
       "      <td>0.042915</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.073937</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.074085</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.074097</td>\n",
       "      <td>0.014186</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=75</td>\n",
       "      <td>0.074135</td>\n",
       "      <td>0.014460</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.074185</td>\n",
       "      <td>0.014089</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.074337</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.074337</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=50</td>\n",
       "      <td>0.074407</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=25</td>\n",
       "      <td>0.074715</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=10</td>\n",
       "      <td>0.076157</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=10</td>\n",
       "      <td>0.082766</td>\n",
       "      <td>0.055889</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=50</td>\n",
       "      <td>0.085176</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=25</td>\n",
       "      <td>0.085190</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=10</td>\n",
       "      <td>0.085230</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=25</td>\n",
       "      <td>0.085264</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=50</td>\n",
       "      <td>0.085272</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.085287</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=10</td>\n",
       "      <td>0.085292</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=100</td>\n",
       "      <td>0.085307</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=200</td>\n",
       "      <td>0.085317</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.085337</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=500</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=75</td>\n",
       "      <td>0.085342</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=75</td>\n",
       "      <td>0.085373</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.085399</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.085419</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.085419</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>RF</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.085424</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.092639</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.092639</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.092643</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.092644</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.092669</td>\n",
       "      <td>0.010266</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles...</td>\n",
       "      <td>0.092696</td>\n",
       "      <td>0.010249</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=75</td>\n",
       "      <td>0.092735</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=50</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=25</td>\n",
       "      <td>0.093005</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - uniform - n_quantiles=10</td>\n",
       "      <td>0.093896</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=75</td>\n",
       "      <td>0.107328</td>\n",
       "      <td>0.039077</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.107479</td>\n",
       "      <td>0.039088</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.107479</td>\n",
       "      <td>0.039088</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=500</td>\n",
       "      <td>0.107496</td>\n",
       "      <td>0.039125</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.107510</td>\n",
       "      <td>0.039155</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=100</td>\n",
       "      <td>0.107512</td>\n",
       "      <td>0.039119</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=50</td>\n",
       "      <td>0.107560</td>\n",
       "      <td>0.039077</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=200</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>0.039181</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=25</td>\n",
       "      <td>0.107982</td>\n",
       "      <td>0.039135</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVR</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=10</td>\n",
       "      <td>0.110079</td>\n",
       "      <td>0.039781</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo                             Estrategia de escalado  RMSE (mean)  \\\n",
       "70      RL  QuantileTransformation - normal - n_quantiles=100     0.067026   \n",
       "76      RL  QuantileTransformation - normal - n_quantiles=200     0.067247   \n",
       "64      RL   QuantileTransformation - normal - n_quantiles=75     0.068010   \n",
       "94      RL  QuantileTransformation - normal - n_quantiles=...     0.068743   \n",
       "100     RL  QuantileTransformation - normal - n_quantiles=...     0.068743   \n",
       "88      RL  QuantileTransformation - normal - n_quantiles=...     0.069205   \n",
       "82      RL  QuantileTransformation - normal - n_quantiles=500     0.069454   \n",
       "58      RL   QuantileTransformation - normal - n_quantiles=50     0.070828   \n",
       "52      RL   QuantileTransformation - normal - n_quantiles=25     0.072243   \n",
       "73      RL  QuantileTransformation - uniform - n_quantiles...     0.073937   \n",
       "79      RL  QuantileTransformation - uniform - n_quantiles...     0.074085   \n",
       "85      RL  QuantileTransformation - uniform - n_quantiles...     0.074097   \n",
       "67      RL  QuantileTransformation - uniform - n_quantiles=75     0.074135   \n",
       "91      RL  QuantileTransformation - uniform - n_quantiles...     0.074185   \n",
       "97      RL  QuantileTransformation - uniform - n_quantiles...     0.074337   \n",
       "103     RL  QuantileTransformation - uniform - n_quantiles...     0.074337   \n",
       "61      RL  QuantileTransformation - uniform - n_quantiles=50     0.074407   \n",
       "55      RL  QuantileTransformation - uniform - n_quantiles=25     0.074715   \n",
       "49      RL  QuantileTransformation - uniform - n_quantiles=10     0.076157   \n",
       "46      RL   QuantileTransformation - normal - n_quantiles=10     0.082766   \n",
       "60      RF  QuantileTransformation - uniform - n_quantiles=50     0.085176   \n",
       "54      RF  QuantileTransformation - uniform - n_quantiles=25     0.085190   \n",
       "48      RF  QuantileTransformation - uniform - n_quantiles=10     0.085230   \n",
       "51      RF   QuantileTransformation - normal - n_quantiles=25     0.085264   \n",
       "57      RF   QuantileTransformation - normal - n_quantiles=50     0.085272   \n",
       "72      RF  QuantileTransformation - uniform - n_quantiles...     0.085287   \n",
       "45      RF   QuantileTransformation - normal - n_quantiles=10     0.085292   \n",
       "69      RF  QuantileTransformation - normal - n_quantiles=100     0.085307   \n",
       "75      RF  QuantileTransformation - normal - n_quantiles=200     0.085317   \n",
       "87      RF  QuantileTransformation - normal - n_quantiles=...     0.085337   \n",
       "81      RF  QuantileTransformation - normal - n_quantiles=500     0.085340   \n",
       "99      RF  QuantileTransformation - normal - n_quantiles=...     0.085340   \n",
       "93      RF  QuantileTransformation - normal - n_quantiles=...     0.085340   \n",
       "63      RF   QuantileTransformation - normal - n_quantiles=75     0.085342   \n",
       "78      RF  QuantileTransformation - uniform - n_quantiles...     0.085366   \n",
       "66      RF  QuantileTransformation - uniform - n_quantiles=75     0.085373   \n",
       "90      RF  QuantileTransformation - uniform - n_quantiles...     0.085399   \n",
       "102     RF  QuantileTransformation - uniform - n_quantiles...     0.085419   \n",
       "96      RF  QuantileTransformation - uniform - n_quantiles...     0.085419   \n",
       "84      RF  QuantileTransformation - uniform - n_quantiles...     0.085424   \n",
       "98     SVR  QuantileTransformation - uniform - n_quantiles...     0.092639   \n",
       "104    SVR  QuantileTransformation - uniform - n_quantiles...     0.092639   \n",
       "86     SVR  QuantileTransformation - uniform - n_quantiles...     0.092643   \n",
       "92     SVR  QuantileTransformation - uniform - n_quantiles...     0.092644   \n",
       "74     SVR  QuantileTransformation - uniform - n_quantiles...     0.092669   \n",
       "80     SVR  QuantileTransformation - uniform - n_quantiles...     0.092696   \n",
       "68     SVR  QuantileTransformation - uniform - n_quantiles=75     0.092735   \n",
       "62     SVR  QuantileTransformation - uniform - n_quantiles=50     0.092779   \n",
       "56     SVR  QuantileTransformation - uniform - n_quantiles=25     0.093005   \n",
       "50     SVR  QuantileTransformation - uniform - n_quantiles=10     0.093896   \n",
       "65     SVR   QuantileTransformation - normal - n_quantiles=75     0.107328   \n",
       "101    SVR  QuantileTransformation - normal - n_quantiles=...     0.107479   \n",
       "95     SVR  QuantileTransformation - normal - n_quantiles=...     0.107479   \n",
       "83     SVR  QuantileTransformation - normal - n_quantiles=500     0.107496   \n",
       "89     SVR  QuantileTransformation - normal - n_quantiles=...     0.107510   \n",
       "71     SVR  QuantileTransformation - normal - n_quantiles=100     0.107512   \n",
       "59     SVR   QuantileTransformation - normal - n_quantiles=50     0.107560   \n",
       "77     SVR  QuantileTransformation - normal - n_quantiles=200     0.107686   \n",
       "53     SVR   QuantileTransformation - normal - n_quantiles=25     0.107982   \n",
       "47     SVR   QuantileTransformation - normal - n_quantiles=10     0.110079   \n",
       "\n",
       "     RMSE (std)                                          Escalador  \n",
       "70     0.032578  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "76     0.030934  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "64     0.034812  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "94     0.032597  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "100    0.032597  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "88     0.033134  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "82     0.033428  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "58     0.038646  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "52     0.042915  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "73     0.014225  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "79     0.014142  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "85     0.014186  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "67     0.014460  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "91     0.014089  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "97     0.013933  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "103    0.013933  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "61     0.014572  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "55     0.014085  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "49     0.014269  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "46     0.055889  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "60     0.002948  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "54     0.002944  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "48     0.002895  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "51     0.002671  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "57     0.002647  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "72     0.002932  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "45     0.002705  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "69     0.002582  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "75     0.002652  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "87     0.002555  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "81     0.002588  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "99     0.002544  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "93     0.002544  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "63     0.002628  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "78     0.002910  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "66     0.002955  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "90     0.002921  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "102    0.002805  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "96     0.002805  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "84     0.002913  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "98     0.010265  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "104    0.010265  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "86     0.010248  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "92     0.010239  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "74     0.010266  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "80     0.010249  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "68     0.010390  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "62     0.010185  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "56     0.010093  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "50     0.009884  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "65     0.039077  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "101    0.039088  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "95     0.039088  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "83     0.039125  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "89     0.039155  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "71     0.039119  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "59     0.039077  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "77     0.039181  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "53     0.039135  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "47     0.039781  ColumnTransformer(remainder='passthrough',\\n  ...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['Estrategia de escalado'].str[0:22] == 'QuantileTransformation'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a6806-ae9c-4818-a637-b30203217059",
   "metadata": {},
   "source": [
    "#### 2.5.6. Discretización de los datos mediante KBinsDiscretizer (KBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a6f94c-9235-47d8-b016-7ff7f14f1e22",
   "metadata": {},
   "source": [
    "Por último, aplicamos un `KBinsDiscretizer` para discretizar nuestros datos en base a diferentes números de intervalos y distintas estrategias. Desgraciadamente, las distribuciones del dataset no se comportan correctamente con el método `'kmeans'`, por lo que tenemos que descartarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "70b0ad7b-ccc5-4f7c-a599-c6379a186715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBinsDiscretization - uniform (onehot) - n_bins=8\n",
      "RF: 0.11 (0.00)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=8\n",
      "RL: 269974360639.88 (382782793887.84)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=8\n",
      "SVR: 0.12 (0.01)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=8\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=8\n",
      "RL: 368468839691.69 (359988612749.93)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=8\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=8\n",
      "RF: 0.11 (0.00)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=8\n",
      "RL: 269974360639.88 (382782793887.84)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=8\n",
      "SVR: 0.12 (0.01)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=8\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=8\n",
      "RL: 368468839691.69 (359988612749.93)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=8\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=8\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=8\n",
      "RL: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=8\n",
      "SVR: 0.12 (0.02)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=8\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=8\n",
      "RL: 0.09 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=8\n",
      "SVR: 0.08 (0.01)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=9\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=9\n",
      "RL: 260028118538.71 (500623457862.63)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=9\n",
      "SVR: 0.12 (0.02)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=9\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=9\n",
      "RL: 0.08 (0.01)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=9\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=9\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=9\n",
      "RL: 260028118538.71 (500623457862.63)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=9\n",
      "SVR: 0.12 (0.02)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=9\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=9\n",
      "RL: 0.08 (0.01)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=9\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=9\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=9\n",
      "RL: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=9\n",
      "SVR: 0.12 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=9\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=9\n",
      "RL: 0.08 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=9\n",
      "SVR: 0.08 (0.01)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=10\n",
      "RF: 0.11 (0.00)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=10\n",
      "RL: 335695234209.76 (587062056104.62)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=10\n",
      "SVR: 0.12 (0.02)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=10\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=10\n",
      "RL: 40227196037.49 (80454392074.82)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=10\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=10\n",
      "RF: 0.11 (0.00)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=10\n",
      "RL: 335695234209.76 (587062056104.62)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=10\n",
      "SVR: 0.12 (0.02)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=10\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=10\n",
      "RL: 40227196037.49 (80454392074.82)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=10\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=10\n",
      "RF: 0.11 (0.00)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=10\n",
      "RL: 0.11 (0.00)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=10\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=10\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=10\n",
      "RL: 0.08 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=10\n",
      "SVR: 0.08 (0.01)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=11\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=11\n",
      "RL: 0.11 (0.02)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=11\n",
      "SVR: 0.12 (0.02)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=11\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=11\n",
      "RL: 0.07 (0.01)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=11\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=11\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=11\n",
      "RL: 386260274019.19 (591136513135.61)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=11\n",
      "SVR: 0.12 (0.02)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=11\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=11\n",
      "RL: 0.07 (0.01)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=11\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=11\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=11\n",
      "RL: 0.10 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=11\n",
      "SVR: 0.11 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=11\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=11\n",
      "RL: 0.08 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=11\n",
      "SVR: 0.08 (0.01)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=12\n",
      "RF: 0.11 (0.00)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=12\n",
      "RL: 0.11 (0.03)\n",
      "KBinsDiscretization - uniform (onehot) - n_bins=12\n",
      "SVR: 0.12 (0.02)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=12\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=12\n",
      "RL: 0.07 (0.01)\n",
      "KBinsDiscretization - quantile (onehot) - n_bins=12\n",
      "SVR: 0.12 (0.01)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=12\n",
      "RF: 0.11 (0.00)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=12\n",
      "RL: 326166719506.86 (592907613513.54)\n",
      "KBinsDiscretization - uniform (onehot-dense) - n_bins=12\n",
      "SVR: 0.12 (0.02)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=12\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=12\n",
      "RL: 479809766780.17 (579450649978.47)\n",
      "KBinsDiscretization - quantile (onehot-dense) - n_bins=12\n",
      "SVR: 0.12 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=12\n",
      "RF: 0.11 (0.01)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=12\n",
      "RL: 0.10 (0.00)\n",
      "KBinsDiscretization - uniform (ordinal) - n_bins=12\n",
      "SVR: 0.11 (0.02)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=12\n",
      "RF: 0.10 (0.00)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=12\n",
      "RL: 0.08 (0.01)\n",
      "KBinsDiscretization - quantile (ordinal) - n_bins=12\n",
      "SVR: 0.07 (0.01)\n",
      "CPU times: total: 3min 55s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "for n_bins in range(8,13):\n",
    "    for encode in ['onehot', 'onehot-dense', 'ordinal']:\n",
    "        for strategy in ['uniform', 'quantile', \n",
    "                         # 'kmeans'\n",
    "                        ]:\n",
    "            for model_name, model in modelos.items():\n",
    "\n",
    "                scal = ColumnTransformer([('numeric',  KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy), numeric_columns)], remainder='passthrough')\n",
    "\n",
    "                pip = Pipeline(steps=[('scaler', scal),\n",
    "                                      ('model',  model)])\n",
    "\n",
    "                # preparar el procedimiento de cross-validation \n",
    "                cv = KFold(n_splits=5)\n",
    "                # evaluar el modelo\n",
    "                cv_results = cross_validate(pip, X, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "                print('KBinsDiscretization - ' + str(strategy) + ' (' + str(encode) + ') - n_bins=' + str(n_bins))\n",
    "                print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                                     - mean(cv_results['test_score']), \n",
    "                                                     std(cv_results['test_score'])))\n",
    "\n",
    "                scores.loc[len(scores)] = [model_name,\n",
    "                                           'KBinsDiscretization - ' + str(strategy) + ' (' + str(encode) + ') - n_bins=' + str(n_bins),\n",
    "                                           - mean(cv_results['test_score']),\n",
    "                                           std(cv_results['test_score']),\n",
    "                                           scal]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d93e61-edd6-4b98-85e3-29efd2aa8002",
   "metadata": {},
   "source": [
    "En la siguiente celda podemos ver el resultado que obtenemos si tratamos de probar el método con los datos bajo la estrategia K-Means. Obtenemos valores `nan` en las medias y desviaciones típicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1b2fc8e9-f70b-443e-a6af-2e17e8a0952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBinsDiscretization - kmeans (onehot) - n_bins=8\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - kmeans (onehot) - n_bins=8\n",
      "RL: 182022174825.37 (250638616211.09)\n",
      "KBinsDiscretization - kmeans (onehot) - n_bins=8\n",
      "SVR: 0.12 (0.01)\n",
      "KBinsDiscretization - kmeans (onehot-dense) - n_bins=8\n",
      "RF: 0.10 (0.01)\n",
      "KBinsDiscretization - kmeans (onehot-dense) - n_bins=8\n",
      "RL: 182022174825.37 (250638616211.09)\n",
      "KBinsDiscretization - kmeans (onehot-dense) - n_bins=8\n",
      "SVR: 0.12 (0.01)\n",
      "KBinsDiscretization - kmeans (ordinal) - n_bins=8\n",
      "RF: 0.09 (0.00)\n",
      "KBinsDiscretization - kmeans (ordinal) - n_bins=8\n",
      "RL: 0.08 (0.01)\n",
      "KBinsDiscretization - kmeans (ordinal) - n_bins=8\n",
      "SVR: 0.08 (0.01)\n",
      "CPU times: total: 12min 28s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "for n_bins in [8]:\n",
    "    for encode in ['onehot', 'onehot-dense', 'ordinal']:\n",
    "        for strategy in ['kmeans']:\n",
    "            for model_name, model in modelos.items():\n",
    "\n",
    "                nor_pt_kbd = Pipeline(steps=[('normalize', MinMaxScaler(feature_range=(0, 1))),\n",
    "                                      ('powertransformation',  PowerTransformer(method='yeo-johnson')),\n",
    "                                        ('KBD_Kmeans', KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy))])\n",
    "\n",
    "                scal = ColumnTransformer([('numeric',  nor_pt_kbd, numeric_columns)], remainder='passthrough')\n",
    "\n",
    "                pip = Pipeline(steps=[('scaler', scal),\n",
    "                                      ('model',  model)])\n",
    "\n",
    "                # preparar el procedimiento de cross-validation \n",
    "                cv = KFold(n_splits=5)\n",
    "                # evaluar el modelo\n",
    "                cv_results = cross_validate(pip, X, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "                print('KBinsDiscretization - ' + str(strategy) + ' (' + str(encode) + ') - n_bins=' + str(n_bins))\n",
    "                print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                                     - mean(cv_results['test_score']), \n",
    "                                                     std(cv_results['test_score'])))\n",
    "\n",
    "                # scores.loc[len(scores)] = [model_name,\n",
    "                #                            'KBinsDiscretization - ' + str(strategy) + ' (' + str(encode) + ') - n_bins=' + str(n_bins),\n",
    "                #                            - mean(cv_results['test_score']),\n",
    "                #                            std(cv_results['test_score']),\n",
    "                #                            scal]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760b761-483b-4d7b-bfc6-4caef8664373",
   "metadata": {},
   "source": [
    "Vemos que el error radica en que no es capaz de determinar una configuración adecuada. El error puede deberse a que la distribución de los datos es demasiado dispar en algunas variables, lo que hace que sea más complicado determinar los intervalos. Esto podría, quizá, solucionarse utilizando un método de identificación de outliers previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "154fbe31-0d4c-42bd-852b-5d4e186c928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nor_pt_kbd = Pipeline(steps=[('normalize', MinMaxScaler(feature_range=(0, 1))),\n",
    "#                       ('powertransformation',  PowerTransformer(method='yeo-johnson')),\n",
    "#                         ('KBD_Kmeans', KBinsDiscretizer(n_bins=8, encode='onehot', strategy='kmeans'))])\n",
    "\n",
    "# scal = ColumnTransformer([('numeric',  nor_pt_kbd, numeric_columns)], remainder='passthrough')\n",
    "\n",
    "# pip = Pipeline(steps=[('scaler', scal),\n",
    "#                       ('model',  model)])\n",
    "\n",
    "# pip.fit(X)\n",
    "# X_scal_aux = pip.transform(X)"
   ]
  },
  {
   "attachments": {
    "6825af41-5f74-4d11-8c35-c1d38da06999.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "823cdd7a-2f12-485e-8a97-9c9cff69c01d",
   "metadata": {},
   "source": [
    "![Screenshot_1.png](attachment:6825af41-5f74-4d11-8c35-c1d38da06999.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a2187f28-d7d0-4907-957c-9b631f7045ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de escalado</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Escalador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>RL</td>\n",
       "      <td>KBinsDiscretization - quantile (onehot) - n_bi...</td>\n",
       "      <td>7.027775e-02</td>\n",
       "      <td>1.033021e-02</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>RL</td>\n",
       "      <td>KBinsDiscretization - quantile (onehot-dense) ...</td>\n",
       "      <td>7.051469e-02</td>\n",
       "      <td>1.176822e-02</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>RL</td>\n",
       "      <td>KBinsDiscretization - quantile (onehot) - n_bi...</td>\n",
       "      <td>7.051469e-02</td>\n",
       "      <td>1.176822e-02</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>SVR</td>\n",
       "      <td>KBinsDiscretization - quantile (ordinal) - n_b...</td>\n",
       "      <td>7.461505e-02</td>\n",
       "      <td>1.373155e-02</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>RL</td>\n",
       "      <td>KBinsDiscretization - quantile (ordinal) - n_b...</td>\n",
       "      <td>7.530219e-02</td>\n",
       "      <td>1.452484e-02</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>RL</td>\n",
       "      <td>KBinsDiscretization - uniform (onehot) - n_bin...</td>\n",
       "      <td>3.356952e+11</td>\n",
       "      <td>5.870621e+11</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>RL</td>\n",
       "      <td>KBinsDiscretization - quantile (onehot-dense) ...</td>\n",
       "      <td>3.684688e+11</td>\n",
       "      <td>3.599886e+11</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>RL</td>\n",
       "      <td>KBinsDiscretization - quantile (onehot) - n_bi...</td>\n",
       "      <td>3.684688e+11</td>\n",
       "      <td>3.599886e+11</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>RL</td>\n",
       "      <td>KBinsDiscretization - uniform (onehot-dense) -...</td>\n",
       "      <td>3.862603e+11</td>\n",
       "      <td>5.911365e+11</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>RL</td>\n",
       "      <td>KBinsDiscretization - quantile (onehot-dense) ...</td>\n",
       "      <td>4.798098e+11</td>\n",
       "      <td>5.794506e+11</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo                             Estrategia de escalado   RMSE (mean)  \\\n",
       "181     RL  KBinsDiscretization - quantile (onehot) - n_bi...  7.027775e-02   \n",
       "169     RL  KBinsDiscretization - quantile (onehot-dense) ...  7.051469e-02   \n",
       "163     RL  KBinsDiscretization - quantile (onehot) - n_bi...  7.051469e-02   \n",
       "194    SVR  KBinsDiscretization - quantile (ordinal) - n_b...  7.461505e-02   \n",
       "193     RL  KBinsDiscretization - quantile (ordinal) - n_b...  7.530219e-02   \n",
       "..     ...                                                ...           ...   \n",
       "142     RL  KBinsDiscretization - uniform (onehot) - n_bin...  3.356952e+11   \n",
       "115     RL  KBinsDiscretization - quantile (onehot-dense) ...  3.684688e+11   \n",
       "109     RL  KBinsDiscretization - quantile (onehot) - n_bi...  3.684688e+11   \n",
       "166     RL  KBinsDiscretization - uniform (onehot-dense) -...  3.862603e+11   \n",
       "187     RL  KBinsDiscretization - quantile (onehot-dense) ...  4.798098e+11   \n",
       "\n",
       "       RMSE (std)                                          Escalador  \n",
       "181  1.033021e-02  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "169  1.176822e-02  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "163  1.176822e-02  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "194  1.373155e-02  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "193  1.452484e-02  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "..            ...                                                ...  \n",
       "142  5.870621e+11  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "115  3.599886e+11  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "109  3.599886e+11  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "166  5.911365e+11  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "187  5.794506e+11  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[scores['Estrategia de escalado'].str[0:19] == 'KBinsDiscretization'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce2ed3e-5f73-46cf-b0fa-273d3c381a3d",
   "metadata": {},
   "source": [
    "#### 2.5.7. Contraste de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd9800-796d-4254-bdbb-1e4c61a58501",
   "metadata": {},
   "source": [
    "Vemos que los mejores métodos de escalado que podemos identificar para nuestro problema son los Power Transformers y los Quantile Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "05374a1c-db6d-45c8-97c2-84660cf3f010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de escalado</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Escalador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RL</td>\n",
       "      <td>PowerTransformation - yeo-johnson - St.: True</td>\n",
       "      <td>0.054572</td>\n",
       "      <td>0.016838</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RL</td>\n",
       "      <td>PowerTransformation - box-cox - PreNormalized ...</td>\n",
       "      <td>0.061422</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RL</td>\n",
       "      <td>PowerTransformation - box-cox - PreNormalized ...</td>\n",
       "      <td>0.061422</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=100</td>\n",
       "      <td>0.067026</td>\n",
       "      <td>0.032578</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=200</td>\n",
       "      <td>0.067247</td>\n",
       "      <td>0.030934</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=75</td>\n",
       "      <td>0.068010</td>\n",
       "      <td>0.034812</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.068743</td>\n",
       "      <td>0.032597</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.068743</td>\n",
       "      <td>0.032597</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=...</td>\n",
       "      <td>0.069205</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>RL</td>\n",
       "      <td>QuantileTransformation - normal - n_quantiles=500</td>\n",
       "      <td>0.069454</td>\n",
       "      <td>0.033428</td>\n",
       "      <td>ColumnTransformer(remainder='passthrough',\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo                             Estrategia de escalado  RMSE (mean)  \\\n",
       "31      RL      PowerTransformation - yeo-johnson - St.: True     0.054572   \n",
       "40      RL  PowerTransformation - box-cox - PreNormalized ...     0.061422   \n",
       "43      RL  PowerTransformation - box-cox - PreNormalized ...     0.061422   \n",
       "70      RL  QuantileTransformation - normal - n_quantiles=100     0.067026   \n",
       "76      RL  QuantileTransformation - normal - n_quantiles=200     0.067247   \n",
       "64      RL   QuantileTransformation - normal - n_quantiles=75     0.068010   \n",
       "94      RL  QuantileTransformation - normal - n_quantiles=...     0.068743   \n",
       "100     RL  QuantileTransformation - normal - n_quantiles=...     0.068743   \n",
       "88      RL  QuantileTransformation - normal - n_quantiles=...     0.069205   \n",
       "82      RL  QuantileTransformation - normal - n_quantiles=500     0.069454   \n",
       "\n",
       "     RMSE (std)                                          Escalador  \n",
       "31     0.016838  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "40     0.010055  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "43     0.010055  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "70     0.032578  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "76     0.030934  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "64     0.034812  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "94     0.032597  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "100    0.032597  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "88     0.033134  ColumnTransformer(remainder='passthrough',\\n  ...  \n",
       "82     0.033428  ColumnTransformer(remainder='passthrough',\\n  ...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values('RMSE (mean)', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd6b9b-8420-422c-b09f-766f0c5703ae",
   "metadata": {},
   "source": [
    "En las posteriores apartados trabajaremos con el dataset obtenido de aplicar la mejor técnica (aquella que haya dado un mejor resultado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9e615fd9-f01e-49a0-aca6-979e3d97fb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>likedPercent</th>\n",
       "      <th>bbeScore</th>\n",
       "      <th>bbeVotes</th>\n",
       "      <th>price</th>\n",
       "      <th>publishYear</th>\n",
       "      <th>publishMonth</th>\n",
       "      <th>publishDay</th>\n",
       "      <th>awards</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Romanian</th>\n",
       "      <th>x0_Russian</th>\n",
       "      <th>x0_Spanish</th>\n",
       "      <th>x0_Swedish</th>\n",
       "      <th>x0_Turkish</th>\n",
       "      <th>x0_nan</th>\n",
       "      <th>x1_Digital</th>\n",
       "      <th>x1_Hardcover</th>\n",
       "      <th>x1_Paperback</th>\n",
       "      <th>x1_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036449</td>\n",
       "      <td>3.889668</td>\n",
       "      <td>0.97737</td>\n",
       "      <td>2.076857</td>\n",
       "      <td>2.120919</td>\n",
       "      <td>0.155443</td>\n",
       "      <td>0.355131</td>\n",
       "      <td>0.800487</td>\n",
       "      <td>0.337433</td>\n",
       "      <td>2.137796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.627188</td>\n",
       "      <td>2.66361</td>\n",
       "      <td>1.914966</td>\n",
       "      <td>2.065692</td>\n",
       "      <td>2.107529</td>\n",
       "      <td>0.727047</td>\n",
       "      <td>-0.064841</td>\n",
       "      <td>0.800487</td>\n",
       "      <td>1.183032</td>\n",
       "      <td>1.59853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.208139</td>\n",
       "      <td>3.410156</td>\n",
       "      <td>0.57396</td>\n",
       "      <td>2.052021</td>\n",
       "      <td>2.091316</td>\n",
       "      <td>-0.239766</td>\n",
       "      <td>0.14536</td>\n",
       "      <td>-0.354878</td>\n",
       "      <td>0.921635</td>\n",
       "      <td>1.127204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.455568</td>\n",
       "      <td>2.884162</td>\n",
       "      <td>0.209199</td>\n",
       "      <td>2.038795</td>\n",
       "      <td>2.075546</td>\n",
       "      <td>0.053047</td>\n",
       "      <td>-0.486538</td>\n",
       "      <td>1.075572</td>\n",
       "      <td>-0.002322</td>\n",
       "      <td>-1.064248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.55709</td>\n",
       "      <td>3.54232</td>\n",
       "      <td>-2.445459</td>\n",
       "      <td>2.005647</td>\n",
       "      <td>2.033552</td>\n",
       "      <td>-1.331069</td>\n",
       "      <td>0.14536</td>\n",
       "      <td>0.800487</td>\n",
       "      <td>-0.440386</td>\n",
       "      <td>2.004474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0.14906</td>\n",
       "      <td>-1.095435</td>\n",
       "      <td>-0.41753</td>\n",
       "      <td>-1.588905</td>\n",
       "      <td>-1.146362</td>\n",
       "      <td>1.815276</td>\n",
       "      <td>-1.335155</td>\n",
       "      <td>-1.665585</td>\n",
       "      <td>-1.368185</td>\n",
       "      <td>-1.064248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>-0.912901</td>\n",
       "      <td>-0.407372</td>\n",
       "      <td>-0.41753</td>\n",
       "      <td>-1.591017</td>\n",
       "      <td>-1.200634</td>\n",
       "      <td>-0.627393</td>\n",
       "      <td>0.14536</td>\n",
       "      <td>-0.662355</td>\n",
       "      <td>-1.368185</td>\n",
       "      <td>-1.064248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>2.314732</td>\n",
       "      <td>-1.644331</td>\n",
       "      <td>0.209199</td>\n",
       "      <td>-1.591546</td>\n",
       "      <td>-1.770187</td>\n",
       "      <td>0.225733</td>\n",
       "      <td>-0.170103</td>\n",
       "      <td>1.613347</td>\n",
       "      <td>-1.107836</td>\n",
       "      <td>-1.064248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>0.578946</td>\n",
       "      <td>-0.577655</td>\n",
       "      <td>0.97737</td>\n",
       "      <td>-1.592075</td>\n",
       "      <td>-1.639783</td>\n",
       "      <td>-1.630963</td>\n",
       "      <td>0.877682</td>\n",
       "      <td>1.075572</td>\n",
       "      <td>0.412505</td>\n",
       "      <td>-1.064248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>-2.528334</td>\n",
       "      <td>-1.587246</td>\n",
       "      <td>0.57396</td>\n",
       "      <td>-1.593133</td>\n",
       "      <td>-1.200634</td>\n",
       "      <td>-0.408068</td>\n",
       "      <td>-0.909973</td>\n",
       "      <td>-1.313112</td>\n",
       "      <td>-1.107836</td>\n",
       "      <td>-1.064248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pages numRatings likedPercent  bbeScore  bbeVotes     price  \\\n",
       "0     0.036449   3.889668      0.97737  2.076857  2.120919  0.155443   \n",
       "1     1.627188    2.66361     1.914966  2.065692  2.107529  0.727047   \n",
       "2    -0.208139   3.410156      0.57396  2.052021  2.091316 -0.239766   \n",
       "3    -0.455568   2.884162     0.209199  2.038795  2.075546  0.053047   \n",
       "4      0.55709    3.54232    -2.445459  2.005647  2.033552 -1.331069   \n",
       "...        ...        ...          ...       ...       ...       ...   \n",
       "1495   0.14906  -1.095435     -0.41753 -1.588905 -1.146362  1.815276   \n",
       "1496 -0.912901  -0.407372     -0.41753 -1.591017 -1.200634 -0.627393   \n",
       "1497  2.314732  -1.644331     0.209199 -1.591546 -1.770187  0.225733   \n",
       "1498  0.578946  -0.577655      0.97737 -1.592075 -1.639783 -1.630963   \n",
       "1499 -2.528334  -1.587246      0.57396 -1.593133 -1.200634 -0.408068   \n",
       "\n",
       "     publishYear publishMonth publishDay    awards  ... x0_Romanian  \\\n",
       "0       0.355131     0.800487   0.337433  2.137796  ...         0.0   \n",
       "1      -0.064841     0.800487   1.183032   1.59853  ...         0.0   \n",
       "2        0.14536    -0.354878   0.921635  1.127204  ...         0.0   \n",
       "3      -0.486538     1.075572  -0.002322 -1.064248  ...         0.0   \n",
       "4        0.14536     0.800487  -0.440386  2.004474  ...         0.0   \n",
       "...          ...          ...        ...       ...  ...         ...   \n",
       "1495   -1.335155    -1.665585  -1.368185 -1.064248  ...         0.0   \n",
       "1496     0.14536    -0.662355  -1.368185 -1.064248  ...         0.0   \n",
       "1497   -0.170103     1.613347  -1.107836 -1.064248  ...         0.0   \n",
       "1498    0.877682     1.075572   0.412505 -1.064248  ...         0.0   \n",
       "1499   -0.909973    -1.313112  -1.107836 -1.064248  ...         0.0   \n",
       "\n",
       "     x0_Russian x0_Spanish x0_Swedish x0_Turkish x0_nan x1_Digital  \\\n",
       "0           0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "3           0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "...         ...        ...        ...        ...    ...        ...   \n",
       "1495        0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "1496        0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "1497        0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "1498        0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "1499        0.0        0.0        0.0        0.0    0.0        0.0   \n",
       "\n",
       "     x1_Hardcover x1_Paperback x1_nan  \n",
       "0             1.0          0.0    0.0  \n",
       "1             0.0          1.0    0.0  \n",
       "2             0.0          1.0    0.0  \n",
       "3             0.0          1.0    0.0  \n",
       "4             0.0          1.0    0.0  \n",
       "...           ...          ...    ...  \n",
       "1495          1.0          0.0    0.0  \n",
       "1496          0.0          1.0    0.0  \n",
       "1497          0.0          1.0    0.0  \n",
       "1498          1.0          0.0    0.0  \n",
       "1499          0.0          1.0    0.0  \n",
       "\n",
       "[1500 rows x 60 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scal = pd.DataFrame(scores.sort_values('RMSE (mean)', ascending=True).reset_index().loc[0,'Escalador'].fit_transform(X),\n",
    "                     columns = X.columns)\n",
    "X_scal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699f12d-3491-4592-8e45-d1b17ec0cb7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.6. Estudio de importancia (FI) de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a9187-97d1-4cbe-9a7e-72865dc89033",
   "metadata": {},
   "source": [
    "A continuación vamos a realizar un estudio sobre el grado de importancia de cada variable de nuestro dataset en el problema de regresión.\n",
    "\n",
    "La intuición nos puede decir que variables como `'likedPercent'`, `'5Stars'` o `'1Star'` van a tener mucha importancia, pero conviene realizar un estudio más en profundidad para entender qué están haciendo realmente los algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08122526-0404-4c96-89e2-6ae8e222e5d5",
   "metadata": {},
   "source": [
    "#### 2.6.1. Linear Regression FI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c21f1-9c43-47d7-8c59-160223a066f3",
   "metadata": {},
   "source": [
    "Hemos visto que uno de los mejores algoritmos que podemos utilizar en nuestro problema es preciasmente el de Regresión Lineal. Esto tiene sentido, ya que nuestra variable objetivo tiene una fuete dependencia lineal con el resto de variables explicativas. Veamos cuáles influyen más en ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cfd2b0cc-c061-4927-93df-04eee5d01d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a2bdf28-aa58-4d9d-84f2-778689cf77f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60)\n",
      "Feature: 0, Score: -0.00143\n",
      "Feature: 1, Score: -0.57230\n",
      "Feature: 2, Score: 0.14107\n",
      "Feature: 3, Score: 0.16106\n",
      "Feature: 4, Score: -0.15139\n",
      "Feature: 5, Score: 0.00470\n",
      "Feature: 6, Score: 0.00364\n",
      "Feature: 7, Score: 0.00023\n",
      "Feature: 8, Score: 0.00070\n",
      "Feature: 9, Score: 0.00078\n",
      "Feature: 10, Score: 0.59448\n",
      "Feature: 11, Score: -0.07511\n",
      "Feature: 12, Score: -0.01871\n",
      "Feature: 13, Score: 0.05249\n",
      "Feature: 14, Score: 0.02749\n",
      "Feature: 15, Score: -0.00413\n",
      "Feature: 16, Score: -0.00208\n",
      "Feature: 17, Score: 0.00437\n",
      "Feature: 18, Score: -0.00977\n",
      "Feature: 19, Score: -0.00491\n",
      "Feature: 20, Score: -0.00452\n",
      "Feature: 21, Score: -0.05806\n",
      "Feature: 22, Score: 0.00354\n",
      "Feature: 23, Score: -0.00301\n",
      "Feature: 24, Score: -0.00543\n",
      "Feature: 25, Score: 0.00005\n",
      "Feature: 26, Score: -0.00624\n",
      "Feature: 27, Score: -0.00180\n",
      "Feature: 28, Score: -0.04748\n",
      "Feature: 29, Score: 0.00404\n",
      "Feature: 30, Score: -0.00884\n",
      "Feature: 31, Score: -0.01093\n",
      "Feature: 32, Score: 0.00034\n",
      "Feature: 33, Score: 0.00179\n",
      "Feature: 34, Score: -0.00334\n",
      "Feature: 35, Score: 0.03011\n",
      "Feature: 36, Score: 0.00000\n",
      "Feature: 37, Score: -0.00000\n",
      "Feature: 38, Score: -0.00000\n",
      "Feature: 39, Score: -0.02957\n",
      "Feature: 40, Score: -0.01008\n",
      "Feature: 41, Score: -0.03571\n",
      "Feature: 42, Score: 0.00000\n",
      "Feature: 43, Score: 0.00000\n",
      "Feature: 44, Score: 0.00000\n",
      "Feature: 45, Score: 0.00000\n",
      "Feature: 46, Score: 0.00000\n",
      "Feature: 47, Score: 0.07065\n",
      "Feature: 48, Score: 0.00000\n",
      "Feature: 49, Score: 0.00000\n",
      "Feature: 50, Score: 0.00000\n",
      "Feature: 51, Score: 0.00000\n",
      "Feature: 52, Score: -0.02593\n",
      "Feature: 53, Score: 0.00000\n",
      "Feature: 54, Score: 0.00000\n",
      "Feature: 55, Score: 0.00052\n",
      "Feature: 56, Score: 0.00473\n",
      "Feature: 57, Score: -0.00397\n",
      "Feature: 58, Score: 0.00230\n",
      "Feature: 59, Score: -0.00306\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = LinearRegression()\n",
    "# fit the model\n",
    "model.fit(X_scal, y)\n",
    "# get importance\n",
    "importance = model.coef_.T\n",
    "print(model.coef_.shape)\n",
    "# summarize feature importance. Los de mayor rango positivo las variables que más importancia tienen para el modelo.\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5c9d0-1dcc-4c59-97c4-86f5d4513650",
   "metadata": {},
   "source": [
    "Vemos que las más importantes son precisamente las que habíamos identificado, especialmente `'5Stars'`, junto con la especial ayuda de `'numRatings'`. Esto tiene sentido, ya que la regresión lineal está calculando el número de 5 estrellas respecto al número de votos y analizando qué porcentaje de ellas representan el total. También son importantes (positivamente) el `'bbeScore'` y `'bbeVotes'`, que indican la popularidad, y (negativamente) `'price'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0b2f3301-ed59-47ea-9725-10492d451491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPvklEQVR4nO3df4xlZX3H8fenuxp/1QCy6MpClybb1k0jiFPQ0FrlR7MsxrWJf4DV0kazIQGDiYkuMTFpmjQ0JsY2QckGqTSa8odSIbiVIkobY7XMKlLWFdkiyLpbdiRtbWxSin77x5y11/HOztw5h52587xfyc3c85xn7/N8d2Y/8+wzc89JVSFJWv9+abUnIEk6OQx8SWqEgS9JjTDwJakRBr4kNWLjak/gRE4//fTaunXrak9DkqbG/v37f1hVm8adW9OBv3XrVmZnZ1d7GpI0NZI8sdg5t3QkqREGviQ1wsCXpEYY+JLUiEECP8mOJI8kOZRkzyJ93pjkwSQHkvzDEONKkpav92/pJNkA3ARcBhwGHkhyV1V9e6TPKcDHgB1V9f0kZ/QdV5I0mSFW+BcAh6rqsap6Brgd2LWgz9uBO6rq+wBVdWyAcSVJExgi8M8Enhw5Pty1jfo14NQk9yfZn+QPF3uxJLuTzCaZnZubG2B6kiQY5o1XGdO28CL7G4HXApcALwT+KcnXquq7v/AHq/YCewFmZma8WD+wdc/nf+748RuvWKWZSJpmQwT+YeCskeMtwJExfX5YVT8GfpzkH4FzgV8IfEnSc2OILZ0HgG1JzknyfOBK4K4Ffe4EfifJxiQvAi4EDg4wtiRpmXqv8Kvq2STXAfcAG4Bbq+pAkmu68zdX1cEkXwAeAn4K3FJVD/cdW5K0fINcPK2q9gH7FrTdvOD4w8CHhxhPkjQ532krSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0YJPCT7EjySJJDSfacoN9vJflJkrcNMa4kafl6B36SDcBNwOXAduCqJNsX6ffnwD19x5QkTW6IFf4FwKGqeqyqngFuB3aN6fce4LPAsQHGlCRNaIjAPxN4cuT4cNf2M0nOBH4fuHmpF0uyO8lsktm5ubkBpidJgmECP2PaasHxR4EPVNVPlnqxqtpbVTNVNbNp06YBpidJAtg4wGscBs4aOd4CHFnQZwa4PQnA6cDOJM9W1ecGGF+StAxDBP4DwLYk5wA/AK4E3j7aoarOOf48ySeBuw17STq5egd+VT2b5Drmf/tmA3BrVR1Ick13fsl9e0nSc2+IFT5VtQ/Yt6BtbNBX1R8NMaYkaTK+01aSGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGjFI4CfZkeSRJIeS7Blz/g+SPNQ9vprk3CHGlSQtX+/AT7IBuAm4HNgOXJVk+4Ju3wN+t6peDfwpsLfvuJKkyQyxwr8AOFRVj1XVM8DtwK7RDlX11ar69+7wa8CWAcaVJE1giMA/E3hy5Phw17aYdwF/t9jJJLuTzCaZnZubG2B6kiQYJvAzpq3GdkzexHzgf2CxF6uqvVU1U1UzmzZtGmB6kiSAjQO8xmHgrJHjLcCRhZ2SvBq4Bbi8qp4eYFxJ0gSGWOE/AGxLck6S5wNXAneNdkhyNnAH8M6q+u4AY0qSJtR7hV9Vzya5DrgH2ADcWlUHklzTnb8Z+BDwMuBjSQCeraqZvmNLkpZviC0dqmofsG9B280jz98NvHuIsSRJK+M7bSWpEYOs8NebrXs+/3PHj994xSrNRJKG4wpfkhph4EtSI5rf0nH7RlIrXOFLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNaP5aOpLWFq9v9dxxhS9JjTDwJakRbumsc/73WNJxrvAlqREGviQ1wsCXpEa4h98g9/Wnh58rDckVviQ1YpDAT7IjySNJDiXZM+Z8kvxld/6hJOcPMa4kafl6B36SDcBNwOXAduCqJNsXdLsc2NY9dgMf7zuuJGkyQ+zhXwAcqqrHAJLcDuwCvj3SZxfw11VVwNeSnJJkc1UdHWD8VTNuf3W977merPrW0t/jWpqL1q5p+DrJfAb3eIHkbcCOqnp3d/xO4MKqum6kz93AjVX1le74PuADVTU75vV2M/+/AM4+++zXPvHEE73mN6rPJ2StfTKH/mYz9J9d2HaiOZ6MeT/X/Y73XetfY8v9+1+svvXiZNW3GrmRZH9VzYw7N8QKP2PaFn4XWU6f+caqvcBegJmZmX7fjbRsQ38hLvZ6J2uctTLuar+mVtda+5wOEfiHgbNGjrcAR1bQR1NqrX1Rr6Zp/LuYxjlrZYYI/AeAbUnOAX4AXAm8fUGfu4Druv39C4H/nPb9+7XIf7iSTqR34FfVs0muA+4BNgC3VtWBJNd0528G9gE7gUPAfwN/3HdcSVqpVhdHg7zTtqr2MR/qo203jzwv4NohxpK0cq0GneZ5aQVJv8BvDOuTl1aQpEa4wpdGuLLVeuYKX5Ia4Qpfq85VtXRyuMKXpEYY+JLUCLd0ppTbIJIm5Qpfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY3w4mnL5MXKJE07V/iS1AgDX5IaYeBLUiMMfElqRK/AT3JaknuTPNp9PHVMn7OSfDnJwSQHklzfZ0xJ0sr0XeHvAe6rqm3Afd3xQs8C76uqVwGvA65Nsr3nuJKkCfUN/F3Abd3z24C3LuxQVUer6hvd8/8CDgJn9hxXkjShvoH/8qo6CvPBDpxxos5JtgKvAb5+gj67k8wmmZ2bm+s5PUnScUu+8SrJF4FXjDn1wUkGSvIS4LPAe6vqR4v1q6q9wF6AmZmZmmQMSdLilgz8qrp0sXNJnkqyuaqOJtkMHFuk3/OYD/tPV9UdK56tJGnF+m7p3AVc3T2/GrhzYYckAT4BHKyqj/QcT5K0Qn0D/0bgsiSPApd1xyR5ZZJ9XZ+LgHcCFyd5sHvs7DmuJGlCvS6eVlVPA5eMaT8C7OyefwVIn3EkSf35TltJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJakSvwE9yWpJ7kzzafTz1BH03JPlmkrv7jClJWpm+K/w9wH1VtQ24rztezPXAwZ7jSZJWqG/g7wJu657fBrx1XKckW4ArgFt6jidJWqG+gf/yqjoK0H08Y5F+HwXeD/x0qRdMsjvJbJLZubm5ntOTJB23cakOSb4IvGLMqQ8uZ4AkbwaOVdX+JG9cqn9V7QX2AszMzNRyxpAkLW3JwK+qSxc7l+SpJJur6miSzcCxMd0uAt6SZCfwAuClST5VVe9Y8awlSRPru6VzF3B19/xq4M6FHarqhqraUlVbgSuBLxn2knTy9Q38G4HLkjwKXNYdk+SVSfb1nZwkaThLbumcSFU9DVwypv0IsHNM+/3A/X3GlCStjO+0laRGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRG1d7AifT4zdesdpTkKRV02uFn+S0JPcmebT7eOoi/U5J8pkk30lyMMnr+4wrSZpc3y2dPcB9VbUNuK87HucvgC9U1W8A5wIHe44rSZpQ38DfBdzWPb8NeOvCDkleCrwB+ARAVT1TVf/Rc1xJ0oT6Bv7Lq+ooQPfxjDF9fhWYA/4qyTeT3JLkxT3HlSRNaMnAT/LFJA+Peexa5hgbgfOBj1fVa4Afs/jWD0l2J5lNMjs3N7fMISRJS1nyt3Sq6tLFziV5KsnmqjqaZDNwbEy3w8Dhqvp6d/wZThD4VbUX2AswMzNTS81PkrQ8fbd07gKu7p5fDdy5sENV/RvwZJJf75ouAb7dc1xJ0oT6Bv6NwGVJHgUu645J8sok+0b6vQf4dJKHgPOAP+s5riRpQr3eeFVVTzO/Yl/YfgTYOXL8IDDTZyxJUj+pWrvb5EnmgCd6vszpwA8HmM5aYC1r03qpZb3UAW3X8itVtWnciTUd+ENIMltV6+J/F9ayNq2XWtZLHWAti/HiaZLUCANfkhrRQuDvXe0JDMha1qb1Ust6qQOsZax1v4cvSZrXwgpfkoSBL0nNWLeBn2RHkkeSHEqy6LV71qIktyY5luThkbZl3WxmrUlyVpIvdze+OZDk+q596upJ8oIk/5zkW10tf9K1T10tAEk2dFewvbs7nso6AJI8nuRfkjyYZLZrm8p6xt0waqha1mXgJ9kA3ARcDmwHrkqyfXVnNZFPAjsWtC33ZjNrzbPA+6rqVcDrgGu7z8U01vM/wMVVdS7zlwjZkeR1TGctANfz8zcjmtY6jntTVZ038jvr01rPuBtGDVNLVa27B/B64J6R4xuAG1Z7XhPWsBV4eOT4EWBz93wz8Mhqz3GFdd3J/HWXproe4EXAN4ALp7EWYEsXHBcDd3dtU1fHSD2PA6cvaJu6eoCXAt+j+4WaoWtZlyt84EzgyZHjw13bNFvOzWbWtCRbgdcAX2dK6+m2QR5k/lLg99b8Zb+nsZaPAu8HfjrSNo11HFfA3yfZn2R31zaN9Sx2w6hBalmvgZ8xbf7+6SpK8hLgs8B7q+pHqz2flaqqn1TVecyvkC9I8purPKWJJXkzcKyq9q/2XAZ0UVWdz/w27rVJ3rDaE1qhiW4YNan1GviHgbNGjrcAR1ZpLkN5qrvJDCe42cyalOR5zIf9p6vqjq55ausBqPn7Mt/P/M9apq2Wi4C3JHkcuB24OMmnmL46fqbmr9BLVR0D/ha4gOmsZ9wNo85noFrWa+A/AGxLck6S5wNXMn+zlmm25M1m1qIkYf4G9ger6iMjp6auniSbkpzSPX8hcCnwHaaslqq6oaq2VNVW5v9tfKmq3sGU1XFckhcn+eXjz4HfAx5mCuupxW8YNUwtq/1Diufwhx87ge8C/wp8cLXnM+Hc/wY4Cvwv89/x3wW8jPkfsj3afTxttee5zFp+m/nttIeAB7vHzmmsB3g18M2uloeBD3XtU1fLSE1v5P9/aDuVdTC/7/2t7nHg+L/3Ka7nPGC2+zr7HHDqULV4aQVJasR63dKRJC1g4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RG/B85zWDF8NJgxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance[:,0])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fade027-2fee-4fbf-95e9-f0e5ae8672ae",
   "metadata": {},
   "source": [
    "#### 2.6.2. CART FI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1aeaf-b1bd-40b5-a111-50a47bc26d2d",
   "metadata": {},
   "source": [
    "Veamos ahora la importancia de las características para un árbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b0dd063c-0fe7-4a66-8bd0-d2e4514d759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "15ab465d-de99-48aa-8bad-4b531c46ea65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n",
      "Feature: 0, Score: 0.02827\n",
      "Feature: 1, Score: 0.00165\n",
      "Feature: 2, Score: 0.77234\n",
      "Feature: 3, Score: 0.00844\n",
      "Feature: 4, Score: 0.00582\n",
      "Feature: 5, Score: 0.01048\n",
      "Feature: 6, Score: 0.01113\n",
      "Feature: 7, Score: 0.00357\n",
      "Feature: 8, Score: 0.00519\n",
      "Feature: 9, Score: 0.00608\n",
      "Feature: 10, Score: 0.03561\n",
      "Feature: 11, Score: 0.00709\n",
      "Feature: 12, Score: 0.06710\n",
      "Feature: 13, Score: 0.00369\n",
      "Feature: 14, Score: 0.00757\n",
      "Feature: 15, Score: 0.00060\n",
      "Feature: 16, Score: 0.00194\n",
      "Feature: 17, Score: 0.00021\n",
      "Feature: 18, Score: 0.00045\n",
      "Feature: 19, Score: 0.00086\n",
      "Feature: 20, Score: 0.00004\n",
      "Feature: 21, Score: 0.00027\n",
      "Feature: 22, Score: 0.00002\n",
      "Feature: 23, Score: 0.00136\n",
      "Feature: 24, Score: 0.00064\n",
      "Feature: 25, Score: 0.00378\n",
      "Feature: 26, Score: 0.00126\n",
      "Feature: 27, Score: 0.00179\n",
      "Feature: 28, Score: 0.00287\n",
      "Feature: 29, Score: 0.00059\n",
      "Feature: 30, Score: 0.00237\n",
      "Feature: 31, Score: 0.00026\n",
      "Feature: 32, Score: 0.00177\n",
      "Feature: 33, Score: 0.00184\n",
      "Feature: 34, Score: 0.00070\n",
      "Feature: 35, Score: 0.00036\n",
      "Feature: 36, Score: 0.00000\n",
      "Feature: 37, Score: 0.00000\n",
      "Feature: 38, Score: 0.00000\n",
      "Feature: 39, Score: 0.00010\n",
      "Feature: 40, Score: 0.00000\n",
      "Feature: 41, Score: 0.00000\n",
      "Feature: 42, Score: 0.00000\n",
      "Feature: 43, Score: 0.00000\n",
      "Feature: 44, Score: 0.00000\n",
      "Feature: 45, Score: 0.00000\n",
      "Feature: 46, Score: 0.00000\n",
      "Feature: 47, Score: 0.00000\n",
      "Feature: 48, Score: 0.00000\n",
      "Feature: 49, Score: 0.00000\n",
      "Feature: 50, Score: 0.00000\n",
      "Feature: 51, Score: 0.00000\n",
      "Feature: 52, Score: 0.00000\n",
      "Feature: 53, Score: 0.00000\n",
      "Feature: 54, Score: 0.00000\n",
      "Feature: 55, Score: 0.00000\n",
      "Feature: 56, Score: 0.00099\n",
      "Feature: 57, Score: 0.00016\n",
      "Feature: 58, Score: 0.00077\n",
      "Feature: 59, Score: 0.00000\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = DecisionTreeRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_   \n",
    "print(model.feature_importances_.shape)\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8a9ef-6ed7-4285-8499-e4cc01e6f750",
   "metadata": {},
   "source": [
    "Vemos ahora que la característica más importante es, sobre todo, `'likedPercent'`, como advertíamos al principio de la sección. También influyen `'5Stars'`, `'3Stars'` y `'pages'`, aunque en mucha menor medida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2ac4f3f6-94a9-46b6-81a6-a229ed94c818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf55d5fe-f2e3-4dc9-bc6a-90f724e2cd12",
   "metadata": {},
   "source": [
    "#### 2.6.3. Random Forest FI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae17779-e7d3-4434-abdc-1728bfacc5e8",
   "metadata": {},
   "source": [
    "Pasemos ahora a ver la importancia de las características según un `RandomForest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8907c542-4bb7-44b5-8990-f2592de1a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c05f1016-f95e-4fb3-a1a4-c20de6584a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n",
      "Feature: 0, Score: 0.03107\n",
      "Feature: 1, Score: 0.00349\n",
      "Feature: 2, Score: 0.76823\n",
      "Feature: 3, Score: 0.01221\n",
      "Feature: 4, Score: 0.00651\n",
      "Feature: 5, Score: 0.02068\n",
      "Feature: 6, Score: 0.01677\n",
      "Feature: 7, Score: 0.00498\n",
      "Feature: 8, Score: 0.00540\n",
      "Feature: 9, Score: 0.00404\n",
      "Feature: 10, Score: 0.02489\n",
      "Feature: 11, Score: 0.01431\n",
      "Feature: 12, Score: 0.03801\n",
      "Feature: 13, Score: 0.00686\n",
      "Feature: 14, Score: 0.00917\n",
      "Feature: 15, Score: 0.00102\n",
      "Feature: 16, Score: 0.00089\n",
      "Feature: 17, Score: 0.00042\n",
      "Feature: 18, Score: 0.00226\n",
      "Feature: 19, Score: 0.00116\n",
      "Feature: 20, Score: 0.00098\n",
      "Feature: 21, Score: 0.00105\n",
      "Feature: 22, Score: 0.00072\n",
      "Feature: 23, Score: 0.00211\n",
      "Feature: 24, Score: 0.00063\n",
      "Feature: 25, Score: 0.00259\n",
      "Feature: 26, Score: 0.00117\n",
      "Feature: 27, Score: 0.00397\n",
      "Feature: 28, Score: 0.00143\n",
      "Feature: 29, Score: 0.00189\n",
      "Feature: 30, Score: 0.00136\n",
      "Feature: 31, Score: 0.00116\n",
      "Feature: 32, Score: 0.00108\n",
      "Feature: 33, Score: 0.00121\n",
      "Feature: 34, Score: 0.00182\n",
      "Feature: 35, Score: 0.00033\n",
      "Feature: 36, Score: 0.00000\n",
      "Feature: 37, Score: 0.00000\n",
      "Feature: 38, Score: 0.00000\n",
      "Feature: 39, Score: 0.00055\n",
      "Feature: 40, Score: 0.00002\n",
      "Feature: 41, Score: 0.00002\n",
      "Feature: 42, Score: 0.00000\n",
      "Feature: 43, Score: 0.00000\n",
      "Feature: 44, Score: 0.00000\n",
      "Feature: 45, Score: 0.00000\n",
      "Feature: 46, Score: 0.00000\n",
      "Feature: 47, Score: 0.00004\n",
      "Feature: 48, Score: 0.00000\n",
      "Feature: 49, Score: 0.00000\n",
      "Feature: 50, Score: 0.00000\n",
      "Feature: 51, Score: 0.00000\n",
      "Feature: 52, Score: 0.00013\n",
      "Feature: 53, Score: 0.00000\n",
      "Feature: 54, Score: 0.00000\n",
      "Feature: 55, Score: 0.00017\n",
      "Feature: 56, Score: 0.00139\n",
      "Feature: 57, Score: 0.00081\n",
      "Feature: 58, Score: 0.00088\n",
      "Feature: 59, Score: 0.00010\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = RandomForestRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "print(model.feature_importances_.shape)\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c0954-e126-4d72-bce8-fd41a9638b5d",
   "metadata": {},
   "source": [
    "Las conclusiones son similares a las del árbol de decisión, basándose principalmente en `'likedPercent'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "76c2c7fa-0ce1-43d8-bab0-d360d4bdf9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9dbf55-2327-4c8f-b5f9-f62e634f4d24",
   "metadata": {},
   "source": [
    "#### 2.6.4. Permutation FI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1ff27-09ff-4a23-8d20-04da2a23033c",
   "metadata": {},
   "source": [
    "Utilicemos finalmente un modelo KNN para calcular el grado de importancia por permutación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b927718a-792a-4658-9c1e-8382f051d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "05cbd81d-af73-4421-baef-dd4893bf9f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00004\n",
      "Feature: 1, Score: 0.08741\n",
      "Feature: 2, Score: 0.00000\n",
      "Feature: 3, Score: 0.00893\n",
      "Feature: 4, Score: 0.00001\n",
      "Feature: 5, Score: 0.00000\n",
      "Feature: 6, Score: 0.00000\n",
      "Feature: 7, Score: 0.00000\n",
      "Feature: 8, Score: 0.00000\n",
      "Feature: 9, Score: 0.00000\n",
      "Feature: 10, Score: 0.13357\n",
      "Feature: 11, Score: 0.01421\n",
      "Feature: 12, Score: 0.05721\n",
      "Feature: 13, Score: 0.01141\n",
      "Feature: 14, Score: 0.00222\n",
      "Feature: 15, Score: 0.00000\n",
      "Feature: 16, Score: 0.00000\n",
      "Feature: 17, Score: 0.00000\n",
      "Feature: 18, Score: 0.00000\n",
      "Feature: 19, Score: 0.00000\n",
      "Feature: 20, Score: 0.00000\n",
      "Feature: 21, Score: 0.00000\n",
      "Feature: 22, Score: 0.00000\n",
      "Feature: 23, Score: 0.00000\n",
      "Feature: 24, Score: 0.00000\n",
      "Feature: 25, Score: 0.00000\n",
      "Feature: 26, Score: 0.00000\n",
      "Feature: 27, Score: 0.00000\n",
      "Feature: 28, Score: 0.00000\n",
      "Feature: 29, Score: 0.00000\n",
      "Feature: 30, Score: 0.00000\n",
      "Feature: 31, Score: 0.00000\n",
      "Feature: 32, Score: 0.00000\n",
      "Feature: 33, Score: 0.00000\n",
      "Feature: 34, Score: 0.00000\n",
      "Feature: 35, Score: 0.00000\n",
      "Feature: 36, Score: 0.00000\n",
      "Feature: 37, Score: 0.00000\n",
      "Feature: 38, Score: 0.00000\n",
      "Feature: 39, Score: 0.00000\n",
      "Feature: 40, Score: 0.00000\n",
      "Feature: 41, Score: 0.00000\n",
      "Feature: 42, Score: 0.00000\n",
      "Feature: 43, Score: 0.00000\n",
      "Feature: 44, Score: 0.00000\n",
      "Feature: 45, Score: 0.00000\n",
      "Feature: 46, Score: 0.00000\n",
      "Feature: 47, Score: 0.00000\n",
      "Feature: 48, Score: 0.00000\n",
      "Feature: 49, Score: 0.00000\n",
      "Feature: 50, Score: 0.00000\n",
      "Feature: 51, Score: 0.00000\n",
      "Feature: 52, Score: 0.00000\n",
      "Feature: 53, Score: 0.00000\n",
      "Feature: 54, Score: 0.00000\n",
      "Feature: 55, Score: 0.00000\n",
      "Feature: 56, Score: 0.00000\n",
      "Feature: 57, Score: 0.00000\n",
      "Feature: 58, Score: 0.00000\n",
      "Feature: 59, Score: 0.00000\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = KNeighborsRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# perform permutation importance\n",
    "results = permutation_importance(model, X, y, scoring='neg_mean_squared_error')\n",
    "# get importance\n",
    "importance = results.importances_mean\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2438bc-46a0-4d6c-8726-cad5c9bb457b",
   "metadata": {},
   "source": [
    "Al igual que como ocurría con el modelo de regresión lineal, los índices de importancia por permutación nos dicen que las variables más relevantes son `'5Stars'` y `'3Stars'` (positivamente) respecto a `'numRatings'`. También tiene en cuenta el resto de indicadores de estrellas y el `'bbeScore'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fc7edf1a-db0c-464a-878f-73f96d8f302d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pages', 'numRatings', 'likedPercent', 'bbeScore', 'bbeVotes', 'price',\n",
       "       'publishYear', 'publishMonth', 'publishDay', 'awards', '5Stars',\n",
       "       '4Stars', '3Stars', '2Stars', '1Star', 'Adult', 'Adventure',\n",
       "       'Childrens', 'Classics', 'Contemporary', 'Fantasy', 'Fiction',\n",
       "       'Historical', 'Historical Fiction', 'Humor', 'Literature', 'Magic',\n",
       "       'Mystery', 'Nonfiction', 'Novels', 'Paranormal', 'Romance',\n",
       "       'Science Fiction', 'Thriller', 'Young Adult', 'x0_Arabic', 'x0_Bengali',\n",
       "       'x0_Bulgarian', 'x0_Dutch', 'x0_English', 'x0_French', 'x0_German',\n",
       "       'x0_Greek', 'x0_Indonesian', 'x0_Italian', 'x0_Japanese', 'x0_Malay',\n",
       "       'x0_Persian', 'x0_Polish', 'x0_Portuguese', 'x0_Romanian', 'x0_Russian',\n",
       "       'x0_Spanish', 'x0_Swedish', 'x0_Turkish', 'x0_nan', 'x1_Digital',\n",
       "       'x1_Hardcover', 'x1_Paperback', 'x1_nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ad72acab-2a88-4661-8fb7-cbc19e29d273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARfUlEQVR4nO3df6jdd33H8edrNwbnj1Jd72aXxCVCsF7GtOWS1XWMrW4jacXszxZcXRmEQjvboUi6wcb+60BEhdIQajaKsv5R3RY0GMUffwi2y03b1caY7S7LlrvE5YqsdRZMs773x/l2O15Per43OTe35+PzAYd7vp8f3/N5k95Xvv2c8z1JVSFJatfPrPcCJElry6CXpMYZ9JLUOINekhpn0EtS4wx6SWpcr6BPsjPJiSSLSfaO6L8uyTeT/CjJh0f0zyR5KsnnJ7FoSVJ/Y4M+yQzwILALmANuTzK3Ytj3gQ8CH73Iae4Fjl/GOiVJl6jPFf0OYLGqTlbVeeBRYPfwgKo6V1VHgBdXTk6yGbgVeHgC65UkrdKGHmM2AaeHjpeAX13Fa3wc+Ajwxr4Trrnmmtq6desqXkKSfrodPXr0e1U1O6qvT9BnRFuv701I8l7gXFUdTfKbY8buAfYAvPWtb2VhYaHPS0iSgCT/drG+Pls3S8CWoePNwJmer30T8L4kpxhs+dyc5NOjBlbV/qqar6r52dmRfylJki5Bn6A/AmxPsi3JRuA24GCfk1fV/VW1uaq2dvO+WlXvv+TVSpJWbezWTVVdSHIPcBiYAQ5U1bEkd3X9+5K8BVgArgJeSnIfMFdVz6/d0iVJfeTV+DXF8/Pz5R69JPWX5GhVzY/q885YSWqcQS9JjTPoJalxBr0kNc6gl6TG9bkzVutk694v/NjxqQduXaeVSJpmXtFLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhrXK+iT7ExyIslikr0j+q9L8s0kP0ry4aH2LUm+luR4kmNJ7p3k4iVJ4439F6aSzAAPAr8DLAFHkhysqm8PDfs+8EHg91ZMvwB8qKqeTPJG4GiSL6+YK0laQ32u6HcAi1V1sqrOA48Cu4cHVNW5qjoCvLii/WxVPdk9/wFwHNg0kZVLknrpE/SbgNNDx0tcQlgn2QpcDzyx2rmSpEvXJ+gzoq1W8yJJ3gB8Frivqp6/yJg9SRaSLCwvL6/m9JKkV9An6JeALUPHm4EzfV8gyWsYhPxnqupzFxtXVfurar6q5mdnZ/ueXpI0Rp+gPwJsT7ItyUbgNuBgn5MnCfAp4HhVfezSlylJulRjP3VTVReS3AMcBmaAA1V1LMldXf++JG8BFoCrgJeS3AfMAb8C/D7wrSRPd6f8k6o6NPFKJEkjjQ16gC6YD61o2zf0/LsMtnRW+gaj9/glSVeId8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG9Qr6JDuTnEiymGTviP7rknwzyY+SfHg1cyVJa2ts0CeZAR4EdgFzwO1J5lYM+z7wQeCjlzBXkrSG+lzR7wAWq+pkVZ0HHgV2Dw+oqnNVdQR4cbVzJUlrq0/QbwJODx0vdW19XM5cSdIE9An6jGirnufvPTfJniQLSRaWl5d7nl6SNE6foF8CtgwdbwbO9Dx/77lVtb+q5qtqfnZ2tufpJUnj9An6I8D2JNuSbARuAw72PP/lzJUkTcCGcQOq6kKSe4DDwAxwoKqOJbmr69+X5C3AAnAV8FKS+4C5qnp+1Nw1qkWSNMLYoAeoqkPAoRVt+4aef5fBtkyvuZKkK8c7YyWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS43p9TfG027r3Cz92fOqBW9dpJZJ05XlFL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS43oFfZKdSU4kWUyyd0R/knyy638myQ1DfX+c5FiSZ5P8TZLXTrIASdIrGxv0SWaAB4FdwBxwe5K5FcN2Adu7xx7goW7uJuCDwHxV/TIwA9w2sdVLksbqc0W/A1isqpNVdR54FNi9Ysxu4JEaeBy4Osm1Xd8G4GeTbABeB5yZ0NolST30CfpNwOmh46WubeyYqvoP4KPAvwNngeeq6kuXvlxJ0mr1CfqMaKs+Y5K8icHV/jbgF4HXJ3n/yBdJ9iRZSLKwvLzcY1mSpD76BP0SsGXoeDM/uf1ysTG/DfxrVS1X1YvA54BfG/UiVbW/quaran52drbv+iVJY/QJ+iPA9iTbkmxk8GbqwRVjDgJ3dJ++uZHBFs1ZBls2NyZ5XZIA7wGOT3D9kqQxxn5NcVVdSHIPcJjBp2YOVNWxJHd1/fuAQ8AtwCLwAnBn1/dEkseAJ4ELwFPA/rUoRJI0Wq/vo6+qQwzCfLht39DzAu6+yNw/B/78MtYoSboM3hkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIa1yvok+xMciLJYpK9I/qT5JNd/zNJbhjquzrJY0m+k+R4kndPsgBJ0isbG/RJZoAHgV3AHHB7krkVw3YB27vHHuChob5PAF+squuAdwLHJ7BuSVJPfa7odwCLVXWyqs4DjwK7V4zZDTxSA48DVye5NslVwG8AnwKoqvNV9V+TW74kaZw+Qb8JOD10vNS19RnzNmAZ+KskTyV5OMnrL2O9kqRV6hP0GdFWPcdsAG4AHqqq64EfAj+xxw+QZE+ShSQLy8vLPZYlSeqjT9AvAVuGjjcDZ3qOWQKWquqJrv0xBsH/E6pqf1XNV9X87Oxsn7VLknroE/RHgO1JtiXZCNwGHFwx5iBwR/fpmxuB56rqbFV9Fzid5O3duPcA357U4iVJ420YN6CqLiS5BzgMzAAHqupYkru6/n3AIeAWYBF4Abhz6BR/BHym+0vi5Io+SdIaGxv0AFV1iEGYD7ftG3pewN0Xmfs0MH/pS9Q4W/d+4ceOTz1w6zqtRNKrkXfGSlLjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxvUK+iQ7k5xIsphk74j+JPlk1/9MkhtW9M8keSrJ5ye1cElSP2ODPskM8CCwC5gDbk8yt2LYLmB799gDPLSi/17g+GWvVpK0an2u6HcAi1V1sqrOA48Cu1eM2Q08UgOPA1cnuRYgyWbgVuDhCa5bktRTn6DfBJweOl7q2vqO+TjwEeClS1uiJOly9An6jGirPmOSvBc4V1VHx75IsifJQpKF5eXlHsuSJPXRJ+iXgC1Dx5uBMz3H3AS8L8kpBls+Nyf59KgXqar9VTVfVfOzs7M9ly9JGqdP0B8BtifZlmQjcBtwcMWYg8Ad3advbgSeq6qzVXV/VW2uqq3dvK9W1fsnWYAk6ZVtGDegqi4kuQc4DMwAB6rqWJK7uv59wCHgFmAReAG4c+2WLElajbFBD1BVhxiE+XDbvqHnBdw95hxfB76+6hVKki6Ld8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG9Qr6JDuTnEiymGTviP4k+WTX/0ySG7r2LUm+luR4kmNJ7p10AZKkVzY26JPMAA8Cu4A54PYkcyuG7QK2d489wENd+wXgQ1X1DuBG4O4RcyVJa6jPFf0OYLGqTlbVeeBRYPeKMbuBR2rgceDqJNdW1dmqehKgqn4AHAc2TXD9kqQx+gT9JuD00PESPxnWY8ck2QpcDzyx6lVKki5Zn6DPiLZazZgkbwA+C9xXVc+PfJFkT5KFJAvLy8s9liVJ6qNP0C8BW4aONwNn+o5J8hoGIf+ZqvrcxV6kqvZX1XxVzc/OzvZZuySphz5BfwTYnmRbko3AbcDBFWMOAnd0n765EXiuqs4mCfAp4HhVfWyiK5ck9bJh3ICqupDkHuAwMAMcqKpjSe7q+vcBh4BbgEXgBeDObvpNwO8D30rydNf2J1V1aKJVSJIuamzQA3TBfGhF276h5wXcPWLeNxi9fy9JukK8M1aSGmfQS1LjDHpJapxBL0mN6/VmrF49tu79wo8dn3rg1nVaiaRp4RW9JDXOoJekxhn0ktQ49+gb5V6+pJd5RS9JjTPoJalxBr0kNc49+iHua0tqkVf0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUuF53xibZCXwCmAEerqoHVvSn678FeAH4g6p6ss9cXTne+Sv9dBp7RZ9kBngQ2AXMAbcnmVsxbBewvXvsAR5axVxJ0hrqs3WzA1isqpNVdR54FNi9Ysxu4JEaeBy4Osm1PedKktZQn6DfBJweOl7q2vqM6TNXkrSG+uzRZ0Rb9RzTZ+7gBMkeBts+AP+d5ESPtb2Sa4DvjXytv+x3gr7jroBrgO+NWs+k266Ai/65TKFWammlDvjpruWXLtbRJ+iXgC1Dx5uBMz3HbOwxF4Cq2g/s77GeXpIsVNX8pM63nqzl1amVWlqpA6zlYvps3RwBtifZlmQjcBtwcMWYg8AdGbgReK6qzvacK0laQ2Ov6KvqQpJ7gMMMPiJ5oKqOJbmr698HHGLw0cpFBh+vvPOV5q5JJZKkkXp9jr6qDjEI8+G2fUPPC7i779wrZGLbQK8C1vLq1EotrdQB1jJSBhktSWqVX4EgSY1rLuiT7ExyIslikr3rvZ7VSHIgybkkzw61vTnJl5P8c/fzTeu5xr6SbEnytSTHkxxLcm/XPnX1JHltkn9I8o9dLX/RtU9dLTC4Yz3JU0k+3x1PZR0ASU4l+VaSp5MsdG1TWU+Sq5M8luQ73e/NuydVS1NB38BXLvw1sHNF217gK1W1HfhKdzwNLgAfqqp3ADcCd3d/FtNYz4+Am6vqncC7gJ3dp8umsRaAe4HjQ8fTWsfLfquq3jX0UcRprecTwBer6jrgnQz+jCZTS1U18wDeDRweOr4fuH+917XKGrYCzw4dnwCu7Z5fC5xY7zVeYl1/D/zOtNcDvA54EvjVaayFwb0sXwFuBj7ftU1dHUP1nAKuWdE2dfUAVwH/Sve+6aRraeqKnja/cuEXanBPAt3Pn1/n9axakq3A9cATTGk93XbH08A54MtVNa21fBz4CPDSUNs01vGyAr6U5Gh3dz1MZz1vA5aBv+q21R5O8nomVEtrQd/7Kxd0ZSR5A/BZ4L6qen6913Opqup/qupdDK6IdyT55XVe0qoleS9wrqqOrvdaJuimqrqBwXbt3Ul+Y70XdIk2ADcAD1XV9cAPmeCWU2tB3+frGqbNf3bfBEr389w6r6e3JK9hEPKfqarPdc1TWw9AVf0X8HUG76VMWy03Ae9LcorBN8nenOTTTF8d/6eqznQ/zwF/y+Abc6exniVgqfs/RYDHGAT/RGppLehb/MqFg8AHuucfYLDX/arX/WM0nwKOV9XHhrqmrp4ks0mu7p7/LPDbwHeYslqq6v6q2lxVWxn8bny1qt7PlNXxsiSvT/LGl58Dvws8yxTWU1XfBU4neXvX9B7g20yqlvV+E2IN3tS4Bfgn4F+AP13v9axy7X8DnAVeZPA3/B8CP8fgzbN/7n6+eb3X2bOWX2ewbfYM8HT3uGUa6wF+BXiqq+VZ4M+69qmrZaim3+T/34ydyjoY7Gv/Y/c49vLv+xTX8y5gofvv7O+AN02qFu+MlaTGtbZ1I0lawaCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalx/wtxUxoAuCI0qAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a98ac9-90ed-42d1-b941-0eaca2afa9f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.7. Selección de características (FS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17c2395-8a04-4998-b039-da1af6b38da9",
   "metadata": {},
   "source": [
    "Una vez hemos analizado la importancia de las características, pasemos a seleccionar aquellas con mayor relevancia en nuestros modelos y a obtener sus resultados asociados.\n",
    "\n",
    "Para ello, importamos los paquetes necesarios y creamos de nuevo un DataFrame que contenga todos nuestros resultados para cada modelo, estrategia de FS y número de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1a21142c-4d10-4f5c-a7bb-6e3c2fbc5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c2aa40e4-19a1-4ae3-8d0f-9fcc16ac3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresFS = pd.DataFrame(columns=['Modelo', \n",
    "                               'Estrategia de selección de características',\n",
    "                               'Número de características',\n",
    "                               'RMSE (mean)',\n",
    "                               'RMSE (std)',\n",
    "                               'Selector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd7ffb-1c41-45d8-81e5-c07e3776d2b1",
   "metadata": {},
   "source": [
    "#### 2.7.1. FS en base al coeficiente de correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb99bc5-fef2-4b65-8cb9-35e663b4b83e",
   "metadata": {},
   "source": [
    "El FS mediante el coeficiente de correlación se aplica al tener únicamente variables numéricas. No es nuestro caso, por lo que nos saltan errores si lo aplicamos a todo el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "902454a6-7cfe-4056-9459-173c400822d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "37bfdf9d-bc23-4cc3-ad3c-374703828068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scal, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8d4d9e46-e28c-4fd9-bd5b-b8572e00af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # feature selection\n",
    "# def select_features(X_train, y_train, X_test):\n",
    "#     # configure to select all features\n",
    "#     fs = SelectKBest(score_func=f_regression, k='all')\n",
    "#     # learn relationship from training data\n",
    "#     fs.fit(X_train, y_train)\n",
    "#     # transform train input data\n",
    "#     X_train_fs = fs.transform(X_train)\n",
    "#     # transform test input data\n",
    "#     X_test_fs = fs.transform(X_test)\n",
    "#     return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# # feature selection\n",
    "# X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# # what are scores for the features\n",
    "# for i in range(len(fs.scores_)):\n",
    "#     print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "attachments": {
    "8497de27-5204-442a-b1bb-a73761b9785c.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "387aede3-7593-4ed2-a68d-8e59650ebf9f",
   "metadata": {},
   "source": [
    "![Screenshot_1.png](attachment:8497de27-5204-442a-b1bb-a73761b9785c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae139a-15e5-477f-8ad9-5f4959bb7d0c",
   "metadata": {},
   "source": [
    "Concretamente nos da un \"float division by zero\". Esto es debido a que, como hay variables categóricas codificadas, existen columnas con varianza cero (que, evidentemente, no aportan información al resultado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e915e64d-8f85-4dbb-856f-eed7bc4ac334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0_Bengali       0.0\n",
       "x0_Bulgarian     0.0\n",
       "x0_Dutch         0.0\n",
       "x0_Greek         0.0\n",
       "x0_Indonesian    0.0\n",
       "x0_Italian       0.0\n",
       "x0_Japanese      0.0\n",
       "x0_Malay         0.0\n",
       "x0_Polish        0.0\n",
       "x0_Portuguese    0.0\n",
       "x0_Romanian      0.0\n",
       "x0_Russian       0.0\n",
       "x0_Swedish       0.0\n",
       "x0_Turkish       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scal.std()[X_scal.std() == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049b8bfc-74c0-41ef-82a4-a16a5c4078e5",
   "metadata": {},
   "source": [
    "Si tomamos únicmanete las columnas numéricas sí obtenemos resultados, interesantes de estudiar. Tendremos en cuenta los resultados, pero no utilizaremos este método para posteriores apartados (ya que no tiene en cuenta las variables categóricas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bd7c45a1-9ad3-4593-a5e7-13c87679972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scal[numeric_columns].astype('float64'), y.astype('float64'), test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "965a5c12-99e2-42e4-beb2-d3da298f9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 47.974567\n",
      "Feature 1: 10.377981\n",
      "Feature 2: 4253.172557\n",
      "Feature 3: 1.359954\n",
      "Feature 4: 0.016570\n",
      "Feature 5: 144.270705\n",
      "Feature 6: 8.079315\n",
      "Feature 7: 0.766765\n",
      "Feature 8: 0.084906\n",
      "Feature 9: 1.159606\n",
      "Feature 10: 7.675001\n",
      "Feature 11: 20.188967\n",
      "Feature 12: 135.186845\n",
      "Feature 13: 252.196359\n",
      "Feature 14: 189.234478\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_regression, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "018ec221-84b4-42ed-884c-87efbe021622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e2c85624-262b-493c-9031-d7a16ff760ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MutualInformation (2)\n",
      "RF: 0.12 (0.00)\n",
      "MutualInformation (3)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (4)\n",
      "RF: 0.08 (0.01)\n",
      "MutualInformation (5)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (6)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (7)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (8)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (9)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (10)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (11)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (12)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (13)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (14)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (2)\n",
      "RL: 0.11 (0.00)\n",
      "MutualInformation (3)\n",
      "RL: 0.08 (0.01)\n",
      "MutualInformation (4)\n",
      "RL: 0.08 (0.01)\n",
      "MutualInformation (5)\n",
      "RL: 0.07 (0.01)\n",
      "MutualInformation (6)\n",
      "RL: 0.07 (0.02)\n",
      "MutualInformation (7)\n",
      "RL: 0.07 (0.01)\n",
      "MutualInformation (8)\n",
      "RL: 0.06 (0.01)\n",
      "MutualInformation (9)\n",
      "RL: 0.06 (0.02)\n",
      "MutualInformation (10)\n",
      "RL: 0.06 (0.02)\n",
      "MutualInformation (11)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (12)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (13)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (14)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (2)\n",
      "SVR: 0.11 (0.00)\n",
      "MutualInformation (3)\n",
      "SVR: 0.07 (0.01)\n",
      "MutualInformation (4)\n",
      "SVR: 0.07 (0.01)\n",
      "MutualInformation (5)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (6)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (7)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (8)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (9)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (10)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (11)\n",
      "SVR: 0.08 (0.03)\n",
      "MutualInformation (12)\n",
      "SVR: 0.08 (0.03)\n",
      "MutualInformation (13)\n",
      "SVR: 0.08 (0.03)\n",
      "MutualInformation (14)\n",
      "SVR: 0.09 (0.02)\n",
      "CPU times: total: 30.3 s\n",
      "Wall time: 26.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for model_name, model in modelos.items():\n",
    "    for k in range(2,len(numeric_columns)):\n",
    "    \n",
    "        fs = SelectKBest(score_func=f_regression, k=k)\n",
    "\n",
    "        pip = Pipeline(steps=[('fs', fs),\n",
    "                              ('model',  model)])\n",
    "\n",
    "        # preparar el procedimiento de cross-validation \n",
    "        cv = KFold(n_splits=5)\n",
    "        # evaluar el modelo\n",
    "        cv_results = cross_validate(pip, X_scal[numeric_columns].astype('float64'), y.astype('float64'), scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "        print('MutualInformation (' + str(k) + ')')\n",
    "        print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                             - mean(cv_results['test_score']), \n",
    "                                             std(cv_results['test_score'])))\n",
    "\n",
    "        scoresFS.loc[len(scoresFS)] = [model_name,\n",
    "                                   'CorrelationCoefficient',\n",
    "                                   k,\n",
    "                                   - mean(cv_results['test_score']),\n",
    "                                   std(cv_results['test_score']),\n",
    "                                   fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9448ee63-d48b-4312-b4a1-3e514482a5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de selección de características</th>\n",
       "      <th>Número de características</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>13</td>\n",
       "      <td>0.052502</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>SelectKBest(k=13, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>14</td>\n",
       "      <td>0.052520</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>SelectKBest(k=14, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>12</td>\n",
       "      <td>0.053085</td>\n",
       "      <td>0.013086</td>\n",
       "      <td>SelectKBest(k=12, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>11</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.014816</td>\n",
       "      <td>SelectKBest(k=11, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>10</td>\n",
       "      <td>0.055649</td>\n",
       "      <td>0.016680</td>\n",
       "      <td>SelectKBest(score_func=&lt;function f_regression ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>9</td>\n",
       "      <td>0.058724</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>SelectKBest(k=9, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>8</td>\n",
       "      <td>0.062426</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>SelectKBest(k=8, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>7</td>\n",
       "      <td>0.068547</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>SelectKBest(k=7, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>4</td>\n",
       "      <td>0.069524</td>\n",
       "      <td>0.011954</td>\n",
       "      <td>SelectKBest(k=4, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>8</td>\n",
       "      <td>0.071179</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>SelectKBest(k=8, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>5</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.015821</td>\n",
       "      <td>SelectKBest(k=5, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>9</td>\n",
       "      <td>0.071581</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>SelectKBest(k=9, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>7</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>SelectKBest(k=7, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>5</td>\n",
       "      <td>0.073728</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>SelectKBest(k=5, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>3</td>\n",
       "      <td>0.073920</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>SelectKBest(k=3, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>6</td>\n",
       "      <td>0.074291</td>\n",
       "      <td>0.015507</td>\n",
       "      <td>SelectKBest(k=6, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>6</td>\n",
       "      <td>0.074424</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>SelectKBest(k=6, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>10</td>\n",
       "      <td>0.075980</td>\n",
       "      <td>0.024143</td>\n",
       "      <td>SelectKBest(score_func=&lt;function f_regression ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>4</td>\n",
       "      <td>0.078034</td>\n",
       "      <td>0.013590</td>\n",
       "      <td>SelectKBest(k=4, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>11</td>\n",
       "      <td>0.079237</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>SelectKBest(k=11, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>3</td>\n",
       "      <td>0.079293</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>SelectKBest(k=3, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>12</td>\n",
       "      <td>0.081243</td>\n",
       "      <td>0.026438</td>\n",
       "      <td>SelectKBest(k=12, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>13</td>\n",
       "      <td>0.082685</td>\n",
       "      <td>0.025361</td>\n",
       "      <td>SelectKBest(k=13, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>10</td>\n",
       "      <td>0.082912</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>SelectKBest(score_func=&lt;function f_regression ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>8</td>\n",
       "      <td>0.083167</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>SelectKBest(k=8, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>12</td>\n",
       "      <td>0.083181</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>SelectKBest(k=12, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>9</td>\n",
       "      <td>0.083238</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>SelectKBest(k=9, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>7</td>\n",
       "      <td>0.083304</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>SelectKBest(k=7, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>13</td>\n",
       "      <td>0.083576</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>SelectKBest(k=13, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>11</td>\n",
       "      <td>0.083853</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>SelectKBest(k=11, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>14</td>\n",
       "      <td>0.084480</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>SelectKBest(k=14, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>5</td>\n",
       "      <td>0.084775</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>SelectKBest(k=5, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>4</td>\n",
       "      <td>0.084957</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>SelectKBest(k=4, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>14</td>\n",
       "      <td>0.085336</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>SelectKBest(k=14, score_func=&lt;function f_regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>6</td>\n",
       "      <td>0.087409</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>SelectKBest(k=6, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>3</td>\n",
       "      <td>0.088347</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>SelectKBest(k=3, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>2</td>\n",
       "      <td>0.107917</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>SelectKBest(k=2, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RL</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>2</td>\n",
       "      <td>0.112022</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>SelectKBest(k=2, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124690</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>SelectKBest(k=2, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Modelo Estrategia de selección de características  \\\n",
       "24     RL                     CorrelationCoefficient   \n",
       "25     RL                     CorrelationCoefficient   \n",
       "23     RL                     CorrelationCoefficient   \n",
       "22     RL                     CorrelationCoefficient   \n",
       "21     RL                     CorrelationCoefficient   \n",
       "20     RL                     CorrelationCoefficient   \n",
       "19     RL                     CorrelationCoefficient   \n",
       "18     RL                     CorrelationCoefficient   \n",
       "28    SVR                     CorrelationCoefficient   \n",
       "32    SVR                     CorrelationCoefficient   \n",
       "29    SVR                     CorrelationCoefficient   \n",
       "33    SVR                     CorrelationCoefficient   \n",
       "31    SVR                     CorrelationCoefficient   \n",
       "16     RL                     CorrelationCoefficient   \n",
       "27    SVR                     CorrelationCoefficient   \n",
       "30    SVR                     CorrelationCoefficient   \n",
       "17     RL                     CorrelationCoefficient   \n",
       "34    SVR                     CorrelationCoefficient   \n",
       "15     RL                     CorrelationCoefficient   \n",
       "35    SVR                     CorrelationCoefficient   \n",
       "14     RL                     CorrelationCoefficient   \n",
       "36    SVR                     CorrelationCoefficient   \n",
       "37    SVR                     CorrelationCoefficient   \n",
       "8      RF                     CorrelationCoefficient   \n",
       "6      RF                     CorrelationCoefficient   \n",
       "10     RF                     CorrelationCoefficient   \n",
       "7      RF                     CorrelationCoefficient   \n",
       "5      RF                     CorrelationCoefficient   \n",
       "11     RF                     CorrelationCoefficient   \n",
       "9      RF                     CorrelationCoefficient   \n",
       "12     RF                     CorrelationCoefficient   \n",
       "3      RF                     CorrelationCoefficient   \n",
       "2      RF                     CorrelationCoefficient   \n",
       "38    SVR                     CorrelationCoefficient   \n",
       "4      RF                     CorrelationCoefficient   \n",
       "1      RF                     CorrelationCoefficient   \n",
       "26    SVR                     CorrelationCoefficient   \n",
       "13     RL                     CorrelationCoefficient   \n",
       "0      RF                     CorrelationCoefficient   \n",
       "\n",
       "    Número de características  RMSE (mean)  RMSE (std)  \\\n",
       "24                         13     0.052502    0.013072   \n",
       "25                         14     0.052520    0.013058   \n",
       "23                         12     0.053085    0.013086   \n",
       "22                         11     0.054425    0.014816   \n",
       "21                         10     0.055649    0.016680   \n",
       "20                          9     0.058724    0.015642   \n",
       "19                          8     0.062426    0.013395   \n",
       "18                          7     0.068547    0.013476   \n",
       "28                          4     0.069524    0.011954   \n",
       "32                          8     0.071179    0.018019   \n",
       "29                          5     0.071281    0.015821   \n",
       "33                          9     0.071581    0.017714   \n",
       "31                          7     0.071936    0.015424   \n",
       "16                          5     0.073728    0.014593   \n",
       "27                          3     0.073920    0.010256   \n",
       "30                          6     0.074291    0.015507   \n",
       "17                          6     0.074424    0.015152   \n",
       "34                         10     0.075980    0.024143   \n",
       "15                          4     0.078034    0.013590   \n",
       "35                         11     0.079237    0.026450   \n",
       "14                          3     0.079293    0.010937   \n",
       "36                         12     0.081243    0.026438   \n",
       "37                         13     0.082685    0.025361   \n",
       "8                          10     0.082912    0.004485   \n",
       "6                           8     0.083167    0.003770   \n",
       "10                         12     0.083181    0.002257   \n",
       "7                           9     0.083238    0.004261   \n",
       "5                           7     0.083304    0.003273   \n",
       "11                         13     0.083576    0.002260   \n",
       "9                          11     0.083853    0.003786   \n",
       "12                         14     0.084480    0.002765   \n",
       "3                           5     0.084775    0.002458   \n",
       "2                           4     0.084957    0.005527   \n",
       "38                         14     0.085336    0.023018   \n",
       "4                           6     0.087409    0.003637   \n",
       "1                           3     0.088347    0.004672   \n",
       "26                          2     0.107917    0.004315   \n",
       "13                          2     0.112022    0.003058   \n",
       "0                           2     0.124690    0.004419   \n",
       "\n",
       "                                             Selector  \n",
       "24  SelectKBest(k=13, score_func=<function f_regre...  \n",
       "25  SelectKBest(k=14, score_func=<function f_regre...  \n",
       "23  SelectKBest(k=12, score_func=<function f_regre...  \n",
       "22  SelectKBest(k=11, score_func=<function f_regre...  \n",
       "21  SelectKBest(score_func=<function f_regression ...  \n",
       "20  SelectKBest(k=9, score_func=<function f_regres...  \n",
       "19  SelectKBest(k=8, score_func=<function f_regres...  \n",
       "18  SelectKBest(k=7, score_func=<function f_regres...  \n",
       "28  SelectKBest(k=4, score_func=<function f_regres...  \n",
       "32  SelectKBest(k=8, score_func=<function f_regres...  \n",
       "29  SelectKBest(k=5, score_func=<function f_regres...  \n",
       "33  SelectKBest(k=9, score_func=<function f_regres...  \n",
       "31  SelectKBest(k=7, score_func=<function f_regres...  \n",
       "16  SelectKBest(k=5, score_func=<function f_regres...  \n",
       "27  SelectKBest(k=3, score_func=<function f_regres...  \n",
       "30  SelectKBest(k=6, score_func=<function f_regres...  \n",
       "17  SelectKBest(k=6, score_func=<function f_regres...  \n",
       "34  SelectKBest(score_func=<function f_regression ...  \n",
       "15  SelectKBest(k=4, score_func=<function f_regres...  \n",
       "35  SelectKBest(k=11, score_func=<function f_regre...  \n",
       "14  SelectKBest(k=3, score_func=<function f_regres...  \n",
       "36  SelectKBest(k=12, score_func=<function f_regre...  \n",
       "37  SelectKBest(k=13, score_func=<function f_regre...  \n",
       "8   SelectKBest(score_func=<function f_regression ...  \n",
       "6   SelectKBest(k=8, score_func=<function f_regres...  \n",
       "10  SelectKBest(k=12, score_func=<function f_regre...  \n",
       "7   SelectKBest(k=9, score_func=<function f_regres...  \n",
       "5   SelectKBest(k=7, score_func=<function f_regres...  \n",
       "11  SelectKBest(k=13, score_func=<function f_regre...  \n",
       "9   SelectKBest(k=11, score_func=<function f_regre...  \n",
       "12  SelectKBest(k=14, score_func=<function f_regre...  \n",
       "3   SelectKBest(k=5, score_func=<function f_regres...  \n",
       "2   SelectKBest(k=4, score_func=<function f_regres...  \n",
       "38  SelectKBest(k=14, score_func=<function f_regre...  \n",
       "4   SelectKBest(k=6, score_func=<function f_regres...  \n",
       "1   SelectKBest(k=3, score_func=<function f_regres...  \n",
       "26  SelectKBest(k=2, score_func=<function f_regres...  \n",
       "13  SelectKBest(k=2, score_func=<function f_regres...  \n",
       "0   SelectKBest(k=2, score_func=<function f_regres...  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresFS[scoresFS['Estrategia de selección de características'] == 'CorrelationCoefficient'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f65db8-7eaa-4b1c-8c06-c9c3fe190cc7",
   "metadata": {},
   "source": [
    "#### 2.7.3. FS mediante Mutual Information (MI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe275bb-9b5c-48df-80cc-f162bf4ff546",
   "metadata": {},
   "source": [
    "Para poder extraer las variables de mayor importancia contemplando comportamientos no lineales (como los que encontramos en variables categóricas y muchas de las variables numéricas), necesitamos emplear técnicas como la de Mutual Information, basada en la información mutua entre variables aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cdd867e3-202e-4860-bb06-aed64eb276a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c3f68690-b72b-4b2f-af57-34562252b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scal, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "065474ad-9d1c-4f23-b938-5432d7ec64a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.071697\n",
      "Feature 1: 0.061732\n",
      "Feature 2: 0.816438\n",
      "Feature 3: 0.022076\n",
      "Feature 4: 0.000001\n",
      "Feature 5: 0.091443\n",
      "Feature 6: 0.062536\n",
      "Feature 7: 0.013874\n",
      "Feature 8: 0.000000\n",
      "Feature 9: 0.029862\n",
      "Feature 10: 0.072816\n",
      "Feature 11: 0.076129\n",
      "Feature 12: 0.131625\n",
      "Feature 13: 0.136807\n",
      "Feature 14: 0.155250\n",
      "Feature 15: 0.000000\n",
      "Feature 16: 0.006380\n",
      "Feature 17: 0.014903\n",
      "Feature 18: 0.013769\n",
      "Feature 19: 0.012475\n",
      "Feature 20: 0.000000\n",
      "Feature 21: 0.023026\n",
      "Feature 22: 0.014437\n",
      "Feature 23: 0.003024\n",
      "Feature 24: 0.000000\n",
      "Feature 25: 0.059655\n",
      "Feature 26: 0.004253\n",
      "Feature 27: 0.004214\n",
      "Feature 28: 0.015337\n",
      "Feature 29: 0.032237\n",
      "Feature 30: 0.000000\n",
      "Feature 31: 0.002567\n",
      "Feature 32: 0.003588\n",
      "Feature 33: 0.000000\n",
      "Feature 34: 0.032665\n",
      "Feature 35: 0.007329\n",
      "Feature 36: 0.000000\n",
      "Feature 37: 0.003695\n",
      "Feature 38: 0.001305\n",
      "Feature 39: 0.009472\n",
      "Feature 40: 0.004267\n",
      "Feature 41: 0.001793\n",
      "Feature 42: 0.000000\n",
      "Feature 43: 0.000000\n",
      "Feature 44: 0.000000\n",
      "Feature 45: 0.003365\n",
      "Feature 46: 0.000000\n",
      "Feature 47: 0.000000\n",
      "Feature 48: 0.005021\n",
      "Feature 49: 0.000000\n",
      "Feature 50: 0.001152\n",
      "Feature 51: 0.000647\n",
      "Feature 52: 0.001969\n",
      "Feature 53: 0.000599\n",
      "Feature 54: 0.000000\n",
      "Feature 55: 0.022167\n",
      "Feature 56: 0.019118\n",
      "Feature 57: 0.006772\n",
      "Feature 58: 0.009993\n",
      "Feature 59: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0432aa7d-c2d9-47e1-9062-50d64baa890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2cad6237-8bc9-4db9-aa93-3454c28d5482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MutualInformation (2)\n",
      "RF: 0.12 (0.01)\n",
      "MutualInformation (3)\n",
      "RF: 0.09 (0.01)\n",
      "MutualInformation (4)\n",
      "RF: 0.08 (0.01)\n",
      "MutualInformation (5)\n",
      "RF: 0.08 (0.01)\n",
      "MutualInformation (6)\n",
      "RF: 0.08 (0.01)\n",
      "MutualInformation (7)\n",
      "RF: 0.08 (0.01)\n",
      "MutualInformation (8)\n",
      "RF: 0.08 (0.01)\n",
      "MutualInformation (9)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (10)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (11)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (12)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (13)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (14)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (15)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (16)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (17)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (18)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (19)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (20)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (21)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (22)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (23)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (24)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (25)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (26)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (27)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (28)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (29)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (30)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (31)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (32)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (33)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (34)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (35)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (36)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (37)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (38)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (39)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (40)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (41)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (42)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (43)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (44)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (45)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (46)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (47)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (48)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (49)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (50)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (51)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (52)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (53)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (54)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (55)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (56)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (57)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (58)\n",
      "RF: 0.08 (0.00)\n",
      "MutualInformation (59)\n",
      "RF: 0.09 (0.00)\n",
      "MutualInformation (2)\n",
      "RL: 0.11 (0.00)\n",
      "MutualInformation (3)\n",
      "RL: 0.09 (0.02)\n",
      "MutualInformation (4)\n",
      "RL: 0.08 (0.02)\n",
      "MutualInformation (5)\n",
      "RL: 0.07 (0.02)\n",
      "MutualInformation (6)\n",
      "RL: 0.07 (0.02)\n",
      "MutualInformation (7)\n",
      "RL: 0.06 (0.02)\n",
      "MutualInformation (8)\n",
      "RL: 0.06 (0.02)\n",
      "MutualInformation (9)\n",
      "RL: 0.06 (0.02)\n",
      "MutualInformation (10)\n",
      "RL: 0.06 (0.02)\n",
      "MutualInformation (11)\n",
      "RL: 0.06 (0.02)\n",
      "MutualInformation (12)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (13)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (14)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (15)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (16)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (17)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (18)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (19)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (20)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (21)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (22)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (23)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (24)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (25)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (26)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (27)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (28)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (29)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (30)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (31)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (32)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (33)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (34)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (35)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (36)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (37)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (38)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (39)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (40)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (41)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (42)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (43)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (44)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (45)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (46)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (47)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (48)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (49)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (50)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (51)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (52)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (53)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (54)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (55)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (56)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (57)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (58)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (59)\n",
      "RL: 0.05 (0.01)\n",
      "MutualInformation (2)\n",
      "SVR: 0.11 (0.00)\n",
      "MutualInformation (3)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (4)\n",
      "SVR: 0.06 (0.01)\n",
      "MutualInformation (5)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (6)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (7)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (8)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (9)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (10)\n",
      "SVR: 0.07 (0.02)\n",
      "MutualInformation (11)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (12)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (13)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (14)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (15)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (16)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (17)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (18)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (19)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (20)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (21)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (22)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (23)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (24)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (25)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (26)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (27)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (28)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (29)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (30)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (31)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (32)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (33)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (34)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (35)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (36)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (37)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (38)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (39)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (40)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (41)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (42)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (43)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (44)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (45)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (46)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (47)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (48)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (49)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (50)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (51)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (52)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (53)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (54)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (55)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (56)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (57)\n",
      "SVR: 0.08 (0.02)\n",
      "MutualInformation (58)\n",
      "SVR: 0.09 (0.02)\n",
      "MutualInformation (59)\n",
      "SVR: 0.09 (0.02)\n",
      "CPU times: total: 14min 29s\n",
      "Wall time: 7min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for model_name, model in modelos.items():\n",
    "    for k in range(2,len(X_train.columns)):\n",
    "    \n",
    "        fs = SelectKBest(score_func=mutual_info_regression, k=k)\n",
    "\n",
    "        pip = Pipeline(steps=[('fs', fs),\n",
    "                              ('model',  model)])\n",
    "\n",
    "        # preparar el procedimiento de cross-validation \n",
    "        cv = KFold(n_splits=5)\n",
    "        # evaluar el modelo\n",
    "        cv_results = cross_validate(pip, X_scal, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "        print('MutualInformation (' + str(k) + ')')\n",
    "        print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                             - mean(cv_results['test_score']), \n",
    "                                             std(cv_results['test_score'])))\n",
    "\n",
    "        scoresFS.loc[len(scoresFS)] = [model_name,\n",
    "                                   'MutualInformation',\n",
    "                                   k,\n",
    "                                   - mean(cv_results['test_score']),\n",
    "                                   std(cv_results['test_score']),\n",
    "                                   fs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0038af91-81f0-48c3-a555-a64d6bbca30e",
   "metadata": {},
   "source": [
    "Con esta técnica obtenemos resultados particularmente buenos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2eeeeefa-1637-4b68-ace1-82f66e14f2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de selección de características</th>\n",
       "      <th>Número de características</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>RL</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>40</td>\n",
       "      <td>0.048920</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>SelectKBest(k=40,\\n            score_func=&lt;fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>RL</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>58</td>\n",
       "      <td>0.049001</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>SelectKBest(k=58,\\n            score_func=&lt;fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>RL</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>28</td>\n",
       "      <td>0.049265</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>SelectKBest(k=28,\\n            score_func=&lt;fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>RL</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>33</td>\n",
       "      <td>0.049270</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>SelectKBest(k=33,\\n            score_func=&lt;fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>RL</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>32</td>\n",
       "      <td>0.049345</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>SelectKBest(k=32,\\n            score_func=&lt;fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RF</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>3</td>\n",
       "      <td>0.089187</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>SelectKBest(k=3,\\n            score_func=&lt;func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RL</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>3</td>\n",
       "      <td>0.094745</td>\n",
       "      <td>0.016228</td>\n",
       "      <td>SelectKBest(k=3,\\n            score_func=&lt;func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>SVR</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>2</td>\n",
       "      <td>0.107005</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>SelectKBest(k=2,\\n            score_func=&lt;func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RL</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>2</td>\n",
       "      <td>0.111267</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>SelectKBest(k=2,\\n            score_func=&lt;func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RF</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>2</td>\n",
       "      <td>0.123415</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>SelectKBest(k=2,\\n            score_func=&lt;func...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo Estrategia de selección de características  \\\n",
       "135     RL                          MutualInformation   \n",
       "153     RL                          MutualInformation   \n",
       "123     RL                          MutualInformation   \n",
       "128     RL                          MutualInformation   \n",
       "127     RL                          MutualInformation   \n",
       "..     ...                                        ...   \n",
       "40      RF                          MutualInformation   \n",
       "98      RL                          MutualInformation   \n",
       "155    SVR                          MutualInformation   \n",
       "97      RL                          MutualInformation   \n",
       "39      RF                          MutualInformation   \n",
       "\n",
       "     Número de características  RMSE (mean)  RMSE (std)  \\\n",
       "135                         40     0.048920    0.012547   \n",
       "153                         58     0.049001    0.012417   \n",
       "123                         28     0.049265    0.012086   \n",
       "128                         33     0.049270    0.012495   \n",
       "127                         32     0.049345    0.012071   \n",
       "..                         ...          ...         ...   \n",
       "40                           3     0.089187    0.013793   \n",
       "98                           3     0.094745    0.016228   \n",
       "155                          2     0.107005    0.004311   \n",
       "97                           2     0.111267    0.003038   \n",
       "39                           2     0.123415    0.005487   \n",
       "\n",
       "                                              Selector  \n",
       "135  SelectKBest(k=40,\\n            score_func=<fun...  \n",
       "153  SelectKBest(k=58,\\n            score_func=<fun...  \n",
       "123  SelectKBest(k=28,\\n            score_func=<fun...  \n",
       "128  SelectKBest(k=33,\\n            score_func=<fun...  \n",
       "127  SelectKBest(k=32,\\n            score_func=<fun...  \n",
       "..                                                 ...  \n",
       "40   SelectKBest(k=3,\\n            score_func=<func...  \n",
       "98   SelectKBest(k=3,\\n            score_func=<func...  \n",
       "155  SelectKBest(k=2,\\n            score_func=<func...  \n",
       "97   SelectKBest(k=2,\\n            score_func=<func...  \n",
       "39   SelectKBest(k=2,\\n            score_func=<func...  \n",
       "\n",
       "[174 rows x 6 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresFS[scoresFS['Estrategia de selección de características'] == 'MutualInformation'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ce06f-ca0c-4040-a360-fa17a2cc5b1b",
   "metadata": {},
   "source": [
    "#### 2.7.4. Eliminación Recursiva de Variables (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f9d4a-3f56-480c-a41d-8146d96e364b",
   "metadata": {},
   "source": [
    "Estudiamos a continuación la selección de características mediante la técnica de Eliminación Recursiva de Variables o RFE aplicada mediante un Árbol de Decisión (un modelo sencillo para reducir los costes temporales y diferente a los que utilizamos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aab9c874-6514-44ac-941b-31bc48d47adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1914b87d-217a-4b0f-a2a4-efa00b9fc3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE (2)\n",
      "RF: 0.12 (0.00)\n",
      "RFE (3)\n",
      "RF: 0.06 (0.00)\n",
      "RFE (4)\n",
      "RF: 0.07 (0.01)\n",
      "RFE (5)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (6)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (7)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (8)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (9)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (10)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (11)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (12)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (13)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (14)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (15)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (16)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (17)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (18)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (19)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (20)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (21)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (22)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (23)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (24)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (25)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (26)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (27)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (28)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (29)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (30)\n",
      "RF: 0.08 (0.00)\n",
      "RFE (31)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (32)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (33)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (34)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (35)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (36)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (37)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (38)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (39)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (40)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (41)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (42)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (43)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (44)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (45)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (46)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (47)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (48)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (49)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (50)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (51)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (52)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (53)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (54)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (55)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (56)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (57)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (58)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (59)\n",
      "RF: 0.09 (0.00)\n",
      "RFE (2)\n",
      "RL: 0.11 (0.01)\n",
      "RFE (3)\n",
      "RL: 0.06 (0.02)\n",
      "RFE (4)\n",
      "RL: 0.06 (0.02)\n",
      "RFE (5)\n",
      "RL: 0.06 (0.02)\n",
      "RFE (6)\n",
      "RL: 0.06 (0.01)\n",
      "RFE (7)\n",
      "RL: 0.06 (0.01)\n",
      "RFE (8)\n",
      "RL: 0.06 (0.01)\n",
      "RFE (9)\n",
      "RL: 0.06 (0.01)\n",
      "RFE (10)\n",
      "RL: 0.06 (0.01)\n",
      "RFE (11)\n",
      "RL: 0.06 (0.01)\n",
      "RFE (12)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (13)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (14)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (15)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (16)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (17)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (18)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (19)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (20)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (21)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (22)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (23)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (24)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (25)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (26)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (27)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (28)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (29)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (30)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (31)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (32)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (33)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (34)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (35)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (36)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (37)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (38)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (39)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (40)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (41)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (42)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (43)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (44)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (45)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (46)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (47)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (48)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (49)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (50)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (51)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (52)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (53)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (54)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (55)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (56)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (57)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (58)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (59)\n",
      "RL: 0.05 (0.01)\n",
      "RFE (2)\n",
      "SVR: 0.11 (0.01)\n",
      "RFE (3)\n",
      "SVR: 0.06 (0.02)\n",
      "RFE (4)\n",
      "SVR: 0.06 (0.02)\n",
      "RFE (5)\n",
      "SVR: 0.07 (0.02)\n",
      "RFE (6)\n",
      "SVR: 0.07 (0.02)\n",
      "RFE (7)\n",
      "SVR: 0.08 (0.02)\n",
      "RFE (8)\n",
      "SVR: 0.08 (0.02)\n",
      "RFE (9)\n",
      "SVR: 0.08 (0.02)\n",
      "RFE (10)\n",
      "SVR: 0.08 (0.02)\n",
      "RFE (11)\n",
      "SVR: 0.08 (0.02)\n",
      "RFE (12)\n",
      "SVR: 0.08 (0.03)\n",
      "RFE (13)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (14)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (15)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (16)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (17)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (18)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (19)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (20)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (21)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (22)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (23)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (24)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (25)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (26)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (27)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (28)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (29)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (30)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (31)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (32)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (33)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (34)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (35)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (36)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (37)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (38)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (39)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (40)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (41)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (42)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (43)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (44)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (45)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (46)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (47)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (48)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (49)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (50)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (51)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (52)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (53)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (54)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (55)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (56)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (57)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (58)\n",
      "SVR: 0.09 (0.02)\n",
      "RFE (59)\n",
      "SVR: 0.09 (0.02)\n",
      "CPU times: total: 14min 56s\n",
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for model_name, model in modelos.items():\n",
    "    for k in range(2,len(X_train.columns)):\n",
    "    \n",
    "        fs = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=k)  \n",
    "\n",
    "        pip = Pipeline(steps=[('fs', fs),\n",
    "                              ('model',  model)])\n",
    "\n",
    "        # preparar el procedimiento de cross-validation \n",
    "        cv = KFold(n_splits=5)\n",
    "        # evaluar el modelo\n",
    "        cv_results = cross_validate(pip, X_scal, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "        print('RFE (' + str(k) + ')')\n",
    "        print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                             - mean(cv_results['test_score']), \n",
    "                                             std(cv_results['test_score'])))\n",
    "\n",
    "        scoresFS.loc[len(scoresFS)] = [model_name,\n",
    "                                   'RFE',\n",
    "                                   k,\n",
    "                                   - mean(cv_results['test_score']),\n",
    "                                   std(cv_results['test_score']),\n",
    "                                   fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0ee40e02-c2b5-453c-a471-8dc06b0a1b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de selección de características</th>\n",
       "      <th>Número de características</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>RL</td>\n",
       "      <td>RFE</td>\n",
       "      <td>38</td>\n",
       "      <td>0.048313</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>RL</td>\n",
       "      <td>RFE</td>\n",
       "      <td>46</td>\n",
       "      <td>0.048527</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>RL</td>\n",
       "      <td>RFE</td>\n",
       "      <td>39</td>\n",
       "      <td>0.048574</td>\n",
       "      <td>0.012439</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>RL</td>\n",
       "      <td>RFE</td>\n",
       "      <td>41</td>\n",
       "      <td>0.048671</td>\n",
       "      <td>0.012224</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>RL</td>\n",
       "      <td>RFE</td>\n",
       "      <td>45</td>\n",
       "      <td>0.048731</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RFE</td>\n",
       "      <td>18</td>\n",
       "      <td>0.087270</td>\n",
       "      <td>0.022387</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RFE</td>\n",
       "      <td>17</td>\n",
       "      <td>0.087311</td>\n",
       "      <td>0.022359</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RFE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.107490</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>RL</td>\n",
       "      <td>RFE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.112682</td>\n",
       "      <td>0.006987</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>RF</td>\n",
       "      <td>RFE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo Estrategia de selección de características  \\\n",
       "307     RL                                        RFE   \n",
       "315     RL                                        RFE   \n",
       "308     RL                                        RFE   \n",
       "310     RL                                        RFE   \n",
       "314     RL                                        RFE   \n",
       "..     ...                                        ...   \n",
       "345    SVR                                        RFE   \n",
       "344    SVR                                        RFE   \n",
       "329    SVR                                        RFE   \n",
       "271     RL                                        RFE   \n",
       "213     RF                                        RFE   \n",
       "\n",
       "     Número de características  RMSE (mean)  RMSE (std)  \\\n",
       "307                         38     0.048313    0.012322   \n",
       "315                         46     0.048527    0.012120   \n",
       "308                         39     0.048574    0.012439   \n",
       "310                         41     0.048671    0.012224   \n",
       "314                         45     0.048731    0.012238   \n",
       "..                         ...          ...         ...   \n",
       "345                         18     0.087270    0.022387   \n",
       "344                         17     0.087311    0.022359   \n",
       "329                          2     0.107490    0.005259   \n",
       "271                          2     0.112682    0.006987   \n",
       "213                          2     0.121534    0.004353   \n",
       "\n",
       "                                              Selector  \n",
       "307  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "315  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "308  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "310  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "314  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "..                                                 ...  \n",
       "345  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "344  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "329  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "271  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "213  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "\n",
       "[174 rows x 6 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresFS[scoresFS['Estrategia de selección de características'] == 'RFE'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d584c-83f7-4f34-9ec2-7795d510b6bf",
   "metadata": {},
   "source": [
    "#### 2.7.5. FS mediante la importancia según un modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52249caf-0f7b-449e-9bd5-9657ba1625a4",
   "metadata": {},
   "source": [
    "Finalmente, vamos a aplicar la selección de características en base a la importancia según un modelo. Concretamente, aplicando los resultados que hemos visto en el punto 2.6.3., vamos a quedarnos con las k variables más importantes según un `RandomForestRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c84f3f4d-37de-4cf6-8992-f527b385caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ae6397b8-e3b5-46c4-86af-43125fb7e460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectFromModel (2)\n",
      "RF: 0.12 (0.01)\n",
      "SelectFromModel (3)\n",
      "RF: 0.11 (0.00)\n",
      "SelectFromModel (4)\n",
      "RF: 0.08 (0.02)\n",
      "SelectFromModel (5)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (6)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (7)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (8)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (9)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (10)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (11)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (12)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (13)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (14)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (15)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (16)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (17)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (18)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (19)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (20)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (21)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (22)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (23)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (24)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (25)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (26)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (27)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (28)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (29)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (30)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (31)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (32)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (33)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (34)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (35)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (36)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (37)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (38)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (39)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (40)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (41)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (42)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (43)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (44)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (45)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (46)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (47)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (48)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (49)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (50)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (51)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (52)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (53)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (54)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (55)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (56)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (57)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (58)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (59)\n",
      "RF: 0.08 (0.00)\n",
      "SelectFromModel (2)\n",
      "RL: 0.11 (0.01)\n",
      "SelectFromModel (3)\n",
      "RL: 0.09 (0.03)\n",
      "SelectFromModel (4)\n",
      "RL: 0.07 (0.02)\n",
      "SelectFromModel (5)\n",
      "RL: 0.06 (0.02)\n",
      "SelectFromModel (6)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (7)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (8)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (9)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (10)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (11)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (12)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (13)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (14)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (15)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (16)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (17)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (18)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (19)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (20)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (21)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (22)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (23)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (24)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (25)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (26)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (27)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (28)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (29)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (30)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (31)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (32)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (33)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (34)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (35)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (36)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (37)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (38)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (39)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (40)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (41)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (42)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (43)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (44)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (45)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (46)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (47)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (48)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (49)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (50)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (51)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (52)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (53)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (54)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (55)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (56)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (57)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (58)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (59)\n",
      "RL: 0.06 (0.01)\n",
      "SelectFromModel (2)\n",
      "SVR: 0.11 (0.00)\n",
      "SelectFromModel (3)\n",
      "SVR: 0.11 (0.01)\n",
      "SelectFromModel (4)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (5)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (6)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (7)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (8)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (9)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (10)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (11)\n",
      "SVR: 0.07 (0.01)\n",
      "SelectFromModel (12)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (13)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (14)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (15)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (16)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (17)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (18)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (19)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (20)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (21)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (22)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (23)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (24)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (25)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (26)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (27)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (28)\n",
      "SVR: 0.07 (0.01)\n",
      "SelectFromModel (29)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (30)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (31)\n",
      "SVR: 0.07 (0.01)\n",
      "SelectFromModel (32)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (33)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (34)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (35)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (36)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (37)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (38)\n",
      "SVR: 0.07 (0.01)\n",
      "SelectFromModel (39)\n",
      "SVR: 0.07 (0.01)\n",
      "SelectFromModel (40)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (41)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (42)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (43)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (44)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (45)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (46)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (47)\n",
      "SVR: 0.07 (0.01)\n",
      "SelectFromModel (48)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (49)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (50)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (51)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (52)\n",
      "SVR: 0.07 (0.01)\n",
      "SelectFromModel (53)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (54)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (55)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (56)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (57)\n",
      "SVR: 0.07 (0.02)\n",
      "SelectFromModel (58)\n",
      "SVR: 0.07 (0.01)\n",
      "SelectFromModel (59)\n",
      "SVR: 0.07 (0.02)\n",
      "CPU times: total: 20min 34s\n",
      "Wall time: 13min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for model_name, model in modelos.items():\n",
    "    for k in range(2,len(X_train.columns)):\n",
    "    \n",
    "        fs = SelectFromModel(RandomForestRegressor(n_estimators=100), max_features=k)\n",
    "\n",
    "        pip = Pipeline(steps=[('fs', fs),\n",
    "                              ('model',  model)])\n",
    "\n",
    "        # preparar el procedimiento de cross-validation \n",
    "        cv = KFold(n_splits=5)\n",
    "        # evaluar el modelo\n",
    "        cv_results = cross_validate(pip, X_scal, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "        print('SelectFromModel (' + str(k) + ')')\n",
    "        print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                             - mean(cv_results['test_score']), \n",
    "                                             std(cv_results['test_score'])))\n",
    "\n",
    "        scoresFS.loc[len(scoresFS)] = [model_name,\n",
    "                                   'SelectFromModel (RandomForest importance)',\n",
    "                                   k,\n",
    "                                   - mean(cv_results['test_score']),\n",
    "                                   std(cv_results['test_score']),\n",
    "                                   fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ca67a34e-7213-4311-8ead-b6714cab5924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de selección de características</th>\n",
       "      <th>Número de características</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>RL</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>8</td>\n",
       "      <td>0.059465</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>RL</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>12</td>\n",
       "      <td>0.059465</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>RL</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>47</td>\n",
       "      <td>0.059465</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>RL</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>20</td>\n",
       "      <td>0.059517</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>RL</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>54</td>\n",
       "      <td>0.059517</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>SVR</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.105221</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>RF</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.106621</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>SVR</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.107936</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>RL</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113163</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>RF</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.123026</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo Estrategia de selección de características  \\\n",
       "451     RL  SelectFromModel (RandomForest importance)   \n",
       "455     RL  SelectFromModel (RandomForest importance)   \n",
       "490     RL  SelectFromModel (RandomForest importance)   \n",
       "463     RL  SelectFromModel (RandomForest importance)   \n",
       "497     RL  SelectFromModel (RandomForest importance)   \n",
       "..     ...                                        ...   \n",
       "504    SVR  SelectFromModel (RandomForest importance)   \n",
       "388     RF  SelectFromModel (RandomForest importance)   \n",
       "503    SVR  SelectFromModel (RandomForest importance)   \n",
       "445     RL  SelectFromModel (RandomForest importance)   \n",
       "387     RF  SelectFromModel (RandomForest importance)   \n",
       "\n",
       "     Número de características  RMSE (mean)  RMSE (std)  \\\n",
       "451                          8     0.059465    0.014774   \n",
       "455                         12     0.059465    0.014774   \n",
       "490                         47     0.059465    0.014774   \n",
       "463                         20     0.059517    0.014719   \n",
       "497                         54     0.059517    0.014719   \n",
       "..                         ...          ...         ...   \n",
       "504                          3     0.105221    0.005682   \n",
       "388                          3     0.106621    0.003591   \n",
       "503                          2     0.107936    0.004231   \n",
       "445                          2     0.113163    0.006944   \n",
       "387                          2     0.123026    0.006901   \n",
       "\n",
       "                                              Selector  \n",
       "451  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "455  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "490  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "463  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "497  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "..                                                 ...  \n",
       "504  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "388  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "503  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "445  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "387  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "\n",
       "[174 rows x 6 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresFS[scoresFS['Estrategia de selección de características'] == 'SelectFromModel (RandomForest importance)'].sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752539ad-47ea-4490-ae27-8f44d8e88580",
   "metadata": {},
   "source": [
    "#### 2.7.6. Contraste de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cee8aa-6f29-45e1-b0ca-cb3c01eb535e",
   "metadata": {},
   "source": [
    "Comparando los resultados obtenidos por los distintos modelos podemos ver cuáles son las mejores combinaciones de técnicas de selección de características con número de variables para el problema que estamos tratando. Si mostramos, por ejemplo, los mejores resultados con un número máximo de 5 variables, vemos que la mejor selección se realiza con una RFE de 3 elementos para el modelo SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1afa775f-f953-4595-bc8b-16d985f5e0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Estrategia de selección de características</th>\n",
       "      <th>Número de características</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "      <th>Selector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RFE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.019186</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>RL</td>\n",
       "      <td>RFE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.059461</td>\n",
       "      <td>0.015853</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>RL</td>\n",
       "      <td>RFE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059501</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>RL</td>\n",
       "      <td>RFE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.059791</td>\n",
       "      <td>0.015765</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>RL</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RFE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.063459</td>\n",
       "      <td>0.018110</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>SVR</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>4</td>\n",
       "      <td>0.063911</td>\n",
       "      <td>0.013474</td>\n",
       "      <td>SelectKBest(k=4,\\n            score_func=&lt;func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>RF</td>\n",
       "      <td>RFE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.064201</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>SVR</td>\n",
       "      <td>RFE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.066521</td>\n",
       "      <td>0.018933</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>SVR</td>\n",
       "      <td>MutualInformation</td>\n",
       "      <td>5</td>\n",
       "      <td>0.068072</td>\n",
       "      <td>0.016270</td>\n",
       "      <td>SelectKBest(k=5,\\n            score_func=&lt;func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>RL</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.069035</td>\n",
       "      <td>0.023365</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>RF</td>\n",
       "      <td>RFE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.069256</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>RFE(estimator=DecisionTreeRegressor(), n_featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>4</td>\n",
       "      <td>0.069524</td>\n",
       "      <td>0.011954</td>\n",
       "      <td>SelectKBest(k=4, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>SVR</td>\n",
       "      <td>SelectFromModel (RandomForest importance)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.070205</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>SelectFromModel(estimator=RandomForestRegresso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVR</td>\n",
       "      <td>CorrelationCoefficient</td>\n",
       "      <td>5</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.015821</td>\n",
       "      <td>SelectKBest(k=5, score_func=&lt;function f_regres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo Estrategia de selección de características  \\\n",
       "330    SVR                                        RFE   \n",
       "273     RL                                        RFE   \n",
       "274     RL                                        RFE   \n",
       "272     RL                                        RFE   \n",
       "448     RL  SelectFromModel (RandomForest importance)   \n",
       "331    SVR                                        RFE   \n",
       "157    SVR                          MutualInformation   \n",
       "214     RF                                        RFE   \n",
       "332    SVR                                        RFE   \n",
       "158    SVR                          MutualInformation   \n",
       "447     RL  SelectFromModel (RandomForest importance)   \n",
       "215     RF                                        RFE   \n",
       "28     SVR                     CorrelationCoefficient   \n",
       "506    SVR  SelectFromModel (RandomForest importance)   \n",
       "29     SVR                     CorrelationCoefficient   \n",
       "\n",
       "     Número de características  RMSE (mean)  RMSE (std)  \\\n",
       "330                          3     0.059200    0.019186   \n",
       "273                          4     0.059461    0.015853   \n",
       "274                          5     0.059501    0.015614   \n",
       "272                          3     0.059791    0.015765   \n",
       "448                          5     0.059810    0.015053   \n",
       "331                          4     0.063459    0.018110   \n",
       "157                          4     0.063911    0.013474   \n",
       "214                          3     0.064201    0.003834   \n",
       "332                          5     0.066521    0.018933   \n",
       "158                          5     0.068072    0.016270   \n",
       "447                          4     0.069035    0.023365   \n",
       "215                          4     0.069256    0.005536   \n",
       "28                           4     0.069524    0.011954   \n",
       "506                          5     0.070205    0.016652   \n",
       "29                           5     0.071281    0.015821   \n",
       "\n",
       "                                              Selector  \n",
       "330  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "273  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "274  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "272  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "448  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "331  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "157  SelectKBest(k=4,\\n            score_func=<func...  \n",
       "214  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "332  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "158  SelectKBest(k=5,\\n            score_func=<func...  \n",
       "447  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "215  RFE(estimator=DecisionTreeRegressor(), n_featu...  \n",
       "28   SelectKBest(k=4, score_func=<function f_regres...  \n",
       "506  SelectFromModel(estimator=RandomForestRegresso...  \n",
       "29   SelectKBest(k=5, score_func=<function f_regres...  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_max = 5\n",
    "scoresFS[scoresFS['Número de características'] <= k_max].sort_values('RMSE (mean)', ascending=True).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b7937-8e7d-452d-b768-74ea80774a71",
   "metadata": {},
   "source": [
    "### 2.8. Transformaciones polinomiales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715df83a-1e1f-4279-9a1e-f3eb108e6ba2",
   "metadata": {},
   "source": [
    "Como último recurso, probemos a aplicar un filtro `PolynomialFeatures` para las 3 variables seleccionadas por el método RFE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2dfd99d2-5e1d-4ee0-89c1-bd15c6c625c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d0aaa611-b125-41c3-b238-1652975a6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresPF = pd.DataFrame(columns=['Modelo', \n",
    "                               'Grado',\n",
    "                               'RMSE (mean)',\n",
    "                               'RMSE (std)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3e79d516-59a9-4106-bd59-2f55b1d5de6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "RF: 0.06 (0.00)\n",
      "2\n",
      "RF: 0.07 (0.00)\n",
      "3\n",
      "RF: 0.07 (0.00)\n",
      "4\n",
      "RF: 0.07 (0.00)\n",
      "5\n",
      "RF: 0.07 (0.00)\n",
      "1\n",
      "RL: 0.06 (0.02)\n",
      "2\n",
      "RL: 0.04 (0.01)\n",
      "3\n",
      "RL: 0.04 (0.02)\n",
      "4\n",
      "RL: 0.07 (0.02)\n",
      "5\n",
      "RL: 0.06 (0.03)\n",
      "1\n",
      "SVR: 0.06 (0.02)\n",
      "2\n",
      "SVR: 0.07 (0.02)\n",
      "3\n",
      "SVR: 0.08 (0.02)\n",
      "4\n",
      "SVR: 0.10 (0.01)\n",
      "5\n",
      "SVR: 0.13 (0.00)\n",
      "CPU times: total: 1min 44s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "for model_name, model in modelos.items():\n",
    "    for degree in range(1,6):\n",
    "\n",
    "        fs = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=3)\n",
    "\n",
    "        trans = PolynomialFeatures(degree=degree)\n",
    "\n",
    "        pip = Pipeline(steps=[('fs', fs),\n",
    "                              ('pf', trans),\n",
    "                              ('model',  model)])\n",
    "\n",
    "        # preparar el procedimiento de cross-validation \n",
    "        cv = KFold(n_splits=5)\n",
    "        # evaluar el modelo\n",
    "        cv_results = cross_validate(pip, X_scal, y, scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "        print(degree)\n",
    "        print('{:s}: {:.2f} ({:.2f})'.format(model_name, \n",
    "                                             - mean(cv_results['test_score']), \n",
    "                                             std(cv_results['test_score'])))\n",
    "\n",
    "        scoresPF.loc[len(scoresPF)] = [model_name,\n",
    "                                     degree,\n",
    "                                     - mean(cv_results['test_score']),\n",
    "                                     std(cv_results['test_score'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e50eb3-47d1-424f-802a-8968e73dd424",
   "metadata": {},
   "source": [
    "Vemos que la regresión logística mejora mucho con un aumento polinomial de grado 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4315a4ec-b8a3-44e3-9c99-f18dc2c6601c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Grado</th>\n",
       "      <th>RMSE (mean)</th>\n",
       "      <th>RMSE (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RL</td>\n",
       "      <td>2</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.011947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RL</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>0.017596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>1</td>\n",
       "      <td>0.057378</td>\n",
       "      <td>0.017222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059791</td>\n",
       "      <td>0.015765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064156</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RL</td>\n",
       "      <td>5</td>\n",
       "      <td>0.064715</td>\n",
       "      <td>0.030192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RL</td>\n",
       "      <td>4</td>\n",
       "      <td>0.066054</td>\n",
       "      <td>0.019754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067355</td>\n",
       "      <td>0.003445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>3</td>\n",
       "      <td>0.067995</td>\n",
       "      <td>0.003735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVR</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068316</td>\n",
       "      <td>0.022556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>4</td>\n",
       "      <td>0.069498</td>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>5</td>\n",
       "      <td>0.070109</td>\n",
       "      <td>0.004645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR</td>\n",
       "      <td>3</td>\n",
       "      <td>0.078855</td>\n",
       "      <td>0.020372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVR</td>\n",
       "      <td>4</td>\n",
       "      <td>0.099476</td>\n",
       "      <td>0.012773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVR</td>\n",
       "      <td>5</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.004426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Modelo  Grado  RMSE (mean)  RMSE (std)\n",
       "6      RL      2     0.037274    0.011947\n",
       "7      RL      3     0.038596    0.017596\n",
       "10    SVR      1     0.057378    0.017222\n",
       "5      RL      1     0.059791    0.015765\n",
       "0      RF      1     0.064156    0.003989\n",
       "9      RL      5     0.064715    0.030192\n",
       "8      RL      4     0.066054    0.019754\n",
       "1      RF      2     0.067355    0.003445\n",
       "2      RF      3     0.067995    0.003735\n",
       "11    SVR      2     0.068316    0.022556\n",
       "3      RF      4     0.069498    0.004058\n",
       "4      RF      5     0.070109    0.004645\n",
       "12    SVR      3     0.078855    0.020372\n",
       "13    SVR      4     0.099476    0.012773\n",
       "14    SVR      5     0.130769    0.004426"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresPF.sort_values('RMSE (mean)', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359dbdf7-ec32-4b27-9460-43cc9e0d17e2",
   "metadata": {},
   "source": [
    "## 3. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28369f4b-237f-4c4f-aded-ffa274d75e24",
   "metadata": {},
   "source": [
    "Hemos conseguido un Root Mean Squared Error mínimo de 0.037, que es muy poco respecto a la valoración de 1 a 5 (como veíamos en los primeros apartados del proyecto). Hemos aplicado técnicas de preprocesamiento inicial de datos, eliminación de variables con poca relevancia o malas características, eliminación de registros duplicados, imputación de valores nulos, identificación de outliers, codificación y decodificación de variables categóricas, escalados y transformaciones, estudios de importancia de variables y selección de características; y hemos ido seleccionando dentro de cada paso la técnica que (junto con las anteriormente aplicadas) nos ha dado mejores resultados en términos de RMSE.\n",
    "\n",
    "Cabe destacar, por un lado, que este error es en cierto modo ficticio, ya que hemos seleccionado únicamente los primeros 1500 registros para ejecutar los últimos estudios por cuestión de eficiencia en tiempo. Estos primeros registros se corresponden (tal y como están ordenados en el dataset original) se corresponden con los más populares de la web Good Reads. Esto crea un sesgo en el sampleo que puede aumentar ficticiamente los resultados, y quizá también hacer que nuestras decisiones estén ligeramente desviadas. Para hacer el estudio correcto (o al menos coherente con el dataset original) deberíamos trabajar con la totalidad de los datos. Por otro lado, tenemos que, al seleccionar el algoritmo, la técnica o las características óptimas en cada uno de los pasos, es posible que hayamos obviado soluciones que, en combinación con otras técnicas posteriores diferentes, hubieran permitido obtener mejores resultados.\n",
    "\n",
    "A pesar de todo, hemos reunido las técnicas de mejores resultados, y podemos aplicarlas al dataset de principio a fin con la totalidad de sus datos, como haremos a continuación. Aun así, también debemos tener en cuenta que hemos tenido los datos de test de la posterior división tamibén en cuenta para los procesos de validación, por lo que estos han influido en nuestras elecciones a la hora de seleccionar las técnicas de preprocesamiento.\n",
    "\n",
    "Los resultados finales son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c27873bf-ed8f-4f0a-b808-071efc013279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\igmarco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\igmarco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\igmarco\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3218: RuntimeWarning: overflow encountered in power\n",
      "  out[pos] = (np.power(x[pos] + 1, lmbda) - 1) / lmbda\n",
      "C:\\Users\\igmarco\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:236: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "C:\\Users\\igmarco\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:247: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Original\n",
      "Modelo: SVR\n",
      "Estrategia de imputación: KNNImputer\n",
      "Encoding de variables categóricas: OneHotEncoder\n",
      "Transformación y escalado: PowerTransformer (yeo-johnson) with post-standarization\n",
      "Selección de catacterísticas: RFE (3)\n",
      "Aumento polinomial de características de grado 2\n",
      "RMSE: 0.103234\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=3)  \n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "            \n",
    "df = datasets[\"Original\"]\n",
    "\n",
    "# X = df.loc[:500, df.columns != 'target']\n",
    "# y = df.loc[:500, df.columns == 'target']\n",
    "\n",
    "X = df.loc[:,df.columns != 'target']\n",
    "y = df.loc[:,df.columns == 'target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "cat_cols = ['language', 'bookFormat']\n",
    "\n",
    "le_lan = ColumnLabelEncoder(LabelEncoder(), 'language') # Necesario ejecutar el código de 2.2.3.2. Imputación por KNN\n",
    "le_bf = ColumnLabelEncoder(LabelEncoder(), 'bookFormat')\n",
    "\n",
    "nullImputer = Pipeline(steps=[('le_lan', le_lan), \n",
    "                              ('le_bf', le_bf),\n",
    "                              ('i',KNNImputer(n_neighbors=9)), \n",
    "                              ('ld_lan', ColumnLabelDesencoder(le_lan, 0)),\n",
    "                              ('ld_bf', ColumnLabelDesencoder(le_bf, 1))])\n",
    "\n",
    "ohe = OneHotEncoder().fit(X_train[cat_cols])\n",
    "\n",
    "encoder = ColumnTransformer([('KNNImputer', nullImputer.fit(X_train), X_train.columns),\n",
    "                            ('OneHotEncoder', ohe, cat_cols)])\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns = np.concatenate((cols, ohe.get_feature_names())))\n",
    "X_test = pd.DataFrame(X_test, columns = np.concatenate((cols, ohe.get_feature_names())))\n",
    "\n",
    "X_train = X_train.drop(['language', 'bookFormat'], axis=1)\n",
    "X_test = X_test.drop(['language', 'bookFormat'], axis=1)\n",
    "\n",
    "numeric_columns = ['pages', 'numRatings', 'likedPercent', 'bbeScore', 'bbeVotes', 'price',\n",
    "                   'publishYear', 'publishMonth', 'publishDay', 'awards', '5Stars',\n",
    "                   '4Stars', '3Stars', '2Stars', '1Star']\n",
    "\n",
    "scaler = ColumnTransformer([('pt',  PowerTransformer(method='yeo-johnson', standardize=True), numeric_columns)], \n",
    "                           remainder='passthrough')\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "trans = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_fs = trans.fit_transform(X_train_fs)\n",
    "X_test_fs = trans.transform(X_test_fs)\n",
    "\n",
    "model = SVR()\n",
    "\n",
    "model.fit(X_train_fs, y_train.values.ravel())\n",
    "y_hat = model.predict(X_test_fs)\n",
    "\n",
    "score = mean_squared_error(y_test.values.ravel(), y_hat)\n",
    "\n",
    "print('Dataset: Original')\n",
    "print('Modelo: SVR')\n",
    "print('Estrategia de imputación: KNNImputer')\n",
    "print('Encoding de variables categóricas: OneHotEncoder')\n",
    "print('Transformación y escalado: PowerTransformer (yeo-johnson) with post-standarization')\n",
    "print('Selección de catacterísticas: RFE (3)')\n",
    "print('Aumento polinomial de características de grado 2')\n",
    "print('RMSE: %.6f' % np.sqrt(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd662f71-3929-43d9-aee8-73cfaaf40241",
   "metadata": {},
   "source": [
    "El error ha aumentado ligeramente, pero, como comentábamos anteriormente, esto se debe a la selección de datos. Si probamos a ejecutar el mismo código filtrando los 1500 libros más populares, obtenemos un RMSE de 0.087478, similar a lo que estábamos acostumbrados.\n",
    "\n",
    "Como último detalle, si comentamos las líneas\n",
    "\n",
    "```\n",
    "trans = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_fs = trans.fit_transform(X_train_fs)\n",
    "X_test_fs = trans.transform(X_test_fs)\n",
    "```\n",
    "\n",
    " podemos ver cómo serían los resultados sin el PolynomialFeatures de grado 2, para comprobar si estamos incurriendo en un problema de overfitting. El resultado final es de 0.103960 de RMSE, ligeramente inferior que aplicando la transformación polinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071f55d-86b4-47bc-954c-685e663ef3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
