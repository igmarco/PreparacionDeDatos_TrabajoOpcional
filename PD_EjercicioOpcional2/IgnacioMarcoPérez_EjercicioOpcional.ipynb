{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a6b59c-9436-421a-a01e-086cd6b76f39",
   "metadata": {},
   "source": [
    "# Práctica entregable: Feature Selection aplicada al dataset *Housing* con un problema de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbfdfea-c58d-4a9e-ae4b-c76ef0d1b31c",
   "metadata": {},
   "source": [
    "Para este problema, utilizaremos el dataset *Housing*, estudiado anteriormente en la práctica P7 de la asignatura. Recogeremos exactamente el último tratamiento realizado, en el que se le aplica un escalado *MinMaxScaler* entre *0* y *1* y una transformación avanzada *PowerTransformer*.\n",
    "\n",
    "Veamos los resultados obtenidos en la práctica para este procesado aplicando un modelo SVR de hiperparámetros por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a16cd88-6005-4f09-9dce-96fb4c94e566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "Mean MAE: 2.209\n"
     ]
    }
   ],
   "source": [
    "# example of power transform input and output variables for regression.\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import loadtxt\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "# load data \n",
    "dataframe = read_csv('housing.csv', header=None)\n",
    "# split into inputs and outputs\n",
    "last_ix = len(dataframe.columns) - 1\n",
    "X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# prepare the model with input scaling and power transform\n",
    "steps = list()\n",
    "#steps.append(('scale', MinMaxScaler()))\n",
    "steps.append(('scale', MinMaxScaler(feature_range=(1e-5, 1))))\n",
    "steps.append(('power', PowerTransformer()))\n",
    "steps.append(('model', svm.SVR()))\n",
    "#steps.append(('model', HuberRegressor()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# prepare the model with target scaling\n",
    "model_target_regressor = TransformedTargetRegressor(regressor=pipeline, transformer=PowerTransformer())\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model_target_regressor, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# convert scores to positive\n",
    "scores = absolute(scores)\n",
    "# summarize the result\n",
    "s_mean = mean(scores)\n",
    "print('Mean MAE: %.3f' % (s_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0fb62-dc7e-41e1-9201-10f727e301fa",
   "metadata": {},
   "source": [
    "## Selección de Características mediante Coeficientes de Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8cca5-06cd-4b53-b8c7-011fe1b3fae5",
   "metadata": {},
   "source": [
    "Veamos el orden de las variables en base a los coeficientes de correlación mediante la función *f_regression()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f85989c-4855-42f0-99fd-06d2b2298410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "Feature 0: 73.362968\n",
      "Feature 1: 71.032551\n",
      "Feature 2: 132.606905\n",
      "Feature 3: 10.055319\n",
      "Feature 4: 102.055325\n",
      "Feature 5: 329.164062\n",
      "Feature 6: 82.965262\n",
      "Feature 7: 34.251355\n",
      "Feature 8: 73.543625\n",
      "Feature 9: 110.524655\n",
      "Feature 10: 152.853099\n",
      "Feature 11: 48.938266\n",
      "Feature 12: 490.397465\n",
      "\n",
      "[12.  5. 10.  2.  9.  4.  6.  8.  0.  1. 11.  7.  3.]\n"
     ]
    }
   ],
   "source": [
    "# Example of calculating correlation statistics for all input variables.\n",
    "# example of correlation feature selection for numerical data\n",
    "from numpy import empty\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_regression, k='all') #Pearson's correlation (only positive values) ¿k=10?\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs  #return fs with scores\n",
    "\n",
    "# load data \n",
    "dataframe = read_csv('housing.csv', header=None)\n",
    "# split into inputs and outputs\n",
    "last_ix = len(dataframe.columns) - 1\n",
    "X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n",
    "print(X.shape, y.shape)\n",
    "# split into train and test sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "corr = empty((X.shape[1],2))\n",
    "for i in range(len(fs.scores_)):\n",
    "    corr[i,0] = i\n",
    "    corr[i,1] = fs.scores_[i]\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "print()\n",
    "print(corr[corr[:, 1].argsort()[::-1]][:,0])\n",
    "\n",
    "    #10 valores interesantes, el resto irrelevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f4805-da1c-45e9-879d-3515fcee5df9",
   "metadata": {},
   "source": [
    "Visualicemos claramente los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959674e8-a46f-4ca3-8122-3649cd65a04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f9d19-9ffb-4256-8b48-326f2b13ee39",
   "metadata": {},
   "source": [
    "## Selección de Características mediante Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d9166-c0f5-47a4-83f4-ba9498873079",
   "metadata": {},
   "source": [
    "Veamos el orden de las variables en base al Mutual Information mediante la función *mutual_info_regression()*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f36002-b202-4a6c-af74-37d8ad1aaf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "Feature 0: 0.310451\n",
      "Feature 1: 0.185942\n",
      "Feature 2: 0.517256\n",
      "Feature 3: 0.014123\n",
      "Feature 4: 0.443175\n",
      "Feature 5: 0.487332\n",
      "Feature 6: 0.343970\n",
      "Feature 7: 0.291080\n",
      "Feature 8: 0.194301\n",
      "Feature 9: 0.334058\n",
      "Feature 10: 0.450730\n",
      "Feature 11: 0.177433\n",
      "Feature 12: 0.690850\n",
      "\n",
      "[12.  2.  5. 10.  4.  6.  9.  0.  7.  8.  1. 11.  3.]\n"
     ]
    }
   ],
   "source": [
    "# Example of applying mutual information feature selection and summarizing the selected features.\n",
    "# example of mutual information feature selection for numerical input data\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k='all') #score_func=mutual_info_regression\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# load data \n",
    "dataframe = read_csv('housing.csv', header=None)\n",
    "# split into inputs and outputs\n",
    "last_ix = len(dataframe.columns) - 1\n",
    "X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n",
    "print(X.shape, y.shape)\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "corr = empty((X.shape[1],2))\n",
    "for i in range(len(fs.scores_)):\n",
    "    corr[i,0] = i\n",
    "    corr[i,1] = fs.scores_[i]\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "print()\n",
    "print(corr[corr[:, 1].argsort()[::-1]][:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a97cc-44b3-42bc-80c9-2771dec401ee",
   "metadata": {},
   "source": [
    "Visualicemos claramente los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a4786f-4f99-4b60-b381-643635052781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70dec2-667d-40ae-9c4b-f39fa2676f78",
   "metadata": {},
   "source": [
    "## Resultados de la aplicación de la Selección de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e83e811-dbd8-4617-8dc0-42d18080857b",
   "metadata": {},
   "source": [
    "### Cálculo del MAE base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc342771-8c20-4729-a927-52af59bb1896",
   "metadata": {},
   "source": [
    "Para poder comprobar la mejora (o la no pérdida) en los resultados obtenidos, calculemos el MAE base para el modelo aplicado al dataset con el procesamiento básico identificado en la práctica *P7*. Para ello, dejamos que se utilicen todas las variables del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f82995-4933-4975-ab60-2ce3b17d7070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "MAE: 3.519\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import loadtxt\n",
    "from pandas import read_csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# load data \n",
    "dataframe = read_csv('housing.csv', header=None)\n",
    "# split into inputs and outputs\n",
    "last_ix = len(dataframe.columns) - 1\n",
    "X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "# prepare the model with input scaling and power transform\n",
    "steps = list()\n",
    "#steps.append(('scale', MinMaxScaler()))\n",
    "steps.append(('scale', MinMaxScaler(feature_range=(1e-5, 1))))\n",
    "steps.append(('power', PowerTransformer()))\n",
    "steps.append(('model', svm.SVR()))\n",
    "#steps.append(('model', HuberRegressor()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# prepare the model with target scaling\n",
    "model_target_regressor = TransformedTargetRegressor(regressor=pipeline, transformer=PowerTransformer())\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# evaluate predictions\n",
    "yhat = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a600e-db97-4188-b107-8b0fd970ecfb",
   "metadata": {},
   "source": [
    "### Cálculo del MAE con Selección de Características mediante Coeficientes de Correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d8024-3f66-4a6a-ae1b-41d4629ec55f",
   "metadata": {},
   "source": [
    "Ahora, calculemos el MAE para la aplicación del mismo modelo aplicado sobre los datos con el mismo procesamiento sobre un número inferior de variables seleccionadas mediante los coeficientes de correlación. Por ejemplo, vemos que utilizando solo 5 variables disminuimos considerablemente la complejidad del modelo y aumentamos la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7844417-8384-4e5a-ae42-12206b26c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "MAE: 3.334\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import loadtxt\n",
    "from pandas import read_csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=f_regression, k=5)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    "\n",
    "# load data \n",
    "dataframe = read_csv('housing.csv', header=None)\n",
    "# split into inputs and outputs\n",
    "last_ix = len(dataframe.columns) - 1\n",
    "X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# prepare the model with input scaling and power transform\n",
    "steps = list()\n",
    "#steps.append(('scale', MinMaxScaler()))\n",
    "steps.append(('scale', MinMaxScaler(feature_range=(1e-5, 1))))\n",
    "steps.append(('power', PowerTransformer()))\n",
    "steps.append(('model', svm.SVR()))\n",
    "#steps.append(('model', HuberRegressor()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# prepare the model with target scaling\n",
    "model_target_regressor = TransformedTargetRegressor(regressor=pipeline, transformer=PowerTransformer())\n",
    "pipeline.fit(X_train_fs, y_train)\n",
    "\n",
    "# evaluate predictions\n",
    "yhat = pipeline.predict(X_test_fs)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9de126-6851-4e30-9f31-5207c918eb2d",
   "metadata": {},
   "source": [
    "### Cálculo del MAE con Selección de Características mediante Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104dd60-4dad-4127-9e58-ac74d18bf472",
   "metadata": {},
   "source": [
    "Ahora, calculemos el MAE para la aplicación del mismo modelo aplicado sobre los datos con el mismo procesamiento sobre un número inferior de variables seleccionadas mediante los valores de información mutua. Por ejemplo, vemos que utilizando 6 variables también disminuimos la complejidad del modelo y seguimos aumentando la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af4e680-20c9-47d5-b54e-ab7e14eab9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "MAE: 3.392\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import loadtxt\n",
    "from pandas import read_csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k=6)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    "\n",
    "# load data \n",
    "dataframe = read_csv('housing.csv', header=None)\n",
    "# split into inputs and outputs\n",
    "last_ix = len(dataframe.columns) - 1\n",
    "X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs = select_features(X_train, y_train, X_test)\n",
    "\n",
    "# prepare the model with input scaling and power transform\n",
    "steps = list()\n",
    "#steps.append(('scale', MinMaxScaler()))\n",
    "steps.append(('scale', MinMaxScaler(feature_range=(1e-5, 1))))\n",
    "steps.append(('power', PowerTransformer()))\n",
    "steps.append(('model', svm.SVR()))\n",
    "#steps.append(('model', HuberRegressor()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# prepare the model with target scaling\n",
    "model_target_regressor = TransformedTargetRegressor(regressor=pipeline, transformer=PowerTransformer())\n",
    "pipeline.fit(X_train_fs, y_train)\n",
    "\n",
    "# evaluate predictions\n",
    "yhat = pipeline.predict(X_test_fs)\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d759b180-d8c0-4ec1-8045-0c792d87b1d3",
   "metadata": {},
   "source": [
    "## Resumen de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e05e87-8b65-4a57-91d6-d9670b300185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "results = DataFrame(columns=['FSmethod', 'k', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b4db3a-d630-4061-b81e-459232df5ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import loadtxt\n",
    "from pandas import read_csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# feature selection\n",
    "def select_features(func, k, X_train, y_train, X_test):\n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=func, k=k)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs\n",
    "\n",
    "FSmethods = [f_regression, mutual_info_regression]\n",
    "FSmethods_names = ['Correlación','Mutual Information']\n",
    "k_values = list(range(1,14))\n",
    "\n",
    "# load data \n",
    "dataframe = read_csv('housing.csv', header=None)\n",
    "# split into inputs and outputs\n",
    "last_ix = len(dataframe.columns) - 1\n",
    "X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "# prepare the model with input scaling and power transform\n",
    "steps = list()\n",
    "#steps.append(('scale', MinMaxScaler()))\n",
    "steps.append(('scale', MinMaxScaler(feature_range=(1e-5, 1))))\n",
    "steps.append(('power', PowerTransformer()))\n",
    "steps.append(('model', svm.SVR()))\n",
    "#steps.append(('model', HuberRegressor()))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "for i,FSmethod in enumerate(FSmethods):\n",
    "    for k in k_values:\n",
    "        # feature selection\n",
    "        X_train_fs, X_test_fs = select_features(FSmethod, k, X_train, y_train, X_test)\n",
    "\n",
    "        # prepare the model with target scaling\n",
    "        model_target_regressor = TransformedTargetRegressor(regressor=pipeline, transformer=PowerTransformer())\n",
    "        pipeline.fit(X_train_fs, y_train)\n",
    "\n",
    "        # evaluate predictions\n",
    "        yhat = pipeline.predict(X_test_fs)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        \n",
    "        results.loc[len(results.index)] = {'FSmethod': FSmethods_names[i], \n",
    "                    'k': k, \n",
    "                    'MAE': mae}\n",
    "        \n",
    "        # print('MAE (%s con k=%i): %.3f' % (FSmethods_names[i], k, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe7cbda8-8063-4fb2-b916-39f2a3448c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FSmethod</th>\n",
       "      <th>k</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mutual Information</td>\n",
       "      <td>10</td>\n",
       "      <td>3.295261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mutual Information</td>\n",
       "      <td>9</td>\n",
       "      <td>3.303136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Correlación</td>\n",
       "      <td>5</td>\n",
       "      <td>3.333810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Correlación</td>\n",
       "      <td>9</td>\n",
       "      <td>3.368152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mutual Information</td>\n",
       "      <td>7</td>\n",
       "      <td>3.381178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FSmethod   k       MAE\n",
       "22  Mutual Information  10  3.295261\n",
       "21  Mutual Information   9  3.303136\n",
       "4          Correlación   5  3.333810\n",
       "8          Correlación   9  3.368152\n",
       "19  Mutual Information   7  3.381178"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('MAE', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5ac0c-a0b7-44f1-94c8-2f358b4b2833",
   "metadata": {},
   "source": [
    "Aunque para escoger el mejor método de Feature Selection deberíamos haber utilizado el conjunto de validación (con un CrossValidation adecuado), estos resultados nos permiten hacernos una idea de qué resultados se obtienen con los distintos métodos para este dataset con la partición realizada.\n",
    "\n",
    "Aunque depende de lo que busquemos en cada problema, considero que la selección de 5 variables realizada mediante los coeficientes de correlación nos aporta el \"mejor\" resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a6d22-67af-4870-a6dc-65e97083265d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
